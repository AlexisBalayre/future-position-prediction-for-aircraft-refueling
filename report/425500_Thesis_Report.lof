\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces Pressure Refuelling of a Commercial Aircraft. Photo Credit: Tom Boon/Simple Flying\nobreakspace {}\cite {ImageRefueling}\relax }}{1}{figure.caption.5}%
\contentsline {figure}{\numberline {1.2}{\ignorespaces Challenges in Detecting Aircraft Refuelling Port\relax }}{2}{figure.caption.6}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces AFRL's Automated Aircraft Ground Refueling system prototype robot (Photo Credit: AFRL/RXQ Robotics Group)\relax }}{4}{figure.caption.7}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces AR3P Concept Development Prototype Robot (Photo Credit: U.S. Army)\relax }}{5}{figure.caption.8}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces AR3P Robot Hot Refueling Demonstration for S-70 Helicopter\relax }}{5}{figure.caption.9}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces Autonomous Aerial Refueling (AAR) of X-47B Unmanned Combat Air System Demonstrator (Photo Credit: U.S. Navy)\relax }}{6}{figure.caption.10}%
\contentsline {figure}{\numberline {2.5}{\ignorespaces Autonomous Air Refueling Detection System with EKF. Source: \citet {AAREKF}\relax }}{6}{figure.caption.11}%
\contentsline {figure}{\numberline {2.6}{\ignorespaces Kalman Filter Workflow for Pose Estimation in Autonomous Ground Refueling. Source: \citet {AGRPoseEstimation}\relax }}{7}{figure.caption.12}%
\contentsline {figure}{\numberline {2.7}{\ignorespaces AAGR Dataset Overview. Source: \citet {DatasetAGR}\relax }}{7}{figure.caption.13}%
\contentsline {figure}{\numberline {2.8}{\ignorespaces Example of outputs from an object detector\nobreakspace {}\cite {huggingface2023objectdetection}.\relax }}{8}{figure.caption.14}%
\contentsline {figure}{\numberline {2.9}{\ignorespaces Basic deep learning-based one-stage vs two-stage object detection model architectures\nobreakspace {}\cite {SurveyDLOD}.\relax }}{8}{figure.caption.15}%
\contentsline {figure}{\numberline {2.10}{\ignorespaces Non-Maximum Suppression (NMS) in Object Detection\nobreakspace {}\cite {LearnOpenCVYOLOv10}.\relax }}{9}{figure.caption.16}%
\contentsline {figure}{\numberline {2.11}{\ignorespaces YOLOv10 Model Workflow\nobreakspace {}\cite {wang2024yolov10}\relax }}{9}{figure.caption.17}%
\contentsline {figure}{\numberline {2.12}{\ignorespaces Large-Kernel Convolution in YOLOv10\nobreakspace {}\cite {LearnOpenCVYOLOv10}\relax }}{10}{figure.caption.18}%
\contentsline {figure}{\numberline {2.13}{\ignorespaces Intersection over Union (IoU) between a detection (in green) and ground-truth (in blue).\nobreakspace {}\cite {huggingface2023objectdetection}\relax }}{11}{figure.caption.20}%
\contentsline {figure}{\numberline {2.14}{\ignorespaces Comparing different Sequence models: RNN, LSTM, and GRU. Source: Colah's blog. Compiled by AIML.com\relax }}{13}{figure.caption.21}%
\contentsline {figure}{\numberline {2.15}{\ignorespaces STED Model Architecture. Source:\nobreakspace {}\citet {MultipleObjectForecasting}\relax }}{14}{figure.caption.22}%
\contentsline {figure}{\numberline {2.16}{\ignorespaces PV-LSTM Model Architecture. Source:\nobreakspace {}\citet {DBLP:journals/corr/abs-2010-10270}\relax }}{15}{figure.caption.24}%
\contentsline {figure}{\numberline {2.17}{\ignorespaces Fusion-GRU model architecture. Source:\nobreakspace {}\citet {FusionGRU}\relax }}{16}{figure.caption.26}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces IntelÂ® ${\text {RealSense}}^{\text {TM}}$ D435 Depth Camera. Source: Intel\relax }}{17}{figure.caption.27}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces Annotated images of the refueling port in the CLOSED state.\relax }}{21}{figure.caption.31}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces Annotated images of the refueling port in the OPEN state.\relax }}{21}{figure.caption.32}%
\contentsline {figure}{\numberline {3.4}{\ignorespaces Annotated images of the refueling port in the SEMI-OPEN state.\relax }}{21}{figure.caption.33}%
\contentsline {figure}{\numberline {3.5}{\ignorespaces Framework Workflow\relax }}{22}{figure.caption.34}%
\contentsline {figure}{\numberline {3.6}{\ignorespaces SizPos-GRU Model Architecture\relax }}{23}{figure.caption.35}%
\contentsline {figure}{\numberline {3.7}{\ignorespaces SizPos-GRU Encoder Architecture. The input sequence \( \mathbf {X} = \{\mathbf {x}_1, \mathbf {x}_2, \dots , \mathbf {x}_T\} \) represents either the spatial dynamics vector (\(\mathbf {P}\)) or the dimensional attributes vector (\(\mathbf {D}\)). This sequence is processed through multiple GRU layers, producing a sequence of hidden states \( H = \{h_1, h_2, \dots , h_T\} \) and a final hidden state \( h_T \) that encapsulates the temporal dependencies in the input sequence.\relax }}{25}{figure.caption.36}%
\contentsline {figure}{\numberline {3.8}{\ignorespaces SizPos-GRU Decoder Architecture. This architecture illustrates the decoding process where the input sequence \( \mathbf {x}_t \) and the last hidden state \( h_{t-1} \) are processed through multiple GRU layers to generate the next hidden state \( h_t \). The sequence of hidden states \( H = \{h_1, h_2, \dots , h_t\} \) is then passed through a self-attention mechanism, which calculates attention scores and weights. The weighted sum of hidden states is combined with linear and non-linear transformations, including dropout and ReLU activation functions, to produce the final output \( \mathbf {x}_{t+1} \). This output is used for predicting the next time step in the sequence, continuing the process iteratively for future predictions.\relax }}{28}{figure.caption.37}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {A.1}{\ignorespaces Temporal analysis of different metrics for the refueling port in the \textit {test\_indoor1} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }}{36}{figure.caption.39}%
\contentsline {figure}{\numberline {A.2}{\ignorespaces Temporal analysis of different metrics for the refueling port in the \textit {test\_indoor1} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }}{37}{figure.caption.40}%
\contentsline {figure}{\numberline {A.3}{\ignorespaces Temporal analysis of different metrics for the refueling port in the \textit {test\_outdoor1} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }}{38}{figure.caption.41}%
\contentsline {figure}{\numberline {A.4}{\ignorespaces Temporal analysis of different metrics for the refueling port in the \textit {test\_outdoor1} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }}{39}{figure.caption.42}%
\contentsline {figure}{\numberline {A.5}{\ignorespaces Temporal analysis of different metrics for the refueling port in the \textit {test\_video\_lab\_platform\_6} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }}{40}{figure.caption.43}%
\contentsline {figure}{\numberline {A.6}{\ignorespaces Temporal analysis of different metrics for the refueling port in the \textit {test\_video\_lab\_platform\_6} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }}{41}{figure.caption.44}%
