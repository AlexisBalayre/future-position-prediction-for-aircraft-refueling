\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces Pressure Refuelling of a Commercial Aircraft. Source: Tom Boon/Simple Flying\relax }}{1}{figure.caption.5}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Example of outputs from an object detector\nobreakspace {}\cite {huggingface2023objectdetection}.\relax }}{5}{figure.caption.6}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces Basic deep learning-based one-stage vs two-stage object detection model architectures\nobreakspace {}\cite {SurveyDLOD}.\relax }}{5}{figure.caption.7}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces Intersection over Union (IoU) between a detection (in green) and ground-truth (in blue).\nobreakspace {}\cite {huggingface2023objectdetection}\relax }}{6}{figure.caption.8}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces Comparing different Sequence models: RNN, LSTM, and GRU. Source: Colah's blog. Compiled by AIML.com\relax }}{8}{figure.caption.9}%
\contentsline {figure}{\numberline {2.5}{\ignorespaces Cubic LSTM Architecture. (a) 3D structure of the CubicLSTM unit. (b) Topological diagram of the CubicLSTM unit. (c) Two-spatial-layer RNN composed of CubicLSTM units. The unit consists of three branches, a spatial (z-) branch for extracting and recognizing moving objects, a temporal (y-) branch for capturing and predicting motions, and an output (x-) branch for combining the first two branches to generate the predicted frames. Source:\nobreakspace {}\citet {CubicLSTMsVideoPrediction}\relax }}{9}{figure.caption.10}%
\contentsline {figure}{\numberline {2.6}{\ignorespaces Model Architecture. Source:\nobreakspace {}\citet {UnsupervisedVideoForecastingFlowParsingMechanism}\relax }}{10}{figure.caption.11}%
\contentsline {figure}{\numberline {2.7}{\ignorespaces FPNet-OF model architecture. Source:\nobreakspace {}\citet {VideoFramePredictionByJointOptimizationWithSynthesisAndOpticalFlowEstimation}\relax }}{10}{figure.caption.12}%
\contentsline {figure}{\numberline {2.8}{\ignorespaces Fusion-GRU model architecture. Source:\nobreakspace {}\citet {FusionGRU}\relax }}{11}{figure.caption.13}%
\contentsline {figure}{\numberline {2.9}{\ignorespaces Dual-Branch Spatial-Temporal Learning Network. Source:\nobreakspace {}\citet {DualBranchSpatialTemporalLearningNetworkVideoPrediction}\relax }}{11}{figure.caption.14}%
\contentsline {figure}{\numberline {2.10}{\ignorespaces Dual-Branch Spatial-Temporal Learning Network. Source:\nobreakspace {}\citet {SurveyDLOD}\relax }}{12}{figure.caption.15}%
\contentsline {figure}{\numberline {2.11}{\ignorespaces 2-digit Moving MNIST data by\nobreakspace {}\citet {DBLP:journals/corr/SrivastavaMS15}\relax }}{12}{figure.caption.16}%
\contentsline {figure}{\numberline {2.12}{\ignorespaces Robotic Pushing Dataset. Source:\nobreakspace {}\citet {DBLP:journals/corr/EitelHB17}\relax }}{13}{figure.caption.17}%
\contentsline {figure}{\numberline {2.13}{\ignorespaces KTH Action Dataset. Source:\nobreakspace {}\citet {KTH}\relax }}{13}{figure.caption.18}%
\contentsline {figure}{\numberline {2.14}{\ignorespaces UCF Sports Dataset. Source:\nobreakspace {}\citet {UCFSport}\relax }}{13}{figure.caption.19}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
