\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {chapter}{Academic Integrity Declaration}{i}{Doc-Start}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Abstract}{ii}{chapter*.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{FusionGRU}
\@writefile{toc}{\contentsline {chapter}{Acknowledgements}{iii}{chapter*.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{Table of Contents}{iv}{chapter*.3}\protected@file@percent }
\citation{ImageRefueling}
\citation{AAREKF}
\citation{AGRPoseEstimation}
\citation{DatasetAGR}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{SurveyDLOD}
\citation{LearnOpenCVYOLOv10}
\citation{wang2024yolov10}
\citation{LearnOpenCVYOLOv10}
\citation{MultipleObjectForecasting}
\citation{DBLP:journals/corr/abs-2010-10270}
\citation{FusionGRU}
\@writefile{toc}{\contentsline {chapter}{List of Figures}{vi}{chapter*.4}\protected@file@percent }
\citation{wang2024yolov10}
\@writefile{toc}{\contentsline {chapter}{List of Tables}{viii}{chapter*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{List of Abbreviations}{ix}{chapter*.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{blakey2011aviation}
\citation{sati2019aircraft,Cummins2020}
\citation{blakey2011aviation}
\citation{doi:10.1080/13669877.2013.879493,CostsOfUnsafetyAviation}
\citation{ImageRefueling}
\citation{ImageRefueling}
\citation{10.1007/978-981-16-5943-0_26}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Background and Motivation}{1}{section.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Pressure Refuelling of a Commercial Aircraft. Photo Credit: Tom Boon/Simple Flying\nobreakspace  {}\cite  {ImageRefueling}\relax }}{1}{figure.caption.7}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:pressure-refuelling}{{1.1}{1}{Pressure Refuelling of a Commercial Aircraft. Photo Credit: Tom Boon/Simple Flying~\cite {ImageRefueling}\relax }{figure.caption.7}{}}
\newlabel{fig:motion-blur-example}{{1.2a}{2}{Motion Blur Example\relax }{figure.caption.8}{}}
\newlabel{sub@fig:motion-blur-example}{{a}{2}{Motion Blur Example\relax }{figure.caption.8}{}}
\newlabel{fig:occlusion-example}{{1.2b}{2}{Occlusion Example\relax }{figure.caption.8}{}}
\newlabel{sub@fig:occlusion-example}{{b}{2}{Occlusion Example\relax }{figure.caption.8}{}}
\newlabel{fig:out-of-view-example}{{1.2c}{2}{Out-of-View Example\relax }{figure.caption.8}{}}
\newlabel{sub@fig:out-of-view-example}{{c}{2}{Out-of-View Example\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Challenges in Detecting Aircraft Refuelling Port\relax }}{2}{figure.caption.8}\protected@file@percent }
\newlabel{fig:challenges-detecting-ports}{{1.2}{2}{Challenges in Detecting Aircraft Refuelling Port\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Research Gap}{2}{section.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Aim and Objectives}{2}{section.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Technological Contributions}{3}{section.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Thesis Layout}{3}{section.1.5}\protected@file@percent }
\citation{ExpertSystemsAGR}
\citation{Schultz1986}
\citation{Bennett1991}
\citation{Burnette2010}
\citation{Ficken2017}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Literature Review}{4}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:literature-review}{{2}{4}{Literature Review}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Automated Refulling Systems in the Aviation Industry}{4}{section.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces AFRL's Automated Aircraft Ground Refuelling system prototype robot (Photo Credit: AFRL/RXQ Robotics Group)\relax }}{4}{figure.caption.9}\protected@file@percent }
\newlabel{fig:test-2010}{{2.1}{4}{AFRL's Automated Aircraft Ground Refuelling system prototype robot (Photo Credit: AFRL/RXQ Robotics Group)\relax }{figure.caption.9}{}}
\newlabel{fig:test-2010}{{2.1}{4}{AFRL's Automated Aircraft Ground Refuelling system prototype robot (Photo Credit: AFRL/RXQ Robotics Group)\relax }{figure.caption.9}{}}
\citation{AR3P2020}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces AR3P Concept Development Prototype Robot (Photo Credit: U.S. Army)\relax }}{5}{figure.caption.10}\protected@file@percent }
\newlabel{fig:test-2017}{{2.2}{5}{AR3P Concept Development Prototype Robot (Photo Credit: U.S. Army)\relax }{figure.caption.10}{}}
\newlabel{test-2020-2}{{2.3a}{5}{AR3P Robot Approaching Detected Aircraft (Photo Credit: Stratom)\relax }{figure.caption.11}{}}
\newlabel{sub@test-2020-2}{{a}{5}{AR3P Robot Approaching Detected Aircraft (Photo Credit: Stratom)\relax }{figure.caption.11}{}}
\newlabel{test-2020-3}{{2.3b}{5}{AR3P Robot Engaging Aircraft Refuelling Port (Photo Credit: Stratom)\relax }{figure.caption.11}{}}
\newlabel{sub@test-2020-3}{{b}{5}{AR3P Robot Engaging Aircraft Refuelling Port (Photo Credit: Stratom)\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces AR3P Robot Hot Refuelling Demonstration for S-70 Helicopter\relax }}{5}{figure.caption.11}\protected@file@percent }
\newlabel{fig:automated-refuelling-systems}{{2.3}{5}{AR3P Robot Hot Refuelling Demonstration for S-70 Helicopter\relax }{figure.caption.11}{}}
\citation{AARBinocularVision,AARCNN,Chen2011}
\citation{AAREKF}
\citation{Cai2023}
\citation{AAREKF}
\citation{AAREKF}
\citation{AGRPoseEstimation}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Autonomous Aerial Refuelling (AAR) of X-47B Unmanned Combat Air System Demonstrator (Photo Credit: U.S. Navy)\relax }}{6}{figure.caption.12}\protected@file@percent }
\newlabel{fig:aerial-refuelling}{{2.4}{6}{Autonomous Aerial Refuelling (AAR) of X-47B Unmanned Combat Air System Demonstrator (Photo Credit: U.S. Navy)\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Autonomous Air Refuelling Detection System with EKF. Source: \citet  {AAREKF}\relax }}{6}{figure.caption.13}\protected@file@percent }
\newlabel{fig:detection-system-aarekf}{{2.5}{6}{Autonomous Air Refuelling Detection System with EKF. Source: \citet {AAREKF}\relax }{figure.caption.13}{}}
\citation{AGRPoseEstimation}
\citation{AGRPoseEstimation}
\citation{DatasetAGR}
\citation{HybridDatasetAGRV1,HybridDatasetAGRV2}
\citation{DatasetAGR}
\citation{DatasetAGR}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Kalman Filter Workflow for Pose Estimation in Autonomous Ground Refuelling. Source: \citet  {AGRPoseEstimation}\relax }}{7}{figure.caption.14}\protected@file@percent }
\newlabel{fig:agr-pose-kalman}{{2.6}{7}{Kalman Filter Workflow for Pose Estimation in Autonomous Ground Refuelling. Source: \citet {AGRPoseEstimation}\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces AAGR Dataset Overview. Source: \citet  {DatasetAGR}\relax }}{7}{figure.caption.15}\protected@file@percent }
\newlabel{fig:agr-dataset}{{2.7}{7}{AAGR Dataset Overview. Source: \citet {DatasetAGR}\relax }{figure.caption.15}{}}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{DBLP:journals/corr/GirshickDDM13}
\citation{DBLP:journals/corr/Girshick15}
\citation{Ren2017}
\citation{DBLP:journals/corr/DaiLHS16}
\citation{Carion2020}
\citation{SurveyDLOD,ODNetworkUAVCNNTransformer}
\citation{DBLP:journals/corr/LiuAESR15}
\citation{DBLP:journals/corr/RedmonDGF15,DBLP:journals/corr/RedmonF16,DBLP:journals/corr/abs-2004-10934,chen2023yoloms,DBLP:journals/corr/abs-2107-08430,YOLOv5Release,li2023yolov6,YOLOv8,wang2024yolov9,xu2022ppyoloe,wang2023goldyolo,xu2023damoyolo,wang2024yolov10}
\citation{lin2018focal}
\citation{SurveyDLOD,ODNetworkUAVCNNTransformer,Diwan2023}
\citation{SurveyDLOD}
\citation{SurveyDLOD}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Object Detection and Tracking in Computer Vision}{8}{section.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Example of outputs from an object detector\nobreakspace  {}\cite  {huggingface2023objectdetection}.\relax }}{8}{figure.caption.16}\protected@file@percent }
\newlabel{fig:object-detection}{{2.8}{8}{Example of outputs from an object detector~\cite {huggingface2023objectdetection}.\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Intersection over Union (IoU) between a detection (in green) and ground-truth (in blue).\nobreakspace  {}\cite  {huggingface2023objectdetection}\relax }}{8}{figure.caption.17}\protected@file@percent }
\newlabel{fig:iou-metric}{{2.9}{8}{Intersection over Union (IoU) between a detection (in green) and ground-truth (in blue).~\cite {huggingface2023objectdetection}\relax }{figure.caption.17}{}}
\citation{LearnOpenCVYOLOv10}
\citation{LearnOpenCVYOLOv10}
\citation{LearnOpenCVYOLOv10}
\citation{wang2024yolov10}
\citation{wang2024yolov10}
\citation{wang2024yolov10}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces Basic deep learning-based one-stage vs two-stage object detection model architectures\nobreakspace  {}\cite  {SurveyDLOD}.\relax }}{9}{figure.caption.18}\protected@file@percent }
\newlabel{fig:two-stage-vs-single-stage}{{2.10}{9}{Basic deep learning-based one-stage vs two-stage object detection model architectures~\cite {SurveyDLOD}.\relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces Non-Maximum Suppression (NMS) in Object Detection\nobreakspace  {}\cite  {LearnOpenCVYOLOv10}.\relax }}{9}{figure.caption.19}\protected@file@percent }
\newlabel{fig:nms}{{2.11}{9}{Non-Maximum Suppression (NMS) in Object Detection~\cite {LearnOpenCVYOLOv10}.\relax }{figure.caption.19}{}}
\citation{wang2024yolov10,LearnOpenCVYOLOv10}
\citation{LearnOpenCVYOLOv10}
\citation{LearnOpenCVYOLOv10}
\citation{wang2024yolov10}
\citation{wang2024yolov10}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces YOLOv10 Model Workflow\nobreakspace  {}\cite  {wang2024yolov10}\relax }}{10}{figure.caption.20}\protected@file@percent }
\newlabel{fig:yolov10}{{2.12}{10}{YOLOv10 Model Workflow~\cite {wang2024yolov10}\relax }{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces Large-Kernel Convolution in YOLOv10\nobreakspace  {}\cite  {LearnOpenCVYOLOv10}\relax }}{10}{figure.caption.21}\protected@file@percent }
\newlabel{fig:large-kernel-yolov10}{{2.13}{10}{Large-Kernel Convolution in YOLOv10~\cite {LearnOpenCVYOLOv10}\relax }{figure.caption.21}{}}
\citation{SurveyVisualOT}
\citation{SurveyVisualOT}
\citation{OverviewCorrelationAlgoOT,SuveyAdvancesSingleOTMethods,SurveyModernODModels}
\citation{SuveyAdvancesSingleOTMethods,SurveyModernODModels,SurveyTransformersSingleOT}
\citation{SurveyTransformersSingleOT}
\citation{SurveySmallObjectDetection,SmallObjectDetectionPositonPrediction}
\citation{SuveyAdvancesSingleOTMethods,SurveyModernODModels}
\citation{OverviewCorrelationAlgoOT,SuveyAdvancesSingleOTMethods}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Performance Comparison of YOLO Models with State-of-the-Art Techniques\nobreakspace  {}\cite  {wang2024yolov10}.\relax }}{11}{table.caption.22}\protected@file@percent }
\newlabel{tab:yolov10-benchmarks}{{2.1}{11}{Performance Comparison of YOLO Models with State-of-the-Art Techniques~\cite {wang2024yolov10}.\relax }{table.caption.22}{}}
\citation{FFPSpaceSystemVehicles}
\citation{Alemany2019,Bemporad2023,PredictionHeadMovement360Degrees,Feng2018,HurricanesFPP}
\citation{CubicLSTMsVideoPrediction,ConvLSTM,DBLP:journals/corr/SrivastavaMS15}
\citation{FusionGRU}
\citation{Alahi2016}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Deep Learning for Spacio-Temporal Prediction}{12}{section.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.14}{\ignorespaces Comparing different Sequence models: RNN, LSTM, and GRU. Source: Colah's blog. Compiled by AIML.com\relax }}{12}{figure.caption.23}\protected@file@percent }
\newlabel{fig:lstm-rnn-gru}{{2.14}{12}{Comparing different Sequence models: RNN, LSTM, and GRU. Source: Colah's blog. Compiled by AIML.com\relax }{figure.caption.23}{}}
\citation{MultipleObjectForecasting}
\citation{MultipleObjectForecasting}
\citation{MultipleObjectForecasting}
\citation{MultipleObjectForecasting}
\citation{MultipleObjectForecasting}
\citation{MultipleObjectForecasting}
\citation{MultipleObjectForecasting}
\@writefile{lof}{\contentsline {figure}{\numberline {2.15}{\ignorespaces STED Model Architecture. Source:\nobreakspace  {}\citet  {MultipleObjectForecasting}\relax }}{13}{figure.caption.24}\protected@file@percent }
\newlabel{fig:sted}{{2.15}{13}{STED Model Architecture. Source:~\citet {MultipleObjectForecasting}\relax }{figure.caption.24}{}}
\citation{DBLP:journals/corr/abs-2010-10270}
\citation{DBLP:journals/corr/abs-2010-10270}
\citation{DBLP:journals/corr/abs-2010-10270}
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces Comparison of the performance of STED with baseline models on the Citywalks dataset. \relax }}{14}{table.caption.25}\protected@file@percent }
\newlabel{tab:sted-results}{{2.2}{14}{Comparison of the performance of STED with baseline models on the Citywalks dataset. \relax }{table.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.16}{\ignorespaces PV-LSTM Model Architecture. Source:\nobreakspace  {}\citet  {DBLP:journals/corr/abs-2010-10270}\relax }}{14}{figure.caption.26}\protected@file@percent }
\newlabel{fig:pv-lstm}{{2.16}{14}{PV-LSTM Model Architecture. Source:~\citet {DBLP:journals/corr/abs-2010-10270}\relax }{figure.caption.26}{}}
\citation{DBLP:journals/corr/abs-2010-10270}
\citation{DBLP:journals/corr/abs-2010-10270}
\citation{DBLP:journals/corr/abs-2010-10270}
\citation{DBLP:journals/corr/abs-2010-10270}
\citation{FusionGRU}
\citation{FusionGRU}
\citation{FusionGRU}
\citation{karim_am_net2023}
\citation{yao2019egocentric,malla2019nemo}
\@writefile{lot}{\contentsline {table}{\numberline {2.3}{\ignorespaces Comparison of the performance of PV-LSTM with baseline models on the Citywalks dataset. \relax }}{15}{table.caption.27}\protected@file@percent }
\newlabel{tab:pv-lstm-results}{{2.3}{15}{Comparison of the performance of PV-LSTM with baseline models on the Citywalks dataset. \relax }{table.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.17}{\ignorespaces Fusion-GRU model architecture. Source:\nobreakspace  {}\citet  {FusionGRU}\relax }}{15}{figure.caption.28}\protected@file@percent }
\newlabel{fig:fusion-gru}{{2.17}{15}{Fusion-GRU model architecture. Source:~\citet {FusionGRU}\relax }{figure.caption.28}{}}
\citation{FusionGRU}
\citation{FusionGRU}
\citation{FusionGRU}
\@writefile{lot}{\contentsline {table}{\numberline {2.4}{\ignorespaces Comparison of the performance of Fusion-GRU with baseline models on the ROL and HEV-I datasets.\relax }}{16}{table.caption.29}\protected@file@percent }
\newlabel{tab:fusion-gru-results}{{2.4}{16}{Comparison of the performance of Fusion-GRU with baseline models on the ROL and HEV-I datasets.\relax }{table.caption.29}{}}
\citation{IntelRealSense}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Methodology}{17}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:methodology}{{3}{17}{Methodology}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Dataset Configuration}{17}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Dataset Description}{17}{subsection.3.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Intel® ${\text  {RealSense}}^{\text  {TM}}$ D435 Depth Camera. Source: Intel\relax }}{17}{figure.caption.30}\protected@file@percent }
\newlabel{fig:intel-realsense-d435}{{3.1}{17}{Intel® ${\text {RealSense}}^{\text {TM}}$ D435 Depth Camera. Source: Intel\relax }{figure.caption.30}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Data Annotation}{18}{subsection.3.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Summary of Available Videos}{19}{subsection.3.1.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces \centering  Summary of available videos in the AARP dataset with their assignment.\relax }}{19}{table.caption.31}\protected@file@percent }
\newlabel{tab:video_summary}{{3.1}{19}{\centering Summary of available videos in the AARP dataset with their assignment.\relax }{table.caption.31}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.4}Data Distribution}{20}{subsection.3.1.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces \centering  Distribution of frames across train, test, and validation sets for each state in the AARP dataset before balancing.\relax }}{20}{table.caption.32}\protected@file@percent }
\newlabel{tab:frame_distribution}{{3.2}{20}{\centering Distribution of frames across train, test, and validation sets for each state in the AARP dataset before balancing.\relax }{table.caption.32}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.5}Data Balancing}{20}{subsection.3.1.5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces \centering  Distribution of frames across train, test, and validation sets for each state in the AARP dataset after balancing.\relax }}{20}{table.caption.33}\protected@file@percent }
\newlabel{tab:balanced_frame_distribution}{{3.3}{20}{\centering Distribution of frames across train, test, and validation sets for each state in the AARP dataset after balancing.\relax }{table.caption.33}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.6}Example Images from the Datase}{21}{subsection.3.1.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Annotated images of the refuelling port in the CLOSED state.\relax }}{21}{figure.caption.34}\protected@file@percent }
\newlabel{fig:grid-closed-images}{{3.2}{21}{Annotated images of the refuelling port in the CLOSED state.\relax }{figure.caption.34}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Annotated images of the refuelling port in the SEMI-OPEN state.\relax }}{21}{figure.caption.35}\protected@file@percent }
\newlabel{fig:grid-semi-open-images}{{3.3}{21}{Annotated images of the refuelling port in the SEMI-OPEN state.\relax }{figure.caption.35}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Annotated images of the refuelling port in the OPEN state.\relax }}{21}{figure.caption.36}\protected@file@percent }
\newlabel{fig:grid-open-images}{{3.4}{21}{Annotated images of the refuelling port in the OPEN state.\relax }{figure.caption.36}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.7}Temporal Dynamics Analysis of the Refuelling Port}{22}{subsection.3.1.7}\protected@file@percent }
\newlabel{fig:central-position-test-indoor1-raw}{{3.5a}{22}{Central Position over Time without Filter.\relax }{figure.caption.37}{}}
\newlabel{sub@fig:central-position-test-indoor1-raw}{{a}{22}{Central Position over Time without Filter.\relax }{figure.caption.37}{}}
\newlabel{fig:central-position-test-indoor1-savgol}{{3.5b}{22}{Central Position over Time with Savitzky-Golay Filter.\relax }{figure.caption.37}{}}
\newlabel{sub@fig:central-position-test-indoor1-savgol}{{b}{22}{Central Position over Time with Savitzky-Golay Filter.\relax }{figure.caption.37}{}}
\newlabel{fig:central-position-test-indoor1-gaussian}{{3.5c}{22}{Central Position over Time with Gaussian Filter.\relax }{figure.caption.37}{}}
\newlabel{sub@fig:central-position-test-indoor1-gaussian}{{c}{22}{Central Position over Time with Gaussian Filter.\relax }{figure.caption.37}{}}
\newlabel{fig:central-position-test-indoor1-rolling}{{3.5d}{22}{Central Position over Time with Rolling Mean Filter.\relax }{figure.caption.37}{}}
\newlabel{sub@fig:central-position-test-indoor1-rolling}{{d}{22}{Central Position over Time with Rolling Mean Filter.\relax }{figure.caption.37}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Temporal analysis of refuelling port central position in video \textit  {test\_indoor1}.\relax }}{22}{figure.caption.37}\protected@file@percent }
\newlabel{fig:central-position-test-indoor1}{{3.5}{22}{Temporal analysis of refuelling port central position in video \textit {test\_indoor1}.\relax }{figure.caption.37}{}}
\newlabel{fig:velocity-test-indoor1-raw}{{3.6a}{23}{Velocity over Time without Filter.\relax }{figure.caption.38}{}}
\newlabel{sub@fig:velocity-test-indoor1-raw}{{a}{23}{Velocity over Time without Filter.\relax }{figure.caption.38}{}}
\newlabel{fig:velocity-test-indoor1-savgol}{{3.6b}{23}{Velocity over Time with Savitzky-Golay Filter.\relax }{figure.caption.38}{}}
\newlabel{sub@fig:velocity-test-indoor1-savgol}{{b}{23}{Velocity over Time with Savitzky-Golay Filter.\relax }{figure.caption.38}{}}
\newlabel{fig:velocity-test-indoor1-gaussian}{{3.6c}{23}{Velocity over Time with Gaussian Filter.\relax }{figure.caption.38}{}}
\newlabel{sub@fig:velocity-test-indoor1-gaussian}{{c}{23}{Velocity over Time with Gaussian Filter.\relax }{figure.caption.38}{}}
\newlabel{fig:velocity-test-indoor1-rolling}{{3.6d}{23}{Velocity over Time with Rolling Mean Filter.\relax }{figure.caption.38}{}}
\newlabel{sub@fig:velocity-test-indoor1-rolling}{{d}{23}{Velocity over Time with Rolling Mean Filter.\relax }{figure.caption.38}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Temporal analysis of refuelling port velocity in video \textit  {test\_indoor1}.\relax }}{23}{figure.caption.38}\protected@file@percent }
\newlabel{fig:velocity-test-indoor1}{{3.6}{23}{Temporal analysis of refuelling port velocity in video \textit {test\_indoor1}.\relax }{figure.caption.38}{}}
\newlabel{fig:acceleration-test-indoor1-raw}{{3.7a}{24}{Acceleration over Time without Filter.\relax }{figure.caption.39}{}}
\newlabel{sub@fig:acceleration-test-indoor1-raw}{{a}{24}{Acceleration over Time without Filter.\relax }{figure.caption.39}{}}
\newlabel{fig:acceleration-test-indoor1-savgol}{{3.7b}{24}{Acceleration over Time with Savitzky-Golay Filter.\relax }{figure.caption.39}{}}
\newlabel{sub@fig:acceleration-test-indoor1-savgol}{{b}{24}{Acceleration over Time with Savitzky-Golay Filter.\relax }{figure.caption.39}{}}
\newlabel{fig:acceleration-test-indoor1-gaussian}{{3.7c}{24}{Acceleration over Time with Gaussian Filter.\relax }{figure.caption.39}{}}
\newlabel{sub@fig:acceleration-test-indoor1-gaussian}{{c}{24}{Acceleration over Time with Gaussian Filter.\relax }{figure.caption.39}{}}
\newlabel{fig:acceleration-test-indoor1-rolling}{{3.7d}{24}{Acceleration over Time with Rolling Mean Filter.\relax }{figure.caption.39}{}}
\newlabel{sub@fig:acceleration-test-indoor1-rolling}{{d}{24}{Acceleration over Time with Rolling Mean Filter.\relax }{figure.caption.39}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Temporal analysis of refuelling port acceleration in video \textit  {test\_indoor1}.\relax }}{24}{figure.caption.39}\protected@file@percent }
\newlabel{fig:acceleration-test-indoor1}{{3.7}{24}{Temporal analysis of refuelling port acceleration in video \textit {test\_indoor1}.\relax }{figure.caption.39}{}}
\citation{Savitzky1964,5888646}
\citation{8378142}
\citation{smith1999dsp}
\newlabel{fig:size-test-indoor1-raw}{{3.8a}{25}{Area over Time without Filter.\relax }{figure.caption.40}{}}
\newlabel{sub@fig:size-test-indoor1-raw}{{a}{25}{Area over Time without Filter.\relax }{figure.caption.40}{}}
\newlabel{fig:size-test-indoor1-savgol}{{3.8b}{25}{Area over Time with Savitzky-Golay Filter.\relax }{figure.caption.40}{}}
\newlabel{sub@fig:size-test-indoor1-savgol}{{b}{25}{Area over Time with Savitzky-Golay Filter.\relax }{figure.caption.40}{}}
\newlabel{fig:size-test-indoor1-gaussian}{{3.8c}{25}{Area over Time with Gaussian Filter.\relax }{figure.caption.40}{}}
\newlabel{sub@fig:size-test-indoor1-gaussian}{{c}{25}{Area over Time with Gaussian Filter.\relax }{figure.caption.40}{}}
\newlabel{fig:size-test-indoor1-rolling}{{3.8d}{25}{Area over Time with Rolling Mean Filter.\relax }{figure.caption.40}{}}
\newlabel{sub@fig:size-test-indoor1-rolling}{{d}{25}{Area over Time with Rolling Mean Filter.\relax }{figure.caption.40}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Temporal analysis of refuelling port size in video \textit  {test\_indoor1}.\relax }}{25}{figure.caption.40}\protected@file@percent }
\newlabel{fig:size-test-indoor1}{{3.8}{25}{Temporal analysis of refuelling port size in video \textit {test\_indoor1}.\relax }{figure.caption.40}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Framework Design}{27}{section.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces Framework Workflow\relax }}{27}{figure.caption.41}\protected@file@percent }
\newlabel{fig:framework-workflow}{{3.9}{27}{Framework Workflow\relax }{figure.caption.41}{}}
\citation{Jocher_Ultralytics_YOLO_2023}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Object Detection Model Fine-tuning}{28}{section.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Sequence Model Design}{28}{section.3.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces \textit  {SizPos-GRU} model Architecture\relax }}{29}{figure.caption.42}\protected@file@percent }
\newlabel{fig:sizpos-gru}{{3.10}{29}{\textit {SizPos-GRU} model Architecture\relax }{figure.caption.42}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Input Representation}{29}{subsection.3.4.1}\protected@file@percent }
\newlabel{eq:spatial_dynamics_vector}{{3.1}{29}{}{equation.3.4.1}{}}
\newlabel{eq:velocity_definitions}{{3.2}{29}{}{equation.3.4.2}{}}
\newlabel{eq:acceleration_definitions}{{3.3}{29}{}{equation.3.4.3}{}}
\newlabel{eq:dimensional_attributes_vector}{{3.4}{29}{}{equation.3.4.4}{}}
\newlabel{eq:dimension_changes}{{3.5}{29}{}{equation.3.4.5}{}}
\newlabel{eq:input_sequences}{{3.4.1}{30}{}{equation.3.4.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Encoders}{30}{subsection.3.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces \textit  {SizPos-GRU} Encoder Architecture.\relax }}{30}{figure.caption.43}\protected@file@percent }
\newlabel{fig:sizpos-gru-encoder}{{3.11}{30}{\textit {SizPos-GRU} Encoder Architecture.\relax }{figure.caption.43}{}}
\newlabel{eq:position_encoder}{{3.6}{30}{}{equation.3.4.6}{}}
\newlabel{eq:size_encoder}{{3.7}{30}{}{equation.3.4.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Hidden State Fusion}{31}{subsection.3.4.3}\protected@file@percent }
\newlabel{eq:hidden_state_fusion}{{3.8}{31}{Hidden State Fusion}{equation.3.4.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.4}Decoders}{31}{subsection.3.4.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces \textit  {SizPos-GRU} Decoder Architecture.\relax }}{31}{figure.caption.44}\protected@file@percent }
\newlabel{fig:sizpos-gru-decoder}{{3.12}{31}{\textit {SizPos-GRU} Decoder Architecture.\relax }{figure.caption.44}{}}
\newlabel{eq:position_decoder_gru}{{3.9}{32}{}{equation.3.4.9}{}}
\newlabel{eq:attention_scores_position}{{3.10}{32}{}{equation.3.4.10}{}}
\newlabel{eq:context_vector_position}{{3.11}{32}{}{equation.3.4.11}{}}
\newlabel{eq:position_prediction_1}{{3.12}{32}{}{equation.3.4.12}{}}
\newlabel{eq:position_prediction_2}{{3.13}{32}{}{equation.3.4.13}{}}
\newlabel{eq:size_decoder_gru}{{3.14}{33}{}{equation.3.4.14}{}}
\newlabel{eq:attention_scores_size}{{3.15}{33}{}{equation.3.4.15}{}}
\newlabel{eq:context_vector_size}{{3.16}{33}{}{equation.3.4.16}{}}
\newlabel{eq:size_prediction_1}{{3.17}{33}{}{equation.3.4.17}{}}
\newlabel{eq:size_prediction_2}{{3.18}{33}{}{equation.3.4.18}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Algorithm Design}{33}{section.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Calculation of Key Values for Loss Functions}{33}{subsection.3.5.1}\protected@file@percent }
\newlabel{eq:bounding_box_x}{{3.19}{33}{}{equation.3.5.19}{}}
\newlabel{eq:bounding_box_y}{{3.20}{33}{}{equation.3.5.20}{}}
\newlabel{eq:bounding_box_w}{{3.21}{33}{}{equation.3.5.21}{}}
\newlabel{eq:bounding_box_h}{{3.22}{33}{}{equation.3.5.22}{}}
\newlabel{eq:velocity_x}{{3.23}{33}{}{equation.3.5.23}{}}
\newlabel{eq:velocity_y}{{3.24}{33}{}{equation.3.5.24}{}}
\newlabel{eq:velocity_w}{{3.25}{33}{}{equation.3.5.25}{}}
\newlabel{eq:velocity_h}{{3.26}{33}{}{equation.3.5.26}{}}
\newlabel{eq:position_x}{{3.27}{34}{}{equation.3.5.27}{}}
\newlabel{eq:position_y}{{3.28}{34}{}{equation.3.5.28}{}}
\newlabel{eq:position_w}{{3.29}{34}{}{equation.3.5.29}{}}
\newlabel{eq:position_h}{{3.30}{34}{}{equation.3.5.30}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Loss Function Formulation}{34}{subsection.3.5.2}\protected@file@percent }
\newlabel{eq:size_loss}{{3.31}{34}{}{equation.3.5.31}{}}
\newlabel{eq:position_loss}{{3.32}{34}{}{equation.3.5.32}{}}
\newlabel{eq:smooth_l1}{{3.33}{34}{}{equation.3.5.33}{}}
\newlabel{eq:bbox_loss}{{3.34}{35}{}{equation.3.5.34}{}}
\newlabel{eq:vel_to_pos_loss}{{3.35}{35}{}{equation.3.5.35}{}}
\newlabel{eq:total_loss}{{3.36}{35}{}{equation.3.5.36}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.3}Data Postprocessing}{35}{subsection.3.5.3}\protected@file@percent }
\newlabel{eq:savgol_filter}{{3.37}{35}{}{equation.3.5.37}{}}
\newlabel{eq:moving_average}{{3.38}{36}{}{equation.3.5.38}{}}
\newlabel{eq:exponential_smoothing}{{3.39}{36}{}{equation.3.5.39}{}}
\newlabel{eq:adaptive_smoothing}{{3.40}{36}{}{equation.3.5.40}{}}
\newlabel{eq:hybrid_smoothing}{{3.41}{36}{}{equation.3.5.41}{}}
\newlabel{eq:kalman_prediction_state}{{3.42}{37}{}{equation.3.5.42}{}}
\newlabel{eq:kalman_prediction_covariance}{{3.43}{37}{}{equation.3.5.43}{}}
\newlabel{eq:kalman_gain}{{3.44}{37}{}{equation.3.5.44}{}}
\newlabel{eq:kalman_update_state}{{3.45}{37}{}{equation.3.5.45}{}}
\newlabel{eq:kalman_update_covariance}{{3.46}{37}{}{equation.3.5.46}{}}
\citation{Falcon_PyTorch_Lightning_2019}
\citation{Ansel_PyTorch_2_Faster_2024}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Experiment Design}{38}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:experiment_design}{{4}{38}{Experiment Design}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Experiment Environment}{38}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Evaluation Metrics}{38}{section.4.2}\protected@file@percent }
\newlabel{eq:ade}{{4.1}{38}{}{equation.4.2.1}{}}
\newlabel{eq:fde}{{4.2}{39}{}{equation.4.2.2}{}}
\newlabel{eq:aiou}{{4.3}{39}{}{equation.4.2.3}{}}
\citation{KingBa15,FusionGRU,DBLP:journals/corr/abs-2010-10270}
\citation{FusionGRU,DBLP:journals/corr/abs-2010-10270}
\newlabel{eq:fiou}{{4.4}{40}{}{equation.4.2.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Model Training and Optimisation}{40}{section.4.3}\protected@file@percent }
\newlabel{eq:lr_update_rule}{{4.5}{40}{}{equation.4.3.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Training Configuration Parameters for the \textit  {SizPos-GRU} model - Descriptions.\relax }}{41}{table.caption.45}\protected@file@percent }
\newlabel{tab:training_parameters_description}{{4.1}{41}{Training Configuration Parameters for the \textit {SizPos-GRU} model - Descriptions.\relax }{table.caption.45}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Training Configuration Parameters for the \textit  {SizPos-GRU} model - Values.\relax }}{41}{table.caption.46}\protected@file@percent }
\newlabel{tab:training_parameters_values}{{4.2}{41}{Training Configuration Parameters for the \textit {SizPos-GRU} model - Values.\relax }{table.caption.46}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Hyperparameter Tuning Configuration - Descriptions\relax }}{42}{table.caption.47}\protected@file@percent }
\newlabel{tab:hp_tuning_descriptions}{{4.3}{42}{Hyperparameter Tuning Configuration - Descriptions\relax }{table.caption.47}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.4}{\ignorespaces Hyperparameter Tuning Configuration - Values Tested\relax }}{42}{table.caption.48}\protected@file@percent }
\newlabel{tab:hp_tuning_values}{{4.4}{42}{Hyperparameter Tuning Configuration - Values Tested\relax }{table.caption.48}{}}
\citation{kalman1960new}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Comparison Experiments}{44}{section.4.4}\protected@file@percent }
\newlabel{eq:kalman_state_transition}{{4.6}{44}{}{equation.4.4.6}{}}
\newlabel{eq:kalman_observation}{{4.7}{44}{}{equation.4.4.7}{}}
\newlabel{eq:kalman_prediction_step_state}{{4.8}{44}{}{equation.4.4.8}{}}
\newlabel{eq:kalman_prediction_step_covariance}{{4.9}{44}{}{equation.4.4.9}{}}
\newlabel{eq:kalman_update_step_gain}{{4.10}{44}{}{equation.4.4.10}{}}
\newlabel{eq:kalman_update_step_state}{{4.11}{44}{}{equation.4.4.11}{}}
\newlabel{eq:kalman_update_step_covariance}{{4.12}{44}{}{equation.4.4.12}{}}
\citation{MultipleObjectForecasting}
\newlabel{eq:cv_velocity}{{4.13}{45}{}{equation.4.4.13}{}}
\newlabel{eq:cv_future_positions}{{4.14}{45}{}{equation.4.4.14}{}}
\citation{DBLP:journals/corr/abs-2010-10270}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces PosVelAcc-LSTM Model\relax }}{46}{algorithm.1}\protected@file@percent }
\newlabel{alg:lstm_posvelacc}{{1}{46}{PosVelAcc-LSTM Model\relax }{algorithm.1}{}}
\newlabel{eq:posvelacc_lstm_loss}{{4.15}{46}{}{equation.4.4.15}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces SizPos-LSTM Model\relax }}{47}{algorithm.2}\protected@file@percent }
\newlabel{alg:lstm_sizpos}{{2}{47}{SizPos-LSTM Model\relax }{algorithm.2}{}}
\newlabel{eq:sizpos_lstm_loss}{{4.16}{47}{}{equation.4.4.16}{}}
\citation{FusionGRU}
\newlabel{eq:gru_update_gate}{{4.17}{48}{}{equation.4.4.17}{}}
\newlabel{eq:gru_reset_gate}{{4.18}{48}{}{equation.4.4.18}{}}
\newlabel{eq:gru_candidate_hidden_state}{{4.19}{48}{}{equation.4.4.19}{}}
\newlabel{eq:gru_hidden_state}{{4.20}{48}{}{equation.4.4.20}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Framework Evaluation}{49}{section.4.5}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces Object Detection and Future Position Prediction Framework\relax }}{49}{algorithm.3}\protected@file@percent }
\newlabel{alg:framework}{{3}{49}{Object Detection and Future Position Prediction Framework\relax }{algorithm.3}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Results and Discussion}{50}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:results}{{5}{50}{Results and Discussion}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Object Detection Training Results}{50}{section.5.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Performance comparison of finetuned YOLO models on the detection of Refuelling Port.\relax }}{50}{table.caption.49}\protected@file@percent }
\newlabel{tab:comparison}{{5.1}{50}{Performance comparison of finetuned YOLO models on the detection of Refuelling Port.\relax }{table.caption.49}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Experiment Results}{51}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Hyperparameter Tuning}{51}{subsection.5.2.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces Hyperparameter tuning results for trajectory prediction using \textit  {SizPos-GRU} model that leverages 30 past frames (1 sec) to predict the position 60 frames (2 sec) into the future.\relax }}{52}{table.caption.50}\protected@file@percent }
\newlabel{tab:vel-metrics-rounded}{{5.2}{52}{Hyperparameter tuning results for trajectory prediction using \textit {SizPos-GRU} model that leverages 30 past frames (1 sec) to predict the position 60 frames (2 sec) into the future.\relax }{table.caption.50}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.3}{\ignorespaces Hyperparameter tuning results for trajectory prediction using \textit  {SizPos-GRU} model that leverages 15 past frames (0.5 sec) to predict the position 30 frames (1 sec) into the future.\relax }}{52}{table.caption.51}\protected@file@percent }
\newlabel{tab:new-dataset-adjusted-header}{{5.3}{52}{Hyperparameter tuning results for trajectory prediction using \textit {SizPos-GRU} model that leverages 15 past frames (0.5 sec) to predict the position 30 frames (1 sec) into the future.\relax }{table.caption.51}{}}
\citation{MultipleObjectForecasting}
\citation{kalman1960new}
\citation{MultipleObjectForecasting}
\citation{kalman1960new}
\@writefile{lot}{\contentsline {table}{\numberline {5.4}{\ignorespaces Performance comparison of various models on trajectory prediction tasks using 30 past frames to predict 60 future frames.\relax }}{53}{table.caption.52}\protected@file@percent }
\newlabel{tab:fusion-gru-results-60frames}{{5.4}{53}{Performance comparison of various models on trajectory prediction tasks using 30 past frames to predict 60 future frames.\relax }{table.caption.52}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.5}{\ignorespaces Performance comparison of various models on trajectory prediction tasks using 15 past frames to predict 30 future frames.\relax }}{53}{table.caption.53}\protected@file@percent }
\newlabel{tab:fusion-gru-results-30frames}{{5.5}{53}{Performance comparison of various models on trajectory prediction tasks using 15 past frames to predict 30 future frames.\relax }{table.caption.53}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Framework Evaluation}{54}{subsection.5.2.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.6}{\ignorespaces Performance metrics using different smoothing filters and Linear Kalman Filter (LKF) configurations for video test\_indoor1.\relax }}{55}{table.caption.54}\protected@file@percent }
\newlabel{tab:performance_metrics_json}{{5.6}{55}{Performance metrics using different smoothing filters and Linear Kalman Filter (LKF) configurations for video test\_indoor1.\relax }{table.caption.54}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.7}{\ignorespaces Performance metrics using different smoothing filters and Linear Kalman Filter (LKF) configurations for video \textit  {video\_lab\_semiopen\_1\_\_\_\_\_\_3}.\relax }}{55}{table.caption.55}\protected@file@percent }
\newlabel{tab:performance_metrics_video_lab_semiopen_1_3}{{5.7}{55}{Performance metrics using different smoothing filters and Linear Kalman Filter (LKF) configurations for video \textit {video\_lab\_semiopen\_1\_\_\_\_\_\_3}.\relax }{table.caption.55}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.8}{\ignorespaces Performance metrics using different smoothing filters and Linear Kalman Filter (LKF) configurations for video \textit  {video\_lab\_platform\_6}.\relax }}{55}{table.caption.56}\protected@file@percent }
\newlabel{tab:performance_metrics_video_lab_platform_6}{{5.8}{55}{Performance metrics using different smoothing filters and Linear Kalman Filter (LKF) configurations for video \textit {video\_lab\_platform\_6}.\relax }{table.caption.56}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Testing Visualisation}{56}{section.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Framework Output Visualisation}{56}{subsection.5.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Visualisation of the trajectory prediction framework output for videos \textit  {video\_lab\_platform\_6}, \textit  {video\_lab\_semiopen\_1\_\_\_\_\_\_3}, and \textit  {test\_indoor1}.\relax }}{56}{figure.caption.57}\protected@file@percent }
\newlabel{fig:trajectory-prediction-test-indoor1}{{5.1}{56}{Visualisation of the trajectory prediction framework output for videos \textit {video\_lab\_platform\_6}, \textit {video\_lab\_semiopen\_1\_\_\_\_\_\_3}, and \textit {test\_indoor1}.\relax }{figure.caption.57}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Framework Output Analysis}{57}{subsection.5.3.2}\protected@file@percent }
\newlabel{fig:framework-video_lab_platform_6-1}{{5.2a}{58}{Predictions from frame 61 to 90.\relax }{figure.caption.58}{}}
\newlabel{sub@fig:framework-video_lab_platform_6-1}{{a}{58}{Predictions from frame 61 to 90.\relax }{figure.caption.58}{}}
\newlabel{fig:framework-video_lab_platform_6-2}{{5.2b}{58}{Predictions from frame 106 to 135.\relax }{figure.caption.58}{}}
\newlabel{sub@fig:framework-video_lab_platform_6-2}{{b}{58}{Predictions from frame 106 to 135.\relax }{figure.caption.58}{}}
\newlabel{fig:framework-video_lab_platform_6-3}{{5.2c}{58}{Predictions from frame 151 to 180.\relax }{figure.caption.58}{}}
\newlabel{sub@fig:framework-video_lab_platform_6-3}{{c}{58}{Predictions from frame 151 to 180.\relax }{figure.caption.58}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Framework outputs from frame 61 to 90 for video \textit  {video\_lab\_platform\_6}.\relax }}{58}{figure.caption.58}\protected@file@percent }
\newlabel{fig:framework-video_lab_platform_6}{{5.2}{58}{Framework outputs from frame 61 to 90 for video \textit {video\_lab\_platform\_6}.\relax }{figure.caption.58}{}}
\newlabel{fig:framework-video_lab_semiopen_1_3-1}{{5.3a}{59}{Predictions from frame 61 to 90.\relax }{figure.caption.59}{}}
\newlabel{sub@fig:framework-video_lab_semiopen_1_3-1}{{a}{59}{Predictions from frame 61 to 90.\relax }{figure.caption.59}{}}
\newlabel{fig:framework-video_lab_semiopen_1_3-2}{{5.3b}{59}{Predictions from frame 106 to 135.\relax }{figure.caption.59}{}}
\newlabel{sub@fig:framework-video_lab_semiopen_1_3-2}{{b}{59}{Predictions from frame 106 to 135.\relax }{figure.caption.59}{}}
\newlabel{fig:framework-video_lab_semiopen_1_3-3}{{5.3c}{59}{Predictions from frame 151 to 180.\relax }{figure.caption.59}{}}
\newlabel{sub@fig:framework-video_lab_semiopen_1_3-3}{{c}{59}{Predictions from frame 151 to 180.\relax }{figure.caption.59}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Framework outputs from frame 61 to 180 for video \textit  {video\_lab\_semiopen\_1\_\_\_\_\_\_3}.\relax }}{59}{figure.caption.59}\protected@file@percent }
\newlabel{fig:framework-video_lab_semiopen_1_3}{{5.3}{59}{Framework outputs from frame 61 to 180 for video \textit {video\_lab\_semiopen\_1\_\_\_\_\_\_3}.\relax }{figure.caption.59}{}}
\newlabel{fig:framework-test_indoor1-1}{{5.4a}{60}{Predictions from frame 61 to 90.\relax }{figure.caption.60}{}}
\newlabel{sub@fig:framework-test_indoor1-1}{{a}{60}{Predictions from frame 61 to 90.\relax }{figure.caption.60}{}}
\newlabel{fig:framework-test_indoor1-2}{{5.4b}{60}{Predictions from frame 106 to 135.\relax }{figure.caption.60}{}}
\newlabel{sub@fig:framework-test_indoor1-2}{{b}{60}{Predictions from frame 106 to 135.\relax }{figure.caption.60}{}}
\newlabel{fig:framework-test_indoor1-3}{{5.4c}{60}{Predictions from frame 151 to 180.\relax }{figure.caption.60}{}}
\newlabel{sub@fig:framework-test_indoor1-3}{{c}{60}{Predictions from frame 151 to 180.\relax }{figure.caption.60}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Framework outputs from frame 61 to 180 for video \textit  {test\_indoor1}.\relax }}{60}{figure.caption.60}\protected@file@percent }
\newlabel{fig:framework-test_indoor1}{{5.4}{60}{Framework outputs from frame 61 to 180 for video \textit {test\_indoor1}.\relax }{figure.caption.60}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusion and Future Work}{61}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:conclusion}{{6}{61}{Conclusion and Future Work}{chapter.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Summary}{61}{section.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Technological Contributions}{61}{section.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Future Work}{61}{section.6.3}\protected@file@percent }
\bibstyle{abbrvnat}
\bibdata{LaTeX,CUCitations}
\bibcite{Alahi2016}{{1}{2016}{{Alahi et~al.}}{{Alahi, Goel, Ramanathan, Robicquet, Fei-Fei, and Savarese}}}
\bibcite{Alemany2019}{{2}{2019}{{Alemany et~al.}}{{Alemany, Beltran, Perez, and Ganzfried}}}
\bibcite{Ansel_PyTorch_2_Faster_2024}{{3}{2024}{{Ansel et~al.}}{{Ansel, Yang, He, Gimelshein, Jain, Voznesensky, Bao, Bell, Berard, Burovski, Chauhan, Chourdia, Constable, Desmaison, DeVito, Ellison, Feng, Gong, Gschwind, Hirsh, Huang, Kalambarkar, Kirsch, Lazos, Lezcano, Liang, Liang, Lu, Luk, Maher, Pan, Puhrsch, Reso, Saroufim, Siraichi, Suk, Suo, Tillet, Wang, Wang, Wen, Zhang, Zhao, Zhou, Zou, Mathews, Chanan, Wu, and Chintala}}}
\bibcite{AR3P2020}{{4}{AvMC}{{}}{{(2020)}}}
\bibcite{ImageRefueling}{{5}{2019}{{Bailey}}{{}}}
\bibcite{Bemporad2023}{{6}{2023}{{Bemporad}}{{}}}
\bibcite{Bennett1991}{{7}{1991}{{Bennett et~al.}}{{Bennett, Shiu, and Leahy}}}
\bibcite{blakey2011aviation}{{8}{2011}{{Blakey et~al.}}{{Blakey, Rye, and Wilson}}}
\bibcite{DBLP:journals/corr/abs-2004-10934}{{9}{2020}{{Bochkovskiy et~al.}}{{Bochkovskiy, Wang, and Liao}}}
\bibcite{DBLP:journals/corr/abs-2010-10270}{{10}{2020}{{Bouhsain et~al.}}{{Bouhsain, Saadatnejad, and Alahi}}}
\@writefile{toc}{\contentsline {chapter}{References}{63}{chapter*.61}\protected@file@percent }
\bibcite{Burnette2010}{{11}{2010}{{Burnette}}{{}}}
\bibcite{Cai2023}{{12}{2023}{{Cai}}{{}}}
\bibcite{Carion2020}{{13}{2020}{{Carion et~al.}}{{Carion, Massa, Synnaeve, Usunier, Kirillov, and Zagoruyko}}}
\bibcite{Chen2011}{{14}{2011}{{Chen and Stettner}}{{}}}
\bibcite{SurveyVisualOT}{{15}{2022}{{Chen et~al.}}{{Chen, Wang, Zhao, Lv, and Niu}}}
\bibcite{chen2023yoloms}{{16}{2023}{{Chen et~al.}}{{Chen, Yuan, Wu, Wang, Hou, and Cheng}}}
\bibcite{SurveySmallObjectDetection}{{17}{2023}{{Cheng et~al.}}{{Cheng, Yuan, Yao, Yan, Zeng, Xie, and Han}}}
\bibcite{CostsOfUnsafetyAviation}{{18}{2010}{{Cokorilo et~al.}}{{Cokorilo, Gvozdenovic, Vasov, and Mirosavljevic}}}
\bibcite{Cummins2020}{{19}{2020}{{Cummins}}{{}}}
\bibcite{DBLP:journals/corr/DaiLHS16}{{20}{2016}{{Dai et~al.}}{{Dai, Li, He, and Sun}}}
\bibcite{Diwan2023}{{21}{2023}{{Diwan et~al.}}{{Diwan, Anirudh, and Tembhurne}}}
\bibcite{huggingface2023objectdetection}{{22}{2023}{{Face}}{{}}}
\bibcite{Falcon_PyTorch_Lightning_2019}{{23}{2019}{{Falcon and {The PyTorch Lightning team}}}{{}}}
\bibcite{CubicLSTMsVideoPrediction}{{24}{2019}{{Fan et~al.}}{{Fan, Zhu, and Yang}}}
\bibcite{Feng2018}{{25}{2018}{{Feng et~al.}}{{Feng, Li, Zhang, Sun, Meng, Guo, and Jin}}}
\bibcite{Ficken2017}{{26}{2017}{{Ficken}}{{}}}
\bibcite{DBLP:journals/corr/abs-2107-08430}{{27}{2021}{{Ge et~al.}}{{Ge, Liu, Wang, Li, and Sun}}}
\bibcite{LearnOpenCVYOLOv10}{{28}{2024}{{Ghosh}}{{}}}
\bibcite{DBLP:journals/corr/Girshick15}{{29}{2015}{{Girshick}}{{}}}
\bibcite{DBLP:journals/corr/GirshickDDM13}{{30}{2013}{{Girshick et~al.}}{{Girshick, Donahue, Darrell, and Malik}}}
\bibcite{AARBinocularVision}{{31}{2023}{{Gong et~al.}}{{Gong, Liu, Xu, Xu, He, Zhang, and Rasol}}}
\bibcite{IntelRealSense}{{32}{2024}{{Intel}}{{}}}
\bibcite{YOLOv5Release}{{33}{2022}{{Jocher}}{{}}}
\bibcite{YOLOv8}{{34}{2023}{{Jocher}}{{}}}
\bibcite{Jocher_Ultralytics_YOLO_2023}{{35}{2023}{{Jocher et~al.}}{{Jocher, Chaurasia, and Qiu}}}
\bibcite{kalman1960new}{{36}{1960}{{Kalman}}{{}}}
\bibcite{SurveyDLOD}{{37}{2022}{{Kang et~al.}}{{Kang, Tariq, Oh, and Woo}}}
\bibcite{karim_am_net2023}{{38}{2023}{{Karim et~al.}}{{Karim, Yin, and Qin}}}
\bibcite{FusionGRU}{{39}{2024}{{Karim et~al.}}{{Karim, Qin, and Wang}}}
\bibcite{KingBa15}{{40}{2015}{{Kingma and Ba}}{{}}}
\bibcite{DatasetAGR}{{41}{2023}{{Kuang et~al.}}{{Kuang, Barnes, Tang, and Jenkins}}}
\bibcite{SurveyTransformersSingleOT}{{42}{2023}{{Kugarajeevan et~al.}}{{Kugarajeevan, Kokul, Ramanan, and Fernando}}}
\bibcite{PredictionHeadMovement360Degrees}{{43}{2021}{{Lee et~al.}}{{Lee, Choi, and Lee}}}
\bibcite{FFPSpaceSystemVehicles}{{44}{2022}{{Lee et~al.}}{{Lee, Jeon, Han, and Jeong}}}
\bibcite{li2023yolov6}{{45}{2023}{{Li et~al.}}{{Li, Li, Geng, Jiang, Cheng, Zhang, Ke, Xu, and Chu}}}
\bibcite{lin2018focal}{{46}{2018}{{Lin et~al.}}{{Lin, Goyal, Girshick, He, and Dollár}}}
\bibcite{10.1007/978-981-16-5943-0_26}{{47}{2021{}}{{Liu et~al.}}{{Liu, Chen, and Liu}}}
\bibcite{OverviewCorrelationAlgoOT}{{48}{2021{}}{{Liu et~al.}}{{Liu, Liu, Srivastava, Połap, and Woźniak}}}
\bibcite{DBLP:journals/corr/LiuAESR15}{{49}{2015}{{Liu et~al.}}{{Liu, Anguelov, Erhan, Szegedy, Reed, Fu, and Berg}}}
\bibcite{malla2019nemo}{{50}{2019}{{Malla et~al.}}{{Malla, Dwivedi, Dariush, and Choi}}}
\bibcite{doi:10.1080/13669877.2013.879493}{{51}{2014}{{Olja~Čokorilo and Dell’Acqua}}{{}}}
\bibcite{HurricanesFPP}{{52}{2021}{{Oueslati et~al.}}{{Oueslati, Tahri, Limam, and Akaichi}}}
\bibcite{ExpertSystemsAGR}{{53}{2021}{{Plaza and Santos}}{{}}}
\bibcite{8378142}{{54}{2017}{{Rawat and Sawale}}{{}}}
\bibcite{DBLP:journals/corr/RedmonF16}{{55}{2016}{{Redmon and Farhadi}}{{}}}
\bibcite{DBLP:journals/corr/RedmonDGF15}{{56}{2015}{{Redmon et~al.}}{{Redmon, Divvala, Girshick, and Farhadi}}}
\bibcite{Ren2017}{{57}{2017}{{Ren et~al.}}{{Ren, He, Girshick, and Sun}}}
\bibcite{sati2019aircraft}{{58}{2019}{{Sati et~al.}}{{Sati, Singh, and Yadav}}}
\bibcite{Savitzky1964}{{59}{1964}{{Savitzky and Golay}}{{}}}
\bibcite{5888646}{{60}{2011}{{Schafer}}{{}}}
\bibcite{Schultz1986}{{61}{1986}{{Schultz}}{{}}}
\bibcite{ConvLSTM}{{62}{2015}{{Shi et~al.}}{{Shi, Chen, Wang, Yeung, Wong, and Woo}}}
\bibcite{smith1999dsp}{{63}{1999}{{Smith}}{{}}}
\bibcite{DBLP:journals/corr/SrivastavaMS15}{{64}{2015}{{Srivastava et~al.}}{{Srivastava, Mansimov, and Salakhutdinov}}}
\bibcite{MultipleObjectForecasting}{{65}{2020}{{Styles et~al.}}{{Styles, Guha, and Sanchez}}}
\bibcite{wang2024yolov10}{{66}{2024{}}{{Wang et~al.}}{{Wang, Chen, Liu, Chen, Lin, Han, and Ding}}}
\bibcite{wang2023goldyolo}{{67}{2023}{{Wang et~al.}}{{Wang, He, Nie, Guo, Liu, Han, and Wang}}}
\bibcite{wang2024yolov9}{{68}{2024{}}{{Wang et~al.}}{{Wang, Yeh, and Liao}}}
\bibcite{AARCNN}{{69}{2017}{{Wang et~al.}}{{Wang, Dong, Kong, Li, and Zhang}}}
\bibcite{SmallObjectDetectionPositonPrediction}{{70}{2021}{{Wu and Xu}}{{}}}
\bibcite{xu2022ppyoloe}{{71}{2022}{{Xu et~al.}}{{Xu, Wang, Lv, Chang, Cui, Deng, Wang, Dang, Wei, Du, and Lai}}}
\bibcite{xu2023damoyolo}{{72}{2023}{{Xu et~al.}}{{Xu, Jiang, Chen, Huang, Zhang, and Sun}}}
\bibcite{yao2019egocentric}{{73}{2019}{{Yao et~al.}}{{Yao, Xu, Choi, Crandall, Atkins, and Dariush}}}
\bibcite{ODNetworkUAVCNNTransformer}{{74}{2023}{{Ye et~al.}}{{Ye, Qin, Zhao, Gao, Deng, and Ouyang}}}
\bibcite{HybridDatasetAGRV2}{{75}{2023}{{Yildirim and Rana}}{{}}}
\bibcite{AGRPoseEstimation}{{76}{2021}{{Yildirim et~al.}}{{Yildirim, Rana, and Tang}}}
\bibcite{HybridDatasetAGRV1}{{77}{2023}{{Yildirim et~al.}}{{Yildirim, Rana, and Tang}}}
\bibcite{SurveyModernODModels}{{78}{2022}{{Zaidi et~al.}}{{Zaidi, Ansari, Aslam, Kanwal, Asghar, and Lee}}}
\bibcite{SuveyAdvancesSingleOTMethods}{{79}{2021}{{Zhang et~al.}}{{Zhang, Wang, Liu, Zhang, and Chen}}}
\bibcite{AAREKF}{{80}{2017}{{Zhong et~al.}}{{Zhong, Li, Wang, and Su}}}
\gdef \@abspage@last{79}
