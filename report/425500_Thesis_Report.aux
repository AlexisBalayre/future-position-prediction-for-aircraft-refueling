\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {chapter}{Academic Integrity Declaration}{i}{Doc-Start}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Table of Contents}{ii}{chapter*.1}\protected@file@percent }
\citation{ImageRefueling}
\citation{AAREKF}
\citation{AGRPoseEstimation}
\citation{DatasetAGR}
\citation{huggingface2023objectdetection}
\citation{SurveyDLOD}
\citation{LearnOpenCVYOLOv10}
\citation{wang2024yolov10}
\citation{LearnOpenCVYOLOv10}
\citation{huggingface2023objectdetection}
\citation{FusionGRU}
\citation{MultipleObjectForecasting}
\citation{DBLP:journals/corr/abs-2010-10270}
\@writefile{toc}{\contentsline {chapter}{List of Figures}{iv}{chapter*.2}\protected@file@percent }
\citation{wang2024yolov10}
\@writefile{toc}{\contentsline {chapter}{List of Tables}{vi}{chapter*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{List of Abbreviations}{vii}{chapter*.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{blakey2011aviation}
\citation{sati2019aircraft}
\citation{blakey2011aviation}
\citation{doi:10.1080/13669877.2013.879493,CostsOfUnsafetyAviation}
\citation{ImageRefueling}
\citation{ImageRefueling}
\citation{10.1007/978-981-16-5943-0_26}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Background and Motivation}{1}{section.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Pressure Refuelling of a Commercial Aircraft. Photo Credit: Tom Boon/Simple Flying\nobreakspace  {}\cite  {ImageRefueling}\relax }}{1}{figure.caption.5}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:pressure-refuelling}{{1.1}{1}{Pressure Refuelling of a Commercial Aircraft. Photo Credit: Tom Boon/Simple Flying~\cite {ImageRefueling}\relax }{figure.caption.5}{}}
\newlabel{fig:motion-blur-example}{{1.2a}{2}{Motion Blur Example\relax }{figure.caption.6}{}}
\newlabel{sub@fig:motion-blur-example}{{a}{2}{Motion Blur Example\relax }{figure.caption.6}{}}
\newlabel{fig:occlusion-example}{{1.2b}{2}{Occlusion Example\relax }{figure.caption.6}{}}
\newlabel{sub@fig:occlusion-example}{{b}{2}{Occlusion Example\relax }{figure.caption.6}{}}
\newlabel{fig:out-of-view-example}{{1.2c}{2}{Out-of-View Example\relax }{figure.caption.6}{}}
\newlabel{sub@fig:out-of-view-example}{{c}{2}{Out-of-View Example\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Challenges in Detecting Aircraft Refuelling Port\relax }}{2}{figure.caption.6}\protected@file@percent }
\newlabel{fig:challenges-detecting-ports}{{1.2}{2}{Challenges in Detecting Aircraft Refuelling Port\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Research Gap}{2}{section.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Aim and Objectives}{3}{section.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Technological Contributions}{3}{section.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Thesis Layout}{3}{section.1.5}\protected@file@percent }
\citation{ExpertSystemsAGR}
\citation{Schultz1986}
\citation{Bennett1991}
\citation{Burnette2010}
\citation{Ficken2017}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Literature Review}{4}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:literature-review}{{2}{4}{Literature Review}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Automated Refulling Systems in the Aviation Industry}{4}{section.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces AFRL's Automated Aircraft Ground Refueling system prototype robot (Photo Credit: AFRL/RXQ Robotics Group)\relax }}{4}{figure.caption.7}\protected@file@percent }
\newlabel{fig:test-2010}{{2.1}{4}{AFRL's Automated Aircraft Ground Refueling system prototype robot (Photo Credit: AFRL/RXQ Robotics Group)\relax }{figure.caption.7}{}}
\newlabel{fig:test-2010}{{2.1}{4}{AFRL's Automated Aircraft Ground Refueling system prototype robot (Photo Credit: AFRL/RXQ Robotics Group)\relax }{figure.caption.7}{}}
\citation{AR3P2020}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces AR3P Concept Development Prototype Robot (Photo Credit: U.S. Army)\relax }}{5}{figure.caption.8}\protected@file@percent }
\newlabel{fig:test-2017}{{2.2}{5}{AR3P Concept Development Prototype Robot (Photo Credit: U.S. Army)\relax }{figure.caption.8}{}}
\newlabel{test-2020-2}{{2.3a}{5}{AR3P Robot Approaching Detected Aircraft (Photo Credit: Stratom)\relax }{figure.caption.9}{}}
\newlabel{sub@test-2020-2}{{a}{5}{AR3P Robot Approaching Detected Aircraft (Photo Credit: Stratom)\relax }{figure.caption.9}{}}
\newlabel{test-2020-3}{{2.3b}{5}{AR3P Robot Engaging Aircraft Refueling Port (Photo Credit: Stratom)\relax }{figure.caption.9}{}}
\newlabel{sub@test-2020-3}{{b}{5}{AR3P Robot Engaging Aircraft Refueling Port (Photo Credit: Stratom)\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces AR3P Robot Hot Refueling Demonstration for S-70 Helicopter\relax }}{5}{figure.caption.9}\protected@file@percent }
\newlabel{fig:automated-refuelling-systems}{{2.3}{5}{AR3P Robot Hot Refueling Demonstration for S-70 Helicopter\relax }{figure.caption.9}{}}
\citation{AARBinocularVision,AARCNN}
\citation{AAREKF}
\citation{AAREKF}
\citation{AAREKF}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Autonomous Aerial Refueling (AAR) of X-47B Unmanned Combat Air System Demonstrator (Photo Credit: U.S. Navy)\relax }}{6}{figure.caption.10}\protected@file@percent }
\newlabel{fig:aerial-refuelling}{{2.4}{6}{Autonomous Aerial Refueling (AAR) of X-47B Unmanned Combat Air System Demonstrator (Photo Credit: U.S. Navy)\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Autonomous Air Refueling Detection System with EKF. Source: \citet  {AAREKF}\relax }}{6}{figure.caption.11}\protected@file@percent }
\newlabel{fig:detection-system-aarekf}{{2.5}{6}{Autonomous Air Refueling Detection System with EKF. Source: \citet {AAREKF}\relax }{figure.caption.11}{}}
\citation{AGRPoseEstimation}
\citation{AGRPoseEstimation}
\citation{AGRPoseEstimation}
\citation{DatasetAGR}
\citation{HybridDatasetAGRV1}
\citation{DatasetAGR}
\citation{DatasetAGR}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Kalman Filter Workflow for Pose Estimation in Autonomous Ground Refueling. Source: \citet  {AGRPoseEstimation}\relax }}{7}{figure.caption.12}\protected@file@percent }
\newlabel{fig:agr-pose-kalman}{{2.6}{7}{Kalman Filter Workflow for Pose Estimation in Autonomous Ground Refueling. Source: \citet {AGRPoseEstimation}\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces AAGR Dataset Overview. Source: \citet  {DatasetAGR}\relax }}{7}{figure.caption.13}\protected@file@percent }
\newlabel{fig:agr-dataset}{{2.7}{7}{AAGR Dataset Overview. Source: \citet {DatasetAGR}\relax }{figure.caption.13}{}}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{DBLP:journals/corr/GirshickDDM13}
\citation{DBLP:journals/corr/Girshick15}
\citation{Ren2017}
\citation{DBLP:journals/corr/DaiLHS16}
\citation{SurveyDLOD,ODNetworkUAVCNNTransformer}
\citation{DBLP:journals/corr/LiuAESR15}
\citation{DBLP:journals/corr/RedmonDGF15,DBLP:journals/corr/RedmonF16,DBLP:journals/corr/abs-2004-10934,chen2023yoloms,DBLP:journals/corr/abs-2107-08430,YOLOv5Release,li2023yolov6,YOLOv8,wang2024yolov9,xu2022ppyoloe,wang2023goldyolo,xu2023damoyolo,wang2024yolov10}
\citation{lin2018focal}
\citation{SurveyDLOD,ODNetworkUAVCNNTransformer}
\citation{SurveyDLOD}
\citation{SurveyDLOD}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Object Detection and Tracking in Computer Vision}{8}{section.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Example of outputs from an object detector\nobreakspace  {}\cite  {huggingface2023objectdetection}.\relax }}{8}{figure.caption.14}\protected@file@percent }
\newlabel{fig:object-detection}{{2.8}{8}{Example of outputs from an object detector~\cite {huggingface2023objectdetection}.\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Basic deep learning-based one-stage vs two-stage object detection model architectures\nobreakspace  {}\cite  {SurveyDLOD}.\relax }}{8}{figure.caption.15}\protected@file@percent }
\newlabel{fig:two-stage-vs-single-stage}{{2.9}{8}{Basic deep learning-based one-stage vs two-stage object detection model architectures~\cite {SurveyDLOD}.\relax }{figure.caption.15}{}}
\citation{LearnOpenCVYOLOv10}
\citation{LearnOpenCVYOLOv10}
\citation{LearnOpenCVYOLOv10}
\citation{wang2024yolov10}
\citation{wang2024yolov10}
\citation{wang2024yolov10}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces Non-Maximum Suppression (NMS) in Object Detection\nobreakspace  {}\cite  {LearnOpenCVYOLOv10}.\relax }}{9}{figure.caption.16}\protected@file@percent }
\newlabel{fig:nms}{{2.10}{9}{Non-Maximum Suppression (NMS) in Object Detection~\cite {LearnOpenCVYOLOv10}.\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces YOLOv10 Model Workflow\nobreakspace  {}\cite  {wang2024yolov10}\relax }}{9}{figure.caption.17}\protected@file@percent }
\newlabel{fig:yolov10}{{2.11}{9}{YOLOv10 Model Workflow~\cite {wang2024yolov10}\relax }{figure.caption.17}{}}
\citation{LearnOpenCVYOLOv10}
\citation{LearnOpenCVYOLOv10}
\citation{wang2024yolov10}
\citation{wang2024yolov10}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces Large-Kernel Convolution in YOLOv10\nobreakspace  {}\cite  {LearnOpenCVYOLOv10}\relax }}{10}{figure.caption.18}\protected@file@percent }
\newlabel{fig:large-kernel-yolov10}{{2.12}{10}{Large-Kernel Convolution in YOLOv10~\cite {LearnOpenCVYOLOv10}\relax }{figure.caption.18}{}}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Performance Comparison of YOLO Models with State-of-the-Art Techniques. Latency is reported using official pre-trained models. \textsuperscript  {f}Latency refers to the forward pass duration without including post-processing. \textsuperscript  {\textdagger } indicates YOLOv10 results obtained with the original one-to-many training and Non-Maximum Suppression (NMS). All metrics below exclude the use of advanced training methods like knowledge distillation or PGI to ensure fair comparisons \cite  {wang2024yolov10}.\relax }}{11}{table.caption.19}\protected@file@percent }
\newlabel{tab:comparison}{{2.1}{11}{Performance Comparison of YOLO Models with State-of-the-Art Techniques. Latency is reported using official pre-trained models. \textsuperscript {f}Latency refers to the forward pass duration without including post-processing. \textsuperscript {\textdagger } indicates YOLOv10 results obtained with the original one-to-many training and Non-Maximum Suppression (NMS). All metrics below exclude the use of advanced training methods like knowledge distillation or PGI to ensure fair comparisons \cite {wang2024yolov10}.\relax }{table.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces Intersection over Union (IoU) between a detection (in green) and ground-truth (in blue).\nobreakspace  {}\cite  {huggingface2023objectdetection}\relax }}{11}{figure.caption.20}\protected@file@percent }
\newlabel{fig:iou-metric}{{2.13}{11}{Intersection over Union (IoU) between a detection (in green) and ground-truth (in blue).~\cite {huggingface2023objectdetection}\relax }{figure.caption.20}{}}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{SurveyVisualOT}
\citation{SurveyVisualOT}
\citation{OverviewCorrelationAlgoOT,SuveyAdvancesSingleOTMethods,SurveyModernODModels}
\citation{SuveyAdvancesSingleOTMethods,SurveyModernODModels,SurveyTransformersSingleOT}
\citation{SurveyTransformersSingleOT}
\citation{SurveySmallObjectDetection,SmallObjectDetectionPositonPrediction}
\citation{SuveyAdvancesSingleOTMethods,SurveyModernODModels}
\citation{OverviewCorrelationAlgoOT,SuveyAdvancesSingleOTMethods}
\citation{FFPSpaceSystemVehicles}
\citation{Alahi2016}
\citation{FusionGRU}
\citation{FusionGRU}
\citation{FusionGRU}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Deep Learning for Spacio-Temporal Prediction}{14}{section.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.14}{\ignorespaces Comparing different Sequence models: RNN, LSTM, and GRU. Source: Colah's blog. Compiled by AIML.com\relax }}{14}{figure.caption.21}\protected@file@percent }
\newlabel{fig:lstm-rnn-gru}{{2.14}{14}{Comparing different Sequence models: RNN, LSTM, and GRU. Source: Colah's blog. Compiled by AIML.com\relax }{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.15}{\ignorespaces Fusion-GRU model architecture. Source:\nobreakspace  {}\citet  {FusionGRU}\relax }}{15}{figure.caption.22}\protected@file@percent }
\newlabel{fig:fusion-gru}{{2.15}{15}{Fusion-GRU model architecture. Source:~\citet {FusionGRU}\relax }{figure.caption.22}{}}
\citation{MultipleObjectForecasting}
\citation{MultipleObjectForecasting}
\citation{DBLP:journals/corr/abs-2010-10270}
\citation{DBLP:journals/corr/abs-2010-10270}
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces Performance Comparison of STED Model with Baseline Models on Citywalks and MOT-17 Datasets. Metrics include Average Displacement Error (ADE), Final Displacement Error (FDE), Average Intersection-over-Union (AIOU), and Final Intersection-over-Union (FIOU). The model was evaluated using 30 input frames to predict 60 future frames.\relax }}{16}{table.caption.23}\protected@file@percent }
\newlabel{tab:results}{{2.2}{16}{Performance Comparison of STED Model with Baseline Models on Citywalks and MOT-17 Datasets. Metrics include Average Displacement Error (ADE), Final Displacement Error (FDE), Average Intersection-over-Union (AIOU), and Final Intersection-over-Union (FIOU). The model was evaluated using 30 input frames to predict 60 future frames.\relax }{table.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.16}{\ignorespaces STED Model Architecture. Source:\nobreakspace  {}\citet  {MultipleObjectForecasting}\relax }}{16}{figure.caption.24}\protected@file@percent }
\newlabel{fig:sted}{{2.16}{16}{STED Model Architecture. Source:~\citet {MultipleObjectForecasting}\relax }{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.17}{\ignorespaces PV-LSTM Model Architecture. Source:\nobreakspace  {}\citet  {DBLP:journals/corr/abs-2010-10270}\relax }}{16}{figure.caption.25}\protected@file@percent }
\newlabel{fig:pv-lstm}{{2.17}{16}{PV-LSTM Model Architecture. Source:~\citet {DBLP:journals/corr/abs-2010-10270}\relax }{figure.caption.25}{}}
\citation{IntelRealSense}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Methodology}{17}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:methodology}{{3}{17}{Methodology}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Dataset Configuration}{17}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Provided Dataset Description}{17}{subsection.3.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Intel® ${\text  {RealSense}}^{\text  {TM}}$ D435 Depth Camera. Source: Intel\relax }}{17}{figure.caption.26}\protected@file@percent }
\newlabel{fig:intel-realsense-d435}{{3.1}{17}{Intel® ${\text {RealSense}}^{\text {TM}}$ D435 Depth Camera. Source: Intel\relax }{figure.caption.26}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Data Annotation}{18}{subsection.3.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Summary of Available Videos}{19}{subsection.3.1.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces \centering  Summary of available videos in the HARD dataset with their assignment.\relax }}{19}{table.caption.27}\protected@file@percent }
\newlabel{tab:video_summary}{{3.1}{19}{\centering Summary of available videos in the HARD dataset with their assignment.\relax }{table.caption.27}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.4}Initial Data Distribution}{19}{subsection.3.1.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces \centering  Distribution of frames across train, test, and validation sets for each state in the HARD dataset before balancing.\relax }}{19}{table.caption.28}\protected@file@percent }
\newlabel{tab:frame_distribution}{{3.2}{19}{\centering Distribution of frames across train, test, and validation sets for each state in the HARD dataset before balancing.\relax }{table.caption.28}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.5}Balanced Data Distribution}{20}{subsection.3.1.5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces \centering  Distribution of frames across train, test, and validation sets for each state in the HARD dataset after balancing.\relax }}{20}{table.caption.29}\protected@file@percent }
\newlabel{tab:balanced_frame_distribution}{{3.3}{20}{\centering Distribution of frames across train, test, and validation sets for each state in the HARD dataset after balancing.\relax }{table.caption.29}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.6}Example Images from the Dataset}{21}{subsection.3.1.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Annotated images of the refueling port in the CLOSED state.\relax }}{21}{figure.caption.30}\protected@file@percent }
\newlabel{fig:grid-closed-images}{{3.2}{21}{Annotated images of the refueling port in the CLOSED state.\relax }{figure.caption.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Annotated images of the refueling port in the OPEN state.\relax }}{21}{figure.caption.31}\protected@file@percent }
\newlabel{fig:grid-open-images}{{3.3}{21}{Annotated images of the refueling port in the OPEN state.\relax }{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Annotated images of the refueling port in the SEMI-OPEN state.\relax }}{21}{figure.caption.32}\protected@file@percent }
\newlabel{fig:grid-semi-open-images}{{3.4}{21}{Annotated images of the refueling port in the SEMI-OPEN state.\relax }{figure.caption.32}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.7}Sequence Model Data Preparation}{22}{subsection.3.1.7}\protected@file@percent }
\newlabel{fig:central-position-test-indoor1}{{3.5a}{22}{Central position of the refueling port over time.\relax }{figure.caption.33}{}}
\newlabel{sub@fig:central-position-test-indoor1}{{a}{22}{Central position of the refueling port over time.\relax }{figure.caption.33}{}}
\newlabel{fig:velocity-test-indoor1}{{3.5b}{22}{Velocity of the refueling port over time.\relax }{figure.caption.33}{}}
\newlabel{sub@fig:velocity-test-indoor1}{{b}{22}{Velocity of the refueling port over time.\relax }{figure.caption.33}{}}
\newlabel{fig:acceleration-test-indoor1}{{3.5c}{22}{Acceleration of the refueling port over time.\relax }{figure.caption.33}{}}
\newlabel{sub@fig:acceleration-test-indoor1}{{c}{22}{Acceleration of the refueling port over time.\relax }{figure.caption.33}{}}
\newlabel{fig:size-test-indoor1}{{3.5d}{22}{Area of the refueling port over time.\relax }{figure.caption.33}{}}
\newlabel{sub@fig:size-test-indoor1}{{d}{22}{Area of the refueling port over time.\relax }{figure.caption.33}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Temporal analysis of different metrics for the refueling port in the \textit  {test\_indoor1} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }}{22}{figure.caption.33}\protected@file@percent }
\newlabel{fig:bbox-metrics-test-indoor1}{{3.5}{22}{Temporal analysis of different metrics for the refueling port in the \textit {test\_indoor1} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }{figure.caption.33}{}}
\newlabel{fig:central-position-test-indoor1-savgol}{{3.6a}{23}{Central position of the refueling port over time.\relax }{figure.caption.34}{}}
\newlabel{sub@fig:central-position-test-indoor1-savgol}{{a}{23}{Central position of the refueling port over time.\relax }{figure.caption.34}{}}
\newlabel{fig:velocity-test-indoor1-savgol}{{3.6b}{23}{Velocity of the refueling port over time.\relax }{figure.caption.34}{}}
\newlabel{sub@fig:velocity-test-indoor1-savgol}{{b}{23}{Velocity of the refueling port over time.\relax }{figure.caption.34}{}}
\newlabel{fig:acceleration-test-indoor1-savgol}{{3.6c}{23}{Acceleration of the refueling port over time.\relax }{figure.caption.34}{}}
\newlabel{sub@fig:acceleration-test-indoor1-savgol}{{c}{23}{Acceleration of the refueling port over time.\relax }{figure.caption.34}{}}
\newlabel{fig:size-test-indoor1-savgol}{{3.6d}{23}{Area of the refueling port over time.\relax }{figure.caption.34}{}}
\newlabel{sub@fig:size-test-indoor1-savgol}{{d}{23}{Area of the refueling port over time.\relax }{figure.caption.34}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Temporal analysis of different metrics for the refueling port in the \textit  {test\_indoor1} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }}{23}{figure.caption.34}\protected@file@percent }
\newlabel{fig:bbox-metrics-test-indoor1-savgol}{{3.6}{23}{Temporal analysis of different metrics for the refueling port in the \textit {test\_indoor1} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }{figure.caption.34}{}}
\newlabel{fig:central-position-test-outdoor1}{{3.7a}{24}{Central position of the refueling port over time.\relax }{figure.caption.35}{}}
\newlabel{sub@fig:central-position-test-outdoor1}{{a}{24}{Central position of the refueling port over time.\relax }{figure.caption.35}{}}
\newlabel{fig:velocity-test-outdoor1}{{3.7b}{24}{Velocity of the refueling port over time.\relax }{figure.caption.35}{}}
\newlabel{sub@fig:velocity-test-outdoor1}{{b}{24}{Velocity of the refueling port over time.\relax }{figure.caption.35}{}}
\newlabel{fig:acceleration-test-outdoor1}{{3.7c}{24}{Acceleration of the refueling port over time.\relax }{figure.caption.35}{}}
\newlabel{sub@fig:acceleration-test-outdoor1}{{c}{24}{Acceleration of the refueling port over time.\relax }{figure.caption.35}{}}
\newlabel{fig:size-test-outdoor1}{{3.7d}{24}{Area of the refueling port over time.\relax }{figure.caption.35}{}}
\newlabel{sub@fig:size-test-outdoor1}{{d}{24}{Area of the refueling port over time.\relax }{figure.caption.35}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Temporal analysis of different metrics for the refueling port in the \textit  {test\_outdoor1} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }}{24}{figure.caption.35}\protected@file@percent }
\newlabel{fig:bbox-metrics-test-outdoor1}{{3.7}{24}{Temporal analysis of different metrics for the refueling port in the \textit {test\_outdoor1} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }{figure.caption.35}{}}
\newlabel{fig:central-position-test-outdoor1-savgol}{{3.8a}{25}{Central position of the refueling port over time.\relax }{figure.caption.36}{}}
\newlabel{sub@fig:central-position-test-outdoor1-savgol}{{a}{25}{Central position of the refueling port over time.\relax }{figure.caption.36}{}}
\newlabel{fig:velocity-test-outdoor1-savgol}{{3.8b}{25}{Velocity of the refueling port over time.\relax }{figure.caption.36}{}}
\newlabel{sub@fig:velocity-test-outdoor1-savgol}{{b}{25}{Velocity of the refueling port over time.\relax }{figure.caption.36}{}}
\newlabel{fig:acceleration-test-outdoor1-savgol}{{3.8c}{25}{Acceleration of the refueling port over time.\relax }{figure.caption.36}{}}
\newlabel{sub@fig:acceleration-test-outdoor1-savgol}{{c}{25}{Acceleration of the refueling port over time.\relax }{figure.caption.36}{}}
\newlabel{fig:size-test-outdoor1-savgol}{{3.8d}{25}{Area of the refueling port over time.\relax }{figure.caption.36}{}}
\newlabel{sub@fig:size-test-outdoor1-savgol}{{d}{25}{Area of the refueling port over time.\relax }{figure.caption.36}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Temporal analysis of different metrics for the refueling port in the \textit  {test\_outdoor1} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }}{25}{figure.caption.36}\protected@file@percent }
\newlabel{fig:bbox-metrics-test-outdoor1-savgol}{{3.8}{25}{Temporal analysis of different metrics for the refueling port in the \textit {test\_outdoor1} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }{figure.caption.36}{}}
\newlabel{fig:central-position-test-video_lab_platform_6}{{3.9a}{26}{Central position of the refueling port over time.\relax }{figure.caption.37}{}}
\newlabel{sub@fig:central-position-test-video_lab_platform_6}{{a}{26}{Central position of the refueling port over time.\relax }{figure.caption.37}{}}
\newlabel{fig:velocity-test-video_lab_platform_6}{{3.9b}{26}{Velocity of the refueling port over time.\relax }{figure.caption.37}{}}
\newlabel{sub@fig:velocity-test-video_lab_platform_6}{{b}{26}{Velocity of the refueling port over time.\relax }{figure.caption.37}{}}
\newlabel{fig:acceleration-test-video_lab_platform_6}{{3.9c}{26}{Acceleration of the refueling port over time.\relax }{figure.caption.37}{}}
\newlabel{sub@fig:acceleration-test-video_lab_platform_6}{{c}{26}{Acceleration of the refueling port over time.\relax }{figure.caption.37}{}}
\newlabel{fig:size-test-video_lab_platform_6}{{3.9d}{26}{Area of the refueling port over time.\relax }{figure.caption.37}{}}
\newlabel{sub@fig:size-test-video_lab_platform_6}{{d}{26}{Area of the refueling port over time.\relax }{figure.caption.37}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces Temporal analysis of different metrics for the refueling port in the \textit  {test\_video\_lab\_platform\_6} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }}{26}{figure.caption.37}\protected@file@percent }
\newlabel{fig:bbox-metrics-test-video_lab_platform_6}{{3.9}{26}{Temporal analysis of different metrics for the refueling port in the \textit {test\_video\_lab\_platform\_6} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }{figure.caption.37}{}}
\newlabel{fig:central-position-test-video_lab_platform_6-savgol}{{3.10a}{27}{Central position of the refueling port over time.\relax }{figure.caption.38}{}}
\newlabel{sub@fig:central-position-test-video_lab_platform_6-savgol}{{a}{27}{Central position of the refueling port over time.\relax }{figure.caption.38}{}}
\newlabel{fig:velocity-test-video_lab_platform_6-savgol}{{3.10b}{27}{Velocity of the refueling port over time.\relax }{figure.caption.38}{}}
\newlabel{sub@fig:velocity-test-video_lab_platform_6-savgol}{{b}{27}{Velocity of the refueling port over time.\relax }{figure.caption.38}{}}
\newlabel{fig:acceleration-test-video_lab_platform_6-savgol}{{3.10c}{27}{Acceleration of the refueling port over time.\relax }{figure.caption.38}{}}
\newlabel{sub@fig:acceleration-test-video_lab_platform_6-savgol}{{c}{27}{Acceleration of the refueling port over time.\relax }{figure.caption.38}{}}
\newlabel{fig:size-test-video_lab_platform_6-savgol}{{3.10d}{27}{Area of the refueling port over time.\relax }{figure.caption.38}{}}
\newlabel{sub@fig:size-test-video_lab_platform_6-savgol}{{d}{27}{Area of the refueling port over time.\relax }{figure.caption.38}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces Temporal analysis of different metrics for the refueling port in the \textit  {test\_video\_lab\_platform\_6} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }}{27}{figure.caption.38}\protected@file@percent }
\newlabel{fig:bbox-metrics-test-video_lab_platform_6-savgol}{{3.10}{27}{Temporal analysis of different metrics for the refueling port in the \textit {test\_video\_lab\_platform\_6} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }{figure.caption.38}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Framework Design}{28}{section.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces Framework Workflow\relax }}{28}{figure.caption.39}\protected@file@percent }
\newlabel{fig:framework-workflow}{{3.11}{28}{Framework Workflow\relax }{figure.caption.39}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Object Detection Model Fine-tuning}{29}{section.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Sequence Model Design}{29}{section.3.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces SizPos-GRU Model Architecture\relax }}{29}{figure.caption.40}\protected@file@percent }
\newlabel{fig:sizpos-gru}{{3.12}{29}{SizPos-GRU Model Architecture\relax }{figure.caption.40}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Input Representation}{29}{subsection.3.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Encoders}{30}{subsection.3.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.13}{\ignorespaces SizPos-GRU Encoder Architecture. The input sequence \( \mathbf  {X} = \{\mathbf  {x}_1, \mathbf  {x}_2, \dots  , \mathbf  {x}_T\} \) represents either the spatial dynamics vector (\(\mathbf  {P}\)) or the dimensional attributes vector (\(\mathbf  {D}\)). This sequence is processed through multiple GRU layers, producing a sequence of hidden states \( H = \{h_1, h_2, \dots  , h_T\} \) and a final hidden state \( h_T \) that encapsulates the temporal dependencies in the input sequence.\relax }}{31}{figure.caption.41}\protected@file@percent }
\newlabel{fig:sizpos-gru-encoder}{{3.13}{31}{SizPos-GRU Encoder Architecture. The input sequence \( \mathbf {X} = \{\mathbf {x}_1, \mathbf {x}_2, \dots , \mathbf {x}_T\} \) represents either the spatial dynamics vector (\(\mathbf {P}\)) or the dimensional attributes vector (\(\mathbf {D}\)). This sequence is processed through multiple GRU layers, producing a sequence of hidden states \( H = \{h_1, h_2, \dots , h_T\} \) and a final hidden state \( h_T \) that encapsulates the temporal dependencies in the input sequence.\relax }{figure.caption.41}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Hidden State Fusion}{31}{subsection.3.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.4}Decoders}{32}{subsection.3.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.4.1}Position Decoder}{32}{subsubsection.3.4.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.4.2}Size Decoder}{32}{subsubsection.3.4.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.4.3}Self-Attention Mechanism}{33}{subsubsection.3.4.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.4.4}Final Output}{33}{subsubsection.3.4.4.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.14}{\ignorespaces SizPos-GRU Decoder Architecture. This architecture illustrates the decoding process where the input sequence \( \mathbf  {x}_t \) and the last hidden state \( h_{t-1} \) are processed through multiple GRU layers to generate the next hidden state \( h_t \). The sequence of hidden states \( H = \{h_1, h_2, \dots  , h_t\} \) is then passed through a self-attention mechanism, which calculates attention scores and weights. The weighted sum of hidden states is combined with linear and non-linear transformations, including dropout and ReLU activation functions, to produce the final output \( \mathbf  {x}_{t+1} \). This output is used for predicting the next time step in the sequence, continuing the process iteratively for future predictions.\relax }}{34}{figure.caption.42}\protected@file@percent }
\newlabel{fig:sizpos-gru-decoder}{{3.14}{34}{SizPos-GRU Decoder Architecture. This architecture illustrates the decoding process where the input sequence \( \mathbf {x}_t \) and the last hidden state \( h_{t-1} \) are processed through multiple GRU layers to generate the next hidden state \( h_t \). The sequence of hidden states \( H = \{h_1, h_2, \dots , h_t\} \) is then passed through a self-attention mechanism, which calculates attention scores and weights. The weighted sum of hidden states is combined with linear and non-linear transformations, including dropout and ReLU activation functions, to produce the final output \( \mathbf {x}_{t+1} \). This output is used for predicting the next time step in the sequence, continuing the process iteratively for future predictions.\relax }{figure.caption.42}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Algorithm Design}{34}{section.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Data Augmentation Strategy}{34}{section.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.1}Sequence Reversal}{34}{subsection.3.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.2}Camera Movement Simulation}{34}{subsection.3.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.3}Zoom Simulation}{35}{subsection.3.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.4}Detection Inaccuracy Simulation}{35}{subsection.3.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.5}Implementation Details}{35}{subsection.3.6.5}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Experiment Design}{36}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:experiment_design}{{4}{36}{Experiment Design}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Experiment Environment}{36}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Comparison Experiments}{36}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Evaluation Metrics}{36}{section.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Results and Discussion}{38}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:results}{{5}{38}{Results and Discussion}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Object Detection Training Results}{38}{section.5.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Comparison of YOLO Models\relax }}{38}{table.caption.43}\protected@file@percent }
\newlabel{tab:comparison}{{5.1}{38}{Comparison of YOLO Models\relax }{table.caption.43}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Summary}{38}{subsection.5.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Data Description}{39}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Experiment Results}{39}{section.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Testing Visualisation}{39}{section.5.4}\protected@file@percent }
\bibstyle{abbrvnat}
\bibdata{LaTeX,CUCitations}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusion and Future Work}{40}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:conclusion}{{6}{40}{Conclusion and Future Work}{chapter.6}{}}
\bibcite{Alahi2016}{{1}{2016}{{Alahi et~al.}}{{Alahi, Goel, Ramanathan, Robicquet, Fei-Fei, and Savarese}}}
\bibcite{AR3P2020}{{2}{AvMC}{{}}{{(2020)}}}
\bibcite{ImageRefueling}{{3}{2019}{{Bailey}}{{}}}
\bibcite{Bennett1991}{{4}{1991}{{Bennett et~al.}}{{Bennett, Shiu, and Leahy}}}
\bibcite{blakey2011aviation}{{5}{2011}{{Blakey et~al.}}{{Blakey, Rye, and Wilson}}}
\bibcite{DBLP:journals/corr/abs-2004-10934}{{6}{2020}{{Bochkovskiy et~al.}}{{Bochkovskiy, Wang, and Liao}}}
\bibcite{DBLP:journals/corr/abs-2010-10270}{{7}{2020}{{Bouhsain et~al.}}{{Bouhsain, Saadatnejad, and Alahi}}}
\bibcite{Burnette2010}{{8}{2010}{{Burnette}}{{}}}
\bibcite{SurveyVisualOT}{{9}{2022}{{Chen et~al.}}{{Chen, Wang, Zhao, Lv, and Niu}}}
\bibcite{chen2023yoloms}{{10}{2023}{{Chen et~al.}}{{Chen, Yuan, Wu, Wang, Hou, and Cheng}}}
\bibcite{SurveySmallObjectDetection}{{11}{2023}{{Cheng et~al.}}{{Cheng, Yuan, Yao, Yan, Zeng, Xie, and Han}}}
\bibcite{CostsOfUnsafetyAviation}{{12}{2010}{{Cokorilo et~al.}}{{Cokorilo, Gvozdenovic, Vasov, and Mirosavljevic}}}
\@writefile{toc}{\contentsline {chapter}{References}{41}{chapter*.44}\protected@file@percent }
\bibcite{DBLP:journals/corr/DaiLHS16}{{13}{2016}{{Dai et~al.}}{{Dai, Li, He, and Sun}}}
\bibcite{huggingface2023objectdetection}{{14}{2023}{{Face}}{{}}}
\bibcite{Ficken2017}{{15}{2017}{{Ficken}}{{}}}
\bibcite{DBLP:journals/corr/abs-2107-08430}{{16}{2021}{{Ge et~al.}}{{Ge, Liu, Wang, Li, and Sun}}}
\bibcite{LearnOpenCVYOLOv10}{{17}{2024}{{Ghosh}}{{}}}
\bibcite{DBLP:journals/corr/Girshick15}{{18}{2015}{{Girshick}}{{}}}
\bibcite{DBLP:journals/corr/GirshickDDM13}{{19}{2013}{{Girshick et~al.}}{{Girshick, Donahue, Darrell, and Malik}}}
\bibcite{AARBinocularVision}{{20}{2023}{{Gong et~al.}}{{Gong, Liu, Xu, Xu, He, Zhang, and Rasol}}}
\bibcite{IntelRealSense}{{21}{2024}{{Intel}}{{}}}
\bibcite{YOLOv5Release}{{22}{2022}{{Jocher}}{{}}}
\bibcite{YOLOv8}{{23}{2023}{{Jocher}}{{}}}
\bibcite{SurveyDLOD}{{24}{2022}{{Kang et~al.}}{{Kang, Tariq, Oh, and Woo}}}
\bibcite{FusionGRU}{{25}{2024}{{Karim et~al.}}{{Karim, Qin, and Wang}}}
\bibcite{DatasetAGR}{{26}{2023}{{Kuang et~al.}}{{Kuang, Barnes, Tang, and Jenkins}}}
\bibcite{SurveyTransformersSingleOT}{{27}{2023}{{Kugarajeevan et~al.}}{{Kugarajeevan, Kokul, Ramanan, and Fernando}}}
\bibcite{FFPSpaceSystemVehicles}{{28}{2022}{{Lee et~al.}}{{Lee, Jeon, Han, and Jeong}}}
\bibcite{li2023yolov6}{{29}{2023}{{Li et~al.}}{{Li, Li, Geng, Jiang, Cheng, Zhang, Ke, Xu, and Chu}}}
\bibcite{lin2018focal}{{30}{2018}{{Lin et~al.}}{{Lin, Goyal, Girshick, He, and Dollár}}}
\bibcite{10.1007/978-981-16-5943-0_26}{{31}{2021{}}{{Liu et~al.}}{{Liu, Chen, and Liu}}}
\bibcite{OverviewCorrelationAlgoOT}{{32}{2021{}}{{Liu et~al.}}{{Liu, Liu, Srivastava, Połap, and Woźniak}}}
\bibcite{DBLP:journals/corr/LiuAESR15}{{33}{2015}{{Liu et~al.}}{{Liu, Anguelov, Erhan, Szegedy, Reed, Fu, and Berg}}}
\bibcite{doi:10.1080/13669877.2013.879493}{{34}{2014}{{Olja~Čokorilo and Dell’Acqua}}{{}}}
\bibcite{ExpertSystemsAGR}{{35}{2021}{{Plaza and Santos}}{{}}}
\bibcite{DBLP:journals/corr/RedmonF16}{{36}{2016}{{Redmon and Farhadi}}{{}}}
\bibcite{DBLP:journals/corr/RedmonDGF15}{{37}{2015}{{Redmon et~al.}}{{Redmon, Divvala, Girshick, and Farhadi}}}
\bibcite{Ren2017}{{38}{2017}{{Ren et~al.}}{{Ren, He, Girshick, and Sun}}}
\bibcite{sati2019aircraft}{{39}{2019}{{Sati et~al.}}{{Sati, Singh, and Yadav}}}
\bibcite{Schultz1986}{{40}{1986}{{Schultz}}{{}}}
\bibcite{MultipleObjectForecasting}{{41}{2020}{{Styles et~al.}}{{Styles, Guha, and Sanchez}}}
\bibcite{wang2024yolov10}{{42}{2024{}}{{Wang et~al.}}{{Wang, Chen, Liu, Chen, Lin, Han, and Ding}}}
\bibcite{wang2023goldyolo}{{43}{2023}{{Wang et~al.}}{{Wang, He, Nie, Guo, Liu, Han, and Wang}}}
\bibcite{wang2024yolov9}{{44}{2024{}}{{Wang et~al.}}{{Wang, Yeh, and Liao}}}
\bibcite{AARCNN}{{45}{2017}{{Wang et~al.}}{{Wang, Dong, Kong, Li, and Zhang}}}
\bibcite{SmallObjectDetectionPositonPrediction}{{46}{2021}{{Wu and Xu}}{{}}}
\bibcite{xu2022ppyoloe}{{47}{2022}{{Xu et~al.}}{{Xu, Wang, Lv, Chang, Cui, Deng, Wang, Dang, Wei, Du, and Lai}}}
\bibcite{xu2023damoyolo}{{48}{2023}{{Xu et~al.}}{{Xu, Jiang, Chen, Huang, Zhang, and Sun}}}
\bibcite{ODNetworkUAVCNNTransformer}{{49}{2023}{{Ye et~al.}}{{Ye, Qin, Zhao, Gao, Deng, and Ouyang}}}
\bibcite{AGRPoseEstimation}{{50}{2021}{{Yildirim et~al.}}{{Yildirim, Rana, and Tang}}}
\bibcite{HybridDatasetAGRV1}{{51}{2023}{{Yildirim et~al.}}{{Yildirim, Rana, and Tang}}}
\bibcite{SurveyModernODModels}{{52}{2022}{{Zaidi et~al.}}{{Zaidi, Ansari, Aslam, Kanwal, Asghar, and Lee}}}
\bibcite{SuveyAdvancesSingleOTMethods}{{53}{2021}{{Zhang et~al.}}{{Zhang, Wang, Liu, Zhang, and Chen}}}
\bibcite{AAREKF}{{54}{2017}{{Zhong et~al.}}{{Zhong, Li, Wang, and Su}}}
\gdef \@abspage@last{53}
