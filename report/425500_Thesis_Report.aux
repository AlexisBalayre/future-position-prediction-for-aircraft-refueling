\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {chapter}{Academic Integrity Declaration}{i}{Doc-Start}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Table of Contents}{ii}{chapter*.1}\protected@file@percent }
\citation{ImageRefueling}
\citation{AAREKF}
\citation{AGRPoseEstimation}
\citation{DatasetAGR}
\citation{huggingface2023objectdetection}
\citation{SurveyDLOD}
\citation{LearnOpenCVYOLOv10}
\citation{wang2024yolov10}
\citation{LearnOpenCVYOLOv10}
\citation{huggingface2023objectdetection}
\citation{MultipleObjectForecasting}
\citation{DBLP:journals/corr/abs-2010-10270}
\citation{FusionGRU}
\@writefile{toc}{\contentsline {chapter}{List of Figures}{iv}{chapter*.2}\protected@file@percent }
\citation{wang2024yolov10}
\@writefile{toc}{\contentsline {chapter}{List of Tables}{vi}{chapter*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{List of Abbreviations}{vii}{chapter*.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{blakey2011aviation}
\citation{sati2019aircraft}
\citation{blakey2011aviation}
\citation{doi:10.1080/13669877.2013.879493,CostsOfUnsafetyAviation}
\citation{ImageRefueling}
\citation{ImageRefueling}
\citation{10.1007/978-981-16-5943-0_26}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Background and Motivation}{1}{section.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Pressure Refuelling of a Commercial Aircraft. Photo Credit: Tom Boon/Simple Flying\nobreakspace  {}\cite  {ImageRefueling}\relax }}{1}{figure.caption.5}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:pressure-refuelling}{{1.1}{1}{Pressure Refuelling of a Commercial Aircraft. Photo Credit: Tom Boon/Simple Flying~\cite {ImageRefueling}\relax }{figure.caption.5}{}}
\newlabel{fig:motion-blur-example}{{1.2a}{2}{Motion Blur Example\relax }{figure.caption.6}{}}
\newlabel{sub@fig:motion-blur-example}{{a}{2}{Motion Blur Example\relax }{figure.caption.6}{}}
\newlabel{fig:occlusion-example}{{1.2b}{2}{Occlusion Example\relax }{figure.caption.6}{}}
\newlabel{sub@fig:occlusion-example}{{b}{2}{Occlusion Example\relax }{figure.caption.6}{}}
\newlabel{fig:out-of-view-example}{{1.2c}{2}{Out-of-View Example\relax }{figure.caption.6}{}}
\newlabel{sub@fig:out-of-view-example}{{c}{2}{Out-of-View Example\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Challenges in Detecting Aircraft Refuelling Port\relax }}{2}{figure.caption.6}\protected@file@percent }
\newlabel{fig:challenges-detecting-ports}{{1.2}{2}{Challenges in Detecting Aircraft Refuelling Port\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Research Gap}{2}{section.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Aim and Objectives}{3}{section.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Technological Contributions}{3}{section.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Thesis Layout}{3}{section.1.5}\protected@file@percent }
\citation{ExpertSystemsAGR}
\citation{Schultz1986}
\citation{Bennett1991}
\citation{Burnette2010}
\citation{Ficken2017}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Literature Review}{4}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:literature-review}{{2}{4}{Literature Review}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Automated Refulling Systems in the Aviation Industry}{4}{section.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces AFRL's Automated Aircraft Ground Refueling system prototype robot (Photo Credit: AFRL/RXQ Robotics Group)\relax }}{4}{figure.caption.7}\protected@file@percent }
\newlabel{fig:test-2010}{{2.1}{4}{AFRL's Automated Aircraft Ground Refueling system prototype robot (Photo Credit: AFRL/RXQ Robotics Group)\relax }{figure.caption.7}{}}
\newlabel{fig:test-2010}{{2.1}{4}{AFRL's Automated Aircraft Ground Refueling system prototype robot (Photo Credit: AFRL/RXQ Robotics Group)\relax }{figure.caption.7}{}}
\citation{AR3P2020}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces AR3P Concept Development Prototype Robot (Photo Credit: U.S. Army)\relax }}{5}{figure.caption.8}\protected@file@percent }
\newlabel{fig:test-2017}{{2.2}{5}{AR3P Concept Development Prototype Robot (Photo Credit: U.S. Army)\relax }{figure.caption.8}{}}
\newlabel{test-2020-2}{{2.3a}{5}{AR3P Robot Approaching Detected Aircraft (Photo Credit: Stratom)\relax }{figure.caption.9}{}}
\newlabel{sub@test-2020-2}{{a}{5}{AR3P Robot Approaching Detected Aircraft (Photo Credit: Stratom)\relax }{figure.caption.9}{}}
\newlabel{test-2020-3}{{2.3b}{5}{AR3P Robot Engaging Aircraft Refueling Port (Photo Credit: Stratom)\relax }{figure.caption.9}{}}
\newlabel{sub@test-2020-3}{{b}{5}{AR3P Robot Engaging Aircraft Refueling Port (Photo Credit: Stratom)\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces AR3P Robot Hot Refueling Demonstration for S-70 Helicopter\relax }}{5}{figure.caption.9}\protected@file@percent }
\newlabel{fig:automated-refuelling-systems}{{2.3}{5}{AR3P Robot Hot Refueling Demonstration for S-70 Helicopter\relax }{figure.caption.9}{}}
\citation{AARBinocularVision,AARCNN}
\citation{AAREKF}
\citation{AAREKF}
\citation{AAREKF}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Autonomous Aerial Refueling (AAR) of X-47B Unmanned Combat Air System Demonstrator (Photo Credit: U.S. Navy)\relax }}{6}{figure.caption.10}\protected@file@percent }
\newlabel{fig:aerial-refuelling}{{2.4}{6}{Autonomous Aerial Refueling (AAR) of X-47B Unmanned Combat Air System Demonstrator (Photo Credit: U.S. Navy)\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Autonomous Air Refueling Detection System with EKF. Source: \citet  {AAREKF}\relax }}{6}{figure.caption.11}\protected@file@percent }
\newlabel{fig:detection-system-aarekf}{{2.5}{6}{Autonomous Air Refueling Detection System with EKF. Source: \citet {AAREKF}\relax }{figure.caption.11}{}}
\citation{AGRPoseEstimation}
\citation{AGRPoseEstimation}
\citation{AGRPoseEstimation}
\citation{DatasetAGR}
\citation{HybridDatasetAGRV1}
\citation{DatasetAGR}
\citation{DatasetAGR}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Kalman Filter Workflow for Pose Estimation in Autonomous Ground Refueling. Source: \citet  {AGRPoseEstimation}\relax }}{7}{figure.caption.12}\protected@file@percent }
\newlabel{fig:agr-pose-kalman}{{2.6}{7}{Kalman Filter Workflow for Pose Estimation in Autonomous Ground Refueling. Source: \citet {AGRPoseEstimation}\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces AAGR Dataset Overview. Source: \citet  {DatasetAGR}\relax }}{7}{figure.caption.13}\protected@file@percent }
\newlabel{fig:agr-dataset}{{2.7}{7}{AAGR Dataset Overview. Source: \citet {DatasetAGR}\relax }{figure.caption.13}{}}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{DBLP:journals/corr/GirshickDDM13}
\citation{DBLP:journals/corr/Girshick15}
\citation{Ren2017}
\citation{DBLP:journals/corr/DaiLHS16}
\citation{SurveyDLOD,ODNetworkUAVCNNTransformer}
\citation{DBLP:journals/corr/LiuAESR15}
\citation{DBLP:journals/corr/RedmonDGF15,DBLP:journals/corr/RedmonF16,DBLP:journals/corr/abs-2004-10934,chen2023yoloms,DBLP:journals/corr/abs-2107-08430,YOLOv5Release,li2023yolov6,YOLOv8,wang2024yolov9,xu2022ppyoloe,wang2023goldyolo,xu2023damoyolo,wang2024yolov10}
\citation{lin2018focal}
\citation{SurveyDLOD,ODNetworkUAVCNNTransformer}
\citation{SurveyDLOD}
\citation{SurveyDLOD}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Object Detection and Tracking in Computer Vision}{8}{section.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Example of outputs from an object detector\nobreakspace  {}\cite  {huggingface2023objectdetection}.\relax }}{8}{figure.caption.14}\protected@file@percent }
\newlabel{fig:object-detection}{{2.8}{8}{Example of outputs from an object detector~\cite {huggingface2023objectdetection}.\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Basic deep learning-based one-stage vs two-stage object detection model architectures\nobreakspace  {}\cite  {SurveyDLOD}.\relax }}{8}{figure.caption.15}\protected@file@percent }
\newlabel{fig:two-stage-vs-single-stage}{{2.9}{8}{Basic deep learning-based one-stage vs two-stage object detection model architectures~\cite {SurveyDLOD}.\relax }{figure.caption.15}{}}
\citation{LearnOpenCVYOLOv10}
\citation{LearnOpenCVYOLOv10}
\citation{LearnOpenCVYOLOv10}
\citation{wang2024yolov10}
\citation{wang2024yolov10}
\citation{wang2024yolov10}
\citation{wang2024yolov10,LearnOpenCVYOLOv10}
\citation{LearnOpenCVYOLOv10}
\citation{LearnOpenCVYOLOv10}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces Non-Maximum Suppression (NMS) in Object Detection\nobreakspace  {}\cite  {LearnOpenCVYOLOv10}.\relax }}{9}{figure.caption.16}\protected@file@percent }
\newlabel{fig:nms}{{2.10}{9}{Non-Maximum Suppression (NMS) in Object Detection~\cite {LearnOpenCVYOLOv10}.\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces YOLOv10 Model Workflow\nobreakspace  {}\cite  {wang2024yolov10}\relax }}{9}{figure.caption.17}\protected@file@percent }
\newlabel{fig:yolov10}{{2.11}{9}{YOLOv10 Model Workflow~\cite {wang2024yolov10}\relax }{figure.caption.17}{}}
\citation{wang2024yolov10}
\citation{wang2024yolov10}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces Large-Kernel Convolution in YOLOv10\nobreakspace  {}\cite  {LearnOpenCVYOLOv10}\relax }}{10}{figure.caption.18}\protected@file@percent }
\newlabel{fig:large-kernel-yolov10}{{2.12}{10}{Large-Kernel Convolution in YOLOv10~\cite {LearnOpenCVYOLOv10}\relax }{figure.caption.18}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Performance Comparison of YOLO Models with State-of-the-Art Techniques. Latency is reported using official pre-trained models. \textsuperscript  {f}Latency refers to the forward pass duration without including post-processing. \textsuperscript  {\textdagger } indicates YOLOv10 results obtained with the original one-to-many training and Non-Maximum Suppression (NMS)\nobreakspace  {}\cite  {wang2024yolov10}.\relax }}{10}{table.caption.19}\protected@file@percent }
\newlabel{tab:yolov10-benchmarks}{{2.1}{10}{Performance Comparison of YOLO Models with State-of-the-Art Techniques. Latency is reported using official pre-trained models. \textsuperscript {f}Latency refers to the forward pass duration without including post-processing. \textsuperscript {\textdagger } indicates YOLOv10 results obtained with the original one-to-many training and Non-Maximum Suppression (NMS)~\cite {wang2024yolov10}.\relax }{table.caption.19}{}}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{SurveyVisualOT}
\citation{SurveyVisualOT}
\citation{OverviewCorrelationAlgoOT,SuveyAdvancesSingleOTMethods,SurveyModernODModels}
\citation{SuveyAdvancesSingleOTMethods,SurveyModernODModels,SurveyTransformersSingleOT}
\citation{SurveyTransformersSingleOT}
\citation{SurveySmallObjectDetection,SmallObjectDetectionPositonPrediction}
\citation{SuveyAdvancesSingleOTMethods,SurveyModernODModels}
\citation{OverviewCorrelationAlgoOT,SuveyAdvancesSingleOTMethods}
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces Intersection over Union (IoU) between a detection (in green) and ground-truth (in blue).\nobreakspace  {}\cite  {huggingface2023objectdetection}\relax }}{11}{figure.caption.20}\protected@file@percent }
\newlabel{fig:iou-metric}{{2.13}{11}{Intersection over Union (IoU) between a detection (in green) and ground-truth (in blue).~\cite {huggingface2023objectdetection}\relax }{figure.caption.20}{}}
\citation{FFPSpaceSystemVehicles}
\citation{Alahi2016}
\citation{MultipleObjectForecasting}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Deep Learning for Spacio-Temporal Prediction}{13}{section.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.14}{\ignorespaces Comparing different Sequence models: RNN, LSTM, and GRU. Source: Colah's blog. Compiled by AIML.com\relax }}{13}{figure.caption.21}\protected@file@percent }
\newlabel{fig:lstm-rnn-gru}{{2.14}{13}{Comparing different Sequence models: RNN, LSTM, and GRU. Source: Colah's blog. Compiled by AIML.com\relax }{figure.caption.21}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.0.1}STED Model}{13}{subsubsection.2.3.0.1}\protected@file@percent }
\citation{MultipleObjectForecasting}
\citation{MultipleObjectForecasting}
\citation{MultipleObjectForecasting}
\citation{MultipleObjectForecasting}
\citation{MultipleObjectForecasting}
\citation{DBLP:journals/corr/abs-2010-10270}
\@writefile{lof}{\contentsline {figure}{\numberline {2.15}{\ignorespaces STED Model Architecture. Source:\nobreakspace  {}\citet  {MultipleObjectForecasting}\relax }}{14}{figure.caption.22}\protected@file@percent }
\newlabel{fig:sted}{{2.15}{14}{STED Model Architecture. Source:~\citet {MultipleObjectForecasting}\relax }{figure.caption.22}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces Comparison of the performance of STED with baseline models on the Citywalks dataset. Metrics include Average Displacement Error (ADE), Final Displacement Error (FDE), Average Intersection-over-Union (AIOU), and Final Intersection-over-Union (FIOU). The model was evaluated using 1 second of input frames to predict 2 seconds of future frames.\relax }}{14}{table.caption.23}\protected@file@percent }
\newlabel{tab:sted-results}{{2.2}{14}{Comparison of the performance of STED with baseline models on the Citywalks dataset. Metrics include Average Displacement Error (ADE), Final Displacement Error (FDE), Average Intersection-over-Union (AIOU), and Final Intersection-over-Union (FIOU). The model was evaluated using 1 second of input frames to predict 2 seconds of future frames.\relax }{table.caption.23}{}}
\citation{DBLP:journals/corr/abs-2010-10270}
\citation{DBLP:journals/corr/abs-2010-10270}
\citation{DBLP:journals/corr/abs-2010-10270}
\citation{DBLP:journals/corr/abs-2010-10270}
\citation{DBLP:journals/corr/abs-2010-10270}
\citation{DBLP:journals/corr/abs-2010-10270}
\@writefile{lof}{\contentsline {figure}{\numberline {2.16}{\ignorespaces PV-LSTM Model Architecture. Source:\nobreakspace  {}\citet  {DBLP:journals/corr/abs-2010-10270}\relax }}{15}{figure.caption.24}\protected@file@percent }
\newlabel{fig:pv-lstm}{{2.16}{15}{PV-LSTM Model Architecture. Source:~\citet {DBLP:journals/corr/abs-2010-10270}\relax }{figure.caption.24}{}}
\citation{FusionGRU}
\citation{FusionGRU}
\citation{FusionGRU}
\@writefile{lot}{\contentsline {table}{\numberline {2.3}{\ignorespaces Comparison of the performance of PV-LSTM with baseline models on the Citywalks dataset. Metrics include Average Displacement Error (ADE), Final Displacement Error (FDE), and Average Intersection-over-Union (AIOU). The model was evaluated using 1 second of input frames to predict 2 seconds of future frames.\relax }}{16}{table.caption.25}\protected@file@percent }
\newlabel{tab:pv-lstm-results}{{2.3}{16}{Comparison of the performance of PV-LSTM with baseline models on the Citywalks dataset. Metrics include Average Displacement Error (ADE), Final Displacement Error (FDE), and Average Intersection-over-Union (AIOU). The model was evaluated using 1 second of input frames to predict 2 seconds of future frames.\relax }{table.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.17}{\ignorespaces Fusion-GRU model architecture. Source:\nobreakspace  {}\citet  {FusionGRU}\relax }}{16}{figure.caption.26}\protected@file@percent }
\newlabel{fig:fusion-gru}{{2.17}{16}{Fusion-GRU model architecture. Source:~\citet {FusionGRU}\relax }{figure.caption.26}{}}
\citation{IntelRealSense}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Methodology}{17}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:methodology}{{3}{17}{Methodology}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Dataset Configuration}{17}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Provided Dataset Description}{17}{subsection.3.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Intel® ${\text  {RealSense}}^{\text  {TM}}$ D435 Depth Camera. Source: Intel\relax }}{17}{figure.caption.27}\protected@file@percent }
\newlabel{fig:intel-realsense-d435}{{3.1}{17}{Intel® ${\text {RealSense}}^{\text {TM}}$ D435 Depth Camera. Source: Intel\relax }{figure.caption.27}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Data Annotation}{18}{subsection.3.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Summary of Available Videos}{19}{subsection.3.1.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces \centering  Summary of available videos in the HARD dataset with their assignment.\relax }}{19}{table.caption.28}\protected@file@percent }
\newlabel{tab:video_summary}{{3.1}{19}{\centering Summary of available videos in the HARD dataset with their assignment.\relax }{table.caption.28}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.4}Initial Data Distribution}{19}{subsection.3.1.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces \centering  Distribution of frames across train, test, and validation sets for each state in the HARD dataset before balancing.\relax }}{19}{table.caption.29}\protected@file@percent }
\newlabel{tab:frame_distribution}{{3.2}{19}{\centering Distribution of frames across train, test, and validation sets for each state in the HARD dataset before balancing.\relax }{table.caption.29}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.5}Balanced Data Distribution}{20}{subsection.3.1.5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces \centering  Distribution of frames across train, test, and validation sets for each state in the HARD dataset after balancing.\relax }}{20}{table.caption.30}\protected@file@percent }
\newlabel{tab:balanced_frame_distribution}{{3.3}{20}{\centering Distribution of frames across train, test, and validation sets for each state in the HARD dataset after balancing.\relax }{table.caption.30}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.6}Example Images from the Dataset}{21}{subsection.3.1.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Annotated images of the refueling port in the CLOSED state.\relax }}{21}{figure.caption.31}\protected@file@percent }
\newlabel{fig:grid-closed-images}{{3.2}{21}{Annotated images of the refueling port in the CLOSED state.\relax }{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Annotated images of the refueling port in the OPEN state.\relax }}{21}{figure.caption.32}\protected@file@percent }
\newlabel{fig:grid-open-images}{{3.3}{21}{Annotated images of the refueling port in the OPEN state.\relax }{figure.caption.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Annotated images of the refueling port in the SEMI-OPEN state.\relax }}{21}{figure.caption.33}\protected@file@percent }
\newlabel{fig:grid-semi-open-images}{{3.4}{21}{Annotated images of the refueling port in the SEMI-OPEN state.\relax }{figure.caption.33}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.7}Sequence Model Data Preparation}{22}{subsection.3.1.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Framework Design}{22}{section.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Framework Workflow\relax }}{22}{figure.caption.34}\protected@file@percent }
\newlabel{fig:framework-workflow}{{3.5}{22}{Framework Workflow\relax }{figure.caption.34}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Object Detection Model Fine-tuning}{23}{section.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Sequence Model Design}{23}{section.3.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces SizPos-GRU Model Architecture\relax }}{23}{figure.caption.35}\protected@file@percent }
\newlabel{fig:sizpos-gru}{{3.6}{23}{SizPos-GRU Model Architecture\relax }{figure.caption.35}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Input Representation}{23}{subsection.3.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Encoders}{24}{subsection.3.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces SizPos-GRU Encoder Architecture. The input sequence \( \mathbf  {X} = \{\mathbf  {x}_1, \mathbf  {x}_2, \dots  , \mathbf  {x}_T\} \) represents either the spatial dynamics vector (\(\mathbf  {P}\)) or the dimensional attributes vector (\(\mathbf  {D}\)). This sequence is processed through multiple GRU layers, producing a sequence of hidden states \( H = \{h_1, h_2, \dots  , h_T\} \) and a final hidden state \( h_T \) that encapsulates the temporal dependencies in the input sequence.\relax }}{25}{figure.caption.36}\protected@file@percent }
\newlabel{fig:sizpos-gru-encoder}{{3.7}{25}{SizPos-GRU Encoder Architecture. The input sequence \( \mathbf {X} = \{\mathbf {x}_1, \mathbf {x}_2, \dots , \mathbf {x}_T\} \) represents either the spatial dynamics vector (\(\mathbf {P}\)) or the dimensional attributes vector (\(\mathbf {D}\)). This sequence is processed through multiple GRU layers, producing a sequence of hidden states \( H = \{h_1, h_2, \dots , h_T\} \) and a final hidden state \( h_T \) that encapsulates the temporal dependencies in the input sequence.\relax }{figure.caption.36}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Hidden State Fusion}{25}{subsection.3.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.4}Decoders}{26}{subsection.3.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.4.1}Position Decoder}{26}{subsubsection.3.4.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.4.2}Size Decoder}{26}{subsubsection.3.4.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.4.3}Self-Attention Mechanism}{27}{subsubsection.3.4.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.4.4}Final Output}{27}{subsubsection.3.4.4.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces SizPos-GRU Decoder Architecture. This architecture illustrates the decoding process where the input sequence \( \mathbf  {x}_t \) and the last hidden state \( h_{t-1} \) are processed through multiple GRU layers to generate the next hidden state \( h_t \). The sequence of hidden states \( H = \{h_1, h_2, \dots  , h_t\} \) is then passed through a self-attention mechanism, which calculates attention scores and weights. The weighted sum of hidden states is combined with linear and non-linear transformations, including dropout and ReLU activation functions, to produce the final output \( \mathbf  {x}_{t+1} \). This output is used for predicting the next time step in the sequence, continuing the process iteratively for future predictions.\relax }}{28}{figure.caption.37}\protected@file@percent }
\newlabel{fig:sizpos-gru-decoder}{{3.8}{28}{SizPos-GRU Decoder Architecture. This architecture illustrates the decoding process where the input sequence \( \mathbf {x}_t \) and the last hidden state \( h_{t-1} \) are processed through multiple GRU layers to generate the next hidden state \( h_t \). The sequence of hidden states \( H = \{h_1, h_2, \dots , h_t\} \) is then passed through a self-attention mechanism, which calculates attention scores and weights. The weighted sum of hidden states is combined with linear and non-linear transformations, including dropout and ReLU activation functions, to produce the final output \( \mathbf {x}_{t+1} \). This output is used for predicting the next time step in the sequence, continuing the process iteratively for future predictions.\relax }{figure.caption.37}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Algorithm Design}{28}{section.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Data Augmentation Strategy}{28}{section.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.1}Sequence Reversal}{28}{subsection.3.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.2}Camera Movement Simulation}{28}{subsection.3.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.3}Zoom Simulation}{29}{subsection.3.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.4}Detection Inaccuracy Simulation}{29}{subsection.3.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.5}Implementation Details}{29}{subsection.3.6.5}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Experiment Design}{30}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:experiment_design}{{4}{30}{Experiment Design}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Experiment Environment}{30}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Comparison Experiments}{30}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Evaluation Metrics}{30}{section.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Results and Discussion}{32}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:results}{{5}{32}{Results and Discussion}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Object Detection Training Results}{32}{section.5.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Comparison of YOLO Models\relax }}{32}{table.caption.38}\protected@file@percent }
\newlabel{tab:comparison}{{5.1}{32}{Comparison of YOLO Models\relax }{table.caption.38}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Summary}{32}{subsection.5.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Data Description}{33}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Experiment Results}{33}{section.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Testing Visualisation}{33}{section.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusion and Future Work}{34}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:conclusion}{{6}{34}{Conclusion and Future Work}{chapter.6}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Source Codes}{35}{appendix.A}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{fig:central-position-test-indoor1}{{A.1a}{36}{Central position of the refueling port over time.\relax }{figure.caption.39}{}}
\newlabel{sub@fig:central-position-test-indoor1}{{a}{36}{Central position of the refueling port over time.\relax }{figure.caption.39}{}}
\newlabel{fig:velocity-test-indoor1}{{A.1b}{36}{Velocity of the refueling port over time.\relax }{figure.caption.39}{}}
\newlabel{sub@fig:velocity-test-indoor1}{{b}{36}{Velocity of the refueling port over time.\relax }{figure.caption.39}{}}
\newlabel{fig:acceleration-test-indoor1}{{A.1c}{36}{Acceleration of the refueling port over time.\relax }{figure.caption.39}{}}
\newlabel{sub@fig:acceleration-test-indoor1}{{c}{36}{Acceleration of the refueling port over time.\relax }{figure.caption.39}{}}
\newlabel{fig:size-test-indoor1}{{A.1d}{36}{Area of the refueling port over time.\relax }{figure.caption.39}{}}
\newlabel{sub@fig:size-test-indoor1}{{d}{36}{Area of the refueling port over time.\relax }{figure.caption.39}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.1}{\ignorespaces Temporal analysis of different metrics for the refueling port in the \textit  {test\_indoor1} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }}{36}{figure.caption.39}\protected@file@percent }
\newlabel{fig:bbox-metrics-test-indoor1}{{A.1}{36}{Temporal analysis of different metrics for the refueling port in the \textit {test\_indoor1} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }{figure.caption.39}{}}
\newlabel{fig:central-position-test-indoor1-savgol}{{A.2a}{37}{Central position of the refueling port over time.\relax }{figure.caption.40}{}}
\newlabel{sub@fig:central-position-test-indoor1-savgol}{{a}{37}{Central position of the refueling port over time.\relax }{figure.caption.40}{}}
\newlabel{fig:velocity-test-indoor1-savgol}{{A.2b}{37}{Velocity of the refueling port over time.\relax }{figure.caption.40}{}}
\newlabel{sub@fig:velocity-test-indoor1-savgol}{{b}{37}{Velocity of the refueling port over time.\relax }{figure.caption.40}{}}
\newlabel{fig:acceleration-test-indoor1-savgol}{{A.2c}{37}{Acceleration of the refueling port over time.\relax }{figure.caption.40}{}}
\newlabel{sub@fig:acceleration-test-indoor1-savgol}{{c}{37}{Acceleration of the refueling port over time.\relax }{figure.caption.40}{}}
\newlabel{fig:size-test-indoor1-savgol}{{A.2d}{37}{Area of the refueling port over time.\relax }{figure.caption.40}{}}
\newlabel{sub@fig:size-test-indoor1-savgol}{{d}{37}{Area of the refueling port over time.\relax }{figure.caption.40}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.2}{\ignorespaces Temporal analysis of different metrics for the refueling port in the \textit  {test\_indoor1} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }}{37}{figure.caption.40}\protected@file@percent }
\newlabel{fig:bbox-metrics-test-indoor1-savgol}{{A.2}{37}{Temporal analysis of different metrics for the refueling port in the \textit {test\_indoor1} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }{figure.caption.40}{}}
\newlabel{fig:central-position-test-outdoor1}{{A.3a}{38}{Central position of the refueling port over time.\relax }{figure.caption.41}{}}
\newlabel{sub@fig:central-position-test-outdoor1}{{a}{38}{Central position of the refueling port over time.\relax }{figure.caption.41}{}}
\newlabel{fig:velocity-test-outdoor1}{{A.3b}{38}{Velocity of the refueling port over time.\relax }{figure.caption.41}{}}
\newlabel{sub@fig:velocity-test-outdoor1}{{b}{38}{Velocity of the refueling port over time.\relax }{figure.caption.41}{}}
\newlabel{fig:acceleration-test-outdoor1}{{A.3c}{38}{Acceleration of the refueling port over time.\relax }{figure.caption.41}{}}
\newlabel{sub@fig:acceleration-test-outdoor1}{{c}{38}{Acceleration of the refueling port over time.\relax }{figure.caption.41}{}}
\newlabel{fig:size-test-outdoor1}{{A.3d}{38}{Area of the refueling port over time.\relax }{figure.caption.41}{}}
\newlabel{sub@fig:size-test-outdoor1}{{d}{38}{Area of the refueling port over time.\relax }{figure.caption.41}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.3}{\ignorespaces Temporal analysis of different metrics for the refueling port in the \textit  {test\_outdoor1} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }}{38}{figure.caption.41}\protected@file@percent }
\newlabel{fig:bbox-metrics-test-outdoor1}{{A.3}{38}{Temporal analysis of different metrics for the refueling port in the \textit {test\_outdoor1} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }{figure.caption.41}{}}
\newlabel{fig:central-position-test-outdoor1-savgol}{{A.4a}{39}{Central position of the refueling port over time.\relax }{figure.caption.42}{}}
\newlabel{sub@fig:central-position-test-outdoor1-savgol}{{a}{39}{Central position of the refueling port over time.\relax }{figure.caption.42}{}}
\newlabel{fig:velocity-test-outdoor1-savgol}{{A.4b}{39}{Velocity of the refueling port over time.\relax }{figure.caption.42}{}}
\newlabel{sub@fig:velocity-test-outdoor1-savgol}{{b}{39}{Velocity of the refueling port over time.\relax }{figure.caption.42}{}}
\newlabel{fig:acceleration-test-outdoor1-savgol}{{A.4c}{39}{Acceleration of the refueling port over time.\relax }{figure.caption.42}{}}
\newlabel{sub@fig:acceleration-test-outdoor1-savgol}{{c}{39}{Acceleration of the refueling port over time.\relax }{figure.caption.42}{}}
\newlabel{fig:size-test-outdoor1-savgol}{{A.4d}{39}{Area of the refueling port over time.\relax }{figure.caption.42}{}}
\newlabel{sub@fig:size-test-outdoor1-savgol}{{d}{39}{Area of the refueling port over time.\relax }{figure.caption.42}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.4}{\ignorespaces Temporal analysis of different metrics for the refueling port in the \textit  {test\_outdoor1} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }}{39}{figure.caption.42}\protected@file@percent }
\newlabel{fig:bbox-metrics-test-outdoor1-savgol}{{A.4}{39}{Temporal analysis of different metrics for the refueling port in the \textit {test\_outdoor1} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }{figure.caption.42}{}}
\newlabel{fig:central-position-test-video_lab_platform_6}{{A.5a}{40}{Central position of the refueling port over time.\relax }{figure.caption.43}{}}
\newlabel{sub@fig:central-position-test-video_lab_platform_6}{{a}{40}{Central position of the refueling port over time.\relax }{figure.caption.43}{}}
\newlabel{fig:velocity-test-video_lab_platform_6}{{A.5b}{40}{Velocity of the refueling port over time.\relax }{figure.caption.43}{}}
\newlabel{sub@fig:velocity-test-video_lab_platform_6}{{b}{40}{Velocity of the refueling port over time.\relax }{figure.caption.43}{}}
\newlabel{fig:acceleration-test-video_lab_platform_6}{{A.5c}{40}{Acceleration of the refueling port over time.\relax }{figure.caption.43}{}}
\newlabel{sub@fig:acceleration-test-video_lab_platform_6}{{c}{40}{Acceleration of the refueling port over time.\relax }{figure.caption.43}{}}
\newlabel{fig:size-test-video_lab_platform_6}{{A.5d}{40}{Area of the refueling port over time.\relax }{figure.caption.43}{}}
\newlabel{sub@fig:size-test-video_lab_platform_6}{{d}{40}{Area of the refueling port over time.\relax }{figure.caption.43}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.5}{\ignorespaces Temporal analysis of different metrics for the refueling port in the \textit  {test\_video\_lab\_platform\_6} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }}{40}{figure.caption.43}\protected@file@percent }
\newlabel{fig:bbox-metrics-test-video_lab_platform_6}{{A.5}{40}{Temporal analysis of different metrics for the refueling port in the \textit {test\_video\_lab\_platform\_6} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }{figure.caption.43}{}}
\bibstyle{abbrvnat}
\bibdata{LaTeX,CUCitations}
\newlabel{fig:central-position-test-video_lab_platform_6-savgol}{{A.6a}{41}{Central position of the refueling port over time.\relax }{figure.caption.44}{}}
\newlabel{sub@fig:central-position-test-video_lab_platform_6-savgol}{{a}{41}{Central position of the refueling port over time.\relax }{figure.caption.44}{}}
\newlabel{fig:velocity-test-video_lab_platform_6-savgol}{{A.6b}{41}{Velocity of the refueling port over time.\relax }{figure.caption.44}{}}
\newlabel{sub@fig:velocity-test-video_lab_platform_6-savgol}{{b}{41}{Velocity of the refueling port over time.\relax }{figure.caption.44}{}}
\newlabel{fig:acceleration-test-video_lab_platform_6-savgol}{{A.6c}{41}{Acceleration of the refueling port over time.\relax }{figure.caption.44}{}}
\newlabel{sub@fig:acceleration-test-video_lab_platform_6-savgol}{{c}{41}{Acceleration of the refueling port over time.\relax }{figure.caption.44}{}}
\newlabel{fig:size-test-video_lab_platform_6-savgol}{{A.6d}{41}{Area of the refueling port over time.\relax }{figure.caption.44}{}}
\newlabel{sub@fig:size-test-video_lab_platform_6-savgol}{{d}{41}{Area of the refueling port over time.\relax }{figure.caption.44}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.6}{\ignorespaces Temporal analysis of different metrics for the refueling port in the \textit  {test\_video\_lab\_platform\_6} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }}{41}{figure.caption.44}\protected@file@percent }
\newlabel{fig:bbox-metrics-test-video_lab_platform_6-savgol}{{A.6}{41}{Temporal analysis of different metrics for the refueling port in the \textit {test\_video\_lab\_platform\_6} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }{figure.caption.44}{}}
\bibcite{Alahi2016}{{1}{2016}{{Alahi et~al.}}{{Alahi, Goel, Ramanathan, Robicquet, Fei-Fei, and Savarese}}}
\bibcite{AR3P2020}{{2}{AvMC}{{}}{{(2020)}}}
\bibcite{ImageRefueling}{{3}{2019}{{Bailey}}{{}}}
\bibcite{Bennett1991}{{4}{1991}{{Bennett et~al.}}{{Bennett, Shiu, and Leahy}}}
\bibcite{blakey2011aviation}{{5}{2011}{{Blakey et~al.}}{{Blakey, Rye, and Wilson}}}
\bibcite{DBLP:journals/corr/abs-2004-10934}{{6}{2020}{{Bochkovskiy et~al.}}{{Bochkovskiy, Wang, and Liao}}}
\bibcite{DBLP:journals/corr/abs-2010-10270}{{7}{2020}{{Bouhsain et~al.}}{{Bouhsain, Saadatnejad, and Alahi}}}
\bibcite{Burnette2010}{{8}{2010}{{Burnette}}{{}}}
\bibcite{SurveyVisualOT}{{9}{2022}{{Chen et~al.}}{{Chen, Wang, Zhao, Lv, and Niu}}}
\bibcite{chen2023yoloms}{{10}{2023}{{Chen et~al.}}{{Chen, Yuan, Wu, Wang, Hou, and Cheng}}}
\bibcite{SurveySmallObjectDetection}{{11}{2023}{{Cheng et~al.}}{{Cheng, Yuan, Yao, Yan, Zeng, Xie, and Han}}}
\bibcite{CostsOfUnsafetyAviation}{{12}{2010}{{Cokorilo et~al.}}{{Cokorilo, Gvozdenovic, Vasov, and Mirosavljevic}}}
\@writefile{toc}{\contentsline {chapter}{References}{42}{appendix*.45}\protected@file@percent }
\bibcite{DBLP:journals/corr/DaiLHS16}{{13}{2016}{{Dai et~al.}}{{Dai, Li, He, and Sun}}}
\bibcite{huggingface2023objectdetection}{{14}{2023}{{Face}}{{}}}
\bibcite{Ficken2017}{{15}{2017}{{Ficken}}{{}}}
\bibcite{DBLP:journals/corr/abs-2107-08430}{{16}{2021}{{Ge et~al.}}{{Ge, Liu, Wang, Li, and Sun}}}
\bibcite{LearnOpenCVYOLOv10}{{17}{2024}{{Ghosh}}{{}}}
\bibcite{DBLP:journals/corr/Girshick15}{{18}{2015}{{Girshick}}{{}}}
\bibcite{DBLP:journals/corr/GirshickDDM13}{{19}{2013}{{Girshick et~al.}}{{Girshick, Donahue, Darrell, and Malik}}}
\bibcite{AARBinocularVision}{{20}{2023}{{Gong et~al.}}{{Gong, Liu, Xu, Xu, He, Zhang, and Rasol}}}
\bibcite{IntelRealSense}{{21}{2024}{{Intel}}{{}}}
\bibcite{YOLOv5Release}{{22}{2022}{{Jocher}}{{}}}
\bibcite{YOLOv8}{{23}{2023}{{Jocher}}{{}}}
\bibcite{SurveyDLOD}{{24}{2022}{{Kang et~al.}}{{Kang, Tariq, Oh, and Woo}}}
\bibcite{FusionGRU}{{25}{2024}{{Karim et~al.}}{{Karim, Qin, and Wang}}}
\bibcite{DatasetAGR}{{26}{2023}{{Kuang et~al.}}{{Kuang, Barnes, Tang, and Jenkins}}}
\bibcite{SurveyTransformersSingleOT}{{27}{2023}{{Kugarajeevan et~al.}}{{Kugarajeevan, Kokul, Ramanan, and Fernando}}}
\bibcite{FFPSpaceSystemVehicles}{{28}{2022}{{Lee et~al.}}{{Lee, Jeon, Han, and Jeong}}}
\bibcite{li2023yolov6}{{29}{2023}{{Li et~al.}}{{Li, Li, Geng, Jiang, Cheng, Zhang, Ke, Xu, and Chu}}}
\bibcite{lin2018focal}{{30}{2018}{{Lin et~al.}}{{Lin, Goyal, Girshick, He, and Dollár}}}
\bibcite{10.1007/978-981-16-5943-0_26}{{31}{2021{}}{{Liu et~al.}}{{Liu, Chen, and Liu}}}
\bibcite{OverviewCorrelationAlgoOT}{{32}{2021{}}{{Liu et~al.}}{{Liu, Liu, Srivastava, Połap, and Woźniak}}}
\bibcite{DBLP:journals/corr/LiuAESR15}{{33}{2015}{{Liu et~al.}}{{Liu, Anguelov, Erhan, Szegedy, Reed, Fu, and Berg}}}
\bibcite{doi:10.1080/13669877.2013.879493}{{34}{2014}{{Olja~Čokorilo and Dell’Acqua}}{{}}}
\bibcite{ExpertSystemsAGR}{{35}{2021}{{Plaza and Santos}}{{}}}
\bibcite{DBLP:journals/corr/RedmonF16}{{36}{2016}{{Redmon and Farhadi}}{{}}}
\bibcite{DBLP:journals/corr/RedmonDGF15}{{37}{2015}{{Redmon et~al.}}{{Redmon, Divvala, Girshick, and Farhadi}}}
\bibcite{Ren2017}{{38}{2017}{{Ren et~al.}}{{Ren, He, Girshick, and Sun}}}
\bibcite{sati2019aircraft}{{39}{2019}{{Sati et~al.}}{{Sati, Singh, and Yadav}}}
\bibcite{Schultz1986}{{40}{1986}{{Schultz}}{{}}}
\bibcite{MultipleObjectForecasting}{{41}{2020}{{Styles et~al.}}{{Styles, Guha, and Sanchez}}}
\bibcite{wang2024yolov10}{{42}{2024{}}{{Wang et~al.}}{{Wang, Chen, Liu, Chen, Lin, Han, and Ding}}}
\bibcite{wang2023goldyolo}{{43}{2023}{{Wang et~al.}}{{Wang, He, Nie, Guo, Liu, Han, and Wang}}}
\bibcite{wang2024yolov9}{{44}{2024{}}{{Wang et~al.}}{{Wang, Yeh, and Liao}}}
\bibcite{AARCNN}{{45}{2017}{{Wang et~al.}}{{Wang, Dong, Kong, Li, and Zhang}}}
\bibcite{SmallObjectDetectionPositonPrediction}{{46}{2021}{{Wu and Xu}}{{}}}
\bibcite{xu2022ppyoloe}{{47}{2022}{{Xu et~al.}}{{Xu, Wang, Lv, Chang, Cui, Deng, Wang, Dang, Wei, Du, and Lai}}}
\bibcite{xu2023damoyolo}{{48}{2023}{{Xu et~al.}}{{Xu, Jiang, Chen, Huang, Zhang, and Sun}}}
\bibcite{ODNetworkUAVCNNTransformer}{{49}{2023}{{Ye et~al.}}{{Ye, Qin, Zhao, Gao, Deng, and Ouyang}}}
\bibcite{AGRPoseEstimation}{{50}{2021}{{Yildirim et~al.}}{{Yildirim, Rana, and Tang}}}
\bibcite{HybridDatasetAGRV1}{{51}{2023}{{Yildirim et~al.}}{{Yildirim, Rana, and Tang}}}
\bibcite{SurveyModernODModels}{{52}{2022}{{Zaidi et~al.}}{{Zaidi, Ansari, Aslam, Kanwal, Asghar, and Lee}}}
\bibcite{SuveyAdvancesSingleOTMethods}{{53}{2021}{{Zhang et~al.}}{{Zhang, Wang, Liu, Zhang, and Chen}}}
\bibcite{AAREKF}{{54}{2017}{{Zhong et~al.}}{{Zhong, Li, Wang, and Su}}}
\gdef \@abspage@last{54}
