\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {chapter}{Academic Integrity Declaration}{i}{Doc-Start}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Abstract}{ii}{chapter*.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{Acknowledgements}{iii}{chapter*.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{Table of Contents}{iv}{chapter*.3}\protected@file@percent }
\citation{ImageRefueling}
\citation{AAREKF}
\citation{AGRPoseEstimation}
\citation{DatasetAGR}
\citation{huggingface2023objectdetection}
\citation{SurveyDLOD}
\citation{LearnOpenCVYOLOv10}
\citation{wang2024yolov10}
\citation{LearnOpenCVYOLOv10}
\citation{huggingface2023objectdetection}
\citation{MultipleObjectForecasting}
\citation{DBLP:journals/corr/abs-2010-10270}
\citation{FusionGRU}
\@writefile{toc}{\contentsline {chapter}{List of Figures}{vi}{chapter*.4}\protected@file@percent }
\citation{wang2024yolov10}
\@writefile{toc}{\contentsline {chapter}{List of Tables}{viii}{chapter*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{List of Abbreviations}{ix}{chapter*.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{blakey2011aviation}
\citation{sati2019aircraft}
\citation{blakey2011aviation}
\citation{doi:10.1080/13669877.2013.879493,CostsOfUnsafetyAviation}
\citation{ImageRefueling}
\citation{ImageRefueling}
\citation{10.1007/978-981-16-5943-0_26}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Background and Motivation}{1}{section.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Pressure Refuelling of a Commercial Aircraft. Photo Credit: Tom Boon/Simple Flying\nobreakspace  {}\cite  {ImageRefueling}\relax }}{1}{figure.caption.7}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:pressure-refuelling}{{1.1}{1}{Pressure Refuelling of a Commercial Aircraft. Photo Credit: Tom Boon/Simple Flying~\cite {ImageRefueling}\relax }{figure.caption.7}{}}
\newlabel{fig:motion-blur-example}{{1.2a}{2}{Motion Blur Example\relax }{figure.caption.8}{}}
\newlabel{sub@fig:motion-blur-example}{{a}{2}{Motion Blur Example\relax }{figure.caption.8}{}}
\newlabel{fig:occlusion-example}{{1.2b}{2}{Occlusion Example\relax }{figure.caption.8}{}}
\newlabel{sub@fig:occlusion-example}{{b}{2}{Occlusion Example\relax }{figure.caption.8}{}}
\newlabel{fig:out-of-view-example}{{1.2c}{2}{Out-of-View Example\relax }{figure.caption.8}{}}
\newlabel{sub@fig:out-of-view-example}{{c}{2}{Out-of-View Example\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Challenges in Detecting Aircraft Refuelling Port\relax }}{2}{figure.caption.8}\protected@file@percent }
\newlabel{fig:challenges-detecting-ports}{{1.2}{2}{Challenges in Detecting Aircraft Refuelling Port\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Research Gap}{2}{section.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Aim and Objectives}{3}{section.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Technological Contributions}{3}{section.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Thesis Layout}{3}{section.1.5}\protected@file@percent }
\citation{ExpertSystemsAGR}
\citation{Schultz1986}
\citation{Bennett1991}
\citation{Burnette2010}
\citation{Ficken2017}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Literature Review}{4}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:literature-review}{{2}{4}{Literature Review}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Automated Refulling Systems in the Aviation Industry}{4}{section.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces AFRL's Automated Aircraft Ground Refueling system prototype robot (Photo Credit: AFRL/RXQ Robotics Group)\relax }}{4}{figure.caption.9}\protected@file@percent }
\newlabel{fig:test-2010}{{2.1}{4}{AFRL's Automated Aircraft Ground Refueling system prototype robot (Photo Credit: AFRL/RXQ Robotics Group)\relax }{figure.caption.9}{}}
\newlabel{fig:test-2010}{{2.1}{4}{AFRL's Automated Aircraft Ground Refueling system prototype robot (Photo Credit: AFRL/RXQ Robotics Group)\relax }{figure.caption.9}{}}
\citation{AR3P2020}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces AR3P Concept Development Prototype Robot (Photo Credit: U.S. Army)\relax }}{5}{figure.caption.10}\protected@file@percent }
\newlabel{fig:test-2017}{{2.2}{5}{AR3P Concept Development Prototype Robot (Photo Credit: U.S. Army)\relax }{figure.caption.10}{}}
\newlabel{test-2020-2}{{2.3a}{5}{AR3P Robot Approaching Detected Aircraft (Photo Credit: Stratom)\relax }{figure.caption.11}{}}
\newlabel{sub@test-2020-2}{{a}{5}{AR3P Robot Approaching Detected Aircraft (Photo Credit: Stratom)\relax }{figure.caption.11}{}}
\newlabel{test-2020-3}{{2.3b}{5}{AR3P Robot Engaging Aircraft Refueling Port (Photo Credit: Stratom)\relax }{figure.caption.11}{}}
\newlabel{sub@test-2020-3}{{b}{5}{AR3P Robot Engaging Aircraft Refueling Port (Photo Credit: Stratom)\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces AR3P Robot Hot Refueling Demonstration for S-70 Helicopter\relax }}{5}{figure.caption.11}\protected@file@percent }
\newlabel{fig:automated-refuelling-systems}{{2.3}{5}{AR3P Robot Hot Refueling Demonstration for S-70 Helicopter\relax }{figure.caption.11}{}}
\citation{AARBinocularVision,AARCNN}
\citation{AAREKF}
\citation{AAREKF}
\citation{AAREKF}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Autonomous Aerial Refueling (AAR) of X-47B Unmanned Combat Air System Demonstrator (Photo Credit: U.S. Navy)\relax }}{6}{figure.caption.12}\protected@file@percent }
\newlabel{fig:aerial-refuelling}{{2.4}{6}{Autonomous Aerial Refueling (AAR) of X-47B Unmanned Combat Air System Demonstrator (Photo Credit: U.S. Navy)\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Autonomous Air Refueling Detection System with EKF. Source: \citet  {AAREKF}\relax }}{6}{figure.caption.13}\protected@file@percent }
\newlabel{fig:detection-system-aarekf}{{2.5}{6}{Autonomous Air Refueling Detection System with EKF. Source: \citet {AAREKF}\relax }{figure.caption.13}{}}
\citation{AGRPoseEstimation}
\citation{AGRPoseEstimation}
\citation{AGRPoseEstimation}
\citation{DatasetAGR}
\citation{HybridDatasetAGRV1}
\citation{DatasetAGR}
\citation{DatasetAGR}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Kalman Filter Workflow for Pose Estimation in Autonomous Ground Refueling. Source: \citet  {AGRPoseEstimation}\relax }}{7}{figure.caption.14}\protected@file@percent }
\newlabel{fig:agr-pose-kalman}{{2.6}{7}{Kalman Filter Workflow for Pose Estimation in Autonomous Ground Refueling. Source: \citet {AGRPoseEstimation}\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces AAGR Dataset Overview. Source: \citet  {DatasetAGR}\relax }}{7}{figure.caption.15}\protected@file@percent }
\newlabel{fig:agr-dataset}{{2.7}{7}{AAGR Dataset Overview. Source: \citet {DatasetAGR}\relax }{figure.caption.15}{}}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{DBLP:journals/corr/GirshickDDM13}
\citation{DBLP:journals/corr/Girshick15}
\citation{Ren2017}
\citation{DBLP:journals/corr/DaiLHS16}
\citation{SurveyDLOD,ODNetworkUAVCNNTransformer}
\citation{DBLP:journals/corr/LiuAESR15}
\citation{DBLP:journals/corr/RedmonDGF15,DBLP:journals/corr/RedmonF16,DBLP:journals/corr/abs-2004-10934,chen2023yoloms,DBLP:journals/corr/abs-2107-08430,YOLOv5Release,li2023yolov6,YOLOv8,wang2024yolov9,xu2022ppyoloe,wang2023goldyolo,xu2023damoyolo,wang2024yolov10}
\citation{lin2018focal}
\citation{SurveyDLOD,ODNetworkUAVCNNTransformer}
\citation{SurveyDLOD}
\citation{SurveyDLOD}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Object Detection and Tracking in Computer Vision}{8}{section.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Example of outputs from an object detector\nobreakspace  {}\cite  {huggingface2023objectdetection}.\relax }}{8}{figure.caption.16}\protected@file@percent }
\newlabel{fig:object-detection}{{2.8}{8}{Example of outputs from an object detector~\cite {huggingface2023objectdetection}.\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Basic deep learning-based one-stage vs two-stage object detection model architectures\nobreakspace  {}\cite  {SurveyDLOD}.\relax }}{8}{figure.caption.17}\protected@file@percent }
\newlabel{fig:two-stage-vs-single-stage}{{2.9}{8}{Basic deep learning-based one-stage vs two-stage object detection model architectures~\cite {SurveyDLOD}.\relax }{figure.caption.17}{}}
\citation{LearnOpenCVYOLOv10}
\citation{LearnOpenCVYOLOv10}
\citation{LearnOpenCVYOLOv10}
\citation{wang2024yolov10}
\citation{wang2024yolov10}
\citation{wang2024yolov10}
\citation{wang2024yolov10,LearnOpenCVYOLOv10}
\citation{LearnOpenCVYOLOv10}
\citation{LearnOpenCVYOLOv10}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces Non-Maximum Suppression (NMS) in Object Detection\nobreakspace  {}\cite  {LearnOpenCVYOLOv10}.\relax }}{9}{figure.caption.18}\protected@file@percent }
\newlabel{fig:nms}{{2.10}{9}{Non-Maximum Suppression (NMS) in Object Detection~\cite {LearnOpenCVYOLOv10}.\relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces YOLOv10 Model Workflow\nobreakspace  {}\cite  {wang2024yolov10}\relax }}{9}{figure.caption.19}\protected@file@percent }
\newlabel{fig:yolov10}{{2.11}{9}{YOLOv10 Model Workflow~\cite {wang2024yolov10}\relax }{figure.caption.19}{}}
\citation{wang2024yolov10}
\citation{wang2024yolov10}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces Large-Kernel Convolution in YOLOv10\nobreakspace  {}\cite  {LearnOpenCVYOLOv10}\relax }}{10}{figure.caption.20}\protected@file@percent }
\newlabel{fig:large-kernel-yolov10}{{2.12}{10}{Large-Kernel Convolution in YOLOv10~\cite {LearnOpenCVYOLOv10}\relax }{figure.caption.20}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Performance Comparison of YOLO Models with State-of-the-Art Techniques. Latency is reported using official pre-trained models. \textsuperscript  {f}Latency refers to the forward pass duration without including post-processing. \textsuperscript  {\textdagger } indicates YOLOv10 results obtained with the original one-to-many training and Non-Maximum Suppression (NMS)\nobreakspace  {}\cite  {wang2024yolov10}.\relax }}{10}{table.caption.21}\protected@file@percent }
\newlabel{tab:yolov10-benchmarks}{{2.1}{10}{Performance Comparison of YOLO Models with State-of-the-Art Techniques. Latency is reported using official pre-trained models. \textsuperscript {f}Latency refers to the forward pass duration without including post-processing. \textsuperscript {\textdagger } indicates YOLOv10 results obtained with the original one-to-many training and Non-Maximum Suppression (NMS)~\cite {wang2024yolov10}.\relax }{table.caption.21}{}}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{SurveyVisualOT}
\citation{SurveyVisualOT}
\citation{OverviewCorrelationAlgoOT,SuveyAdvancesSingleOTMethods,SurveyModernODModels}
\citation{SuveyAdvancesSingleOTMethods,SurveyModernODModels,SurveyTransformersSingleOT}
\citation{SurveyTransformersSingleOT}
\citation{SurveySmallObjectDetection,SmallObjectDetectionPositonPrediction}
\citation{SuveyAdvancesSingleOTMethods,SurveyModernODModels}
\citation{OverviewCorrelationAlgoOT,SuveyAdvancesSingleOTMethods}
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces Intersection over Union (IoU) between a detection (in green) and ground-truth (in blue).\nobreakspace  {}\cite  {huggingface2023objectdetection}\relax }}{11}{figure.caption.22}\protected@file@percent }
\newlabel{fig:iou-metric}{{2.13}{11}{Intersection over Union (IoU) between a detection (in green) and ground-truth (in blue).~\cite {huggingface2023objectdetection}\relax }{figure.caption.22}{}}
\citation{FFPSpaceSystemVehicles}
\citation{Alahi2016}
\citation{MultipleObjectForecasting}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Deep Learning for Spacio-Temporal Prediction}{13}{section.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.14}{\ignorespaces Comparing different Sequence models: RNN, LSTM, and GRU. Source: Colah's blog. Compiled by AIML.com\relax }}{13}{figure.caption.23}\protected@file@percent }
\newlabel{fig:lstm-rnn-gru}{{2.14}{13}{Comparing different Sequence models: RNN, LSTM, and GRU. Source: Colah's blog. Compiled by AIML.com\relax }{figure.caption.23}{}}
\citation{MultipleObjectForecasting}
\citation{MultipleObjectForecasting}
\citation{MultipleObjectForecasting}
\citation{MultipleObjectForecasting}
\citation{MultipleObjectForecasting}
\citation{DBLP:journals/corr/abs-2010-10270}
\@writefile{lof}{\contentsline {figure}{\numberline {2.15}{\ignorespaces STED Model Architecture. Source:\nobreakspace  {}\citet  {MultipleObjectForecasting}\relax }}{14}{figure.caption.24}\protected@file@percent }
\newlabel{fig:sted}{{2.15}{14}{STED Model Architecture. Source:~\citet {MultipleObjectForecasting}\relax }{figure.caption.24}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces Comparison of the performance of STED with baseline models on the Citywalks dataset. Metrics include Average Displacement Error (ADE), Final Displacement Error (FDE), Average Intersection-over-Union (AIoU), and Final Intersection-over-Union (FIoU). The model was evaluated using 1 second of input frames to predict 2 seconds of future frames.\relax }}{14}{table.caption.25}\protected@file@percent }
\newlabel{tab:sted-results}{{2.2}{14}{Comparison of the performance of STED with baseline models on the Citywalks dataset. Metrics include Average Displacement Error (ADE), Final Displacement Error (FDE), Average Intersection-over-Union (AIoU), and Final Intersection-over-Union (FIoU). The model was evaluated using 1 second of input frames to predict 2 seconds of future frames.\relax }{table.caption.25}{}}
\citation{DBLP:journals/corr/abs-2010-10270}
\citation{DBLP:journals/corr/abs-2010-10270}
\citation{DBLP:journals/corr/abs-2010-10270}
\citation{DBLP:journals/corr/abs-2010-10270}
\citation{DBLP:journals/corr/abs-2010-10270}
\citation{DBLP:journals/corr/abs-2010-10270}
\@writefile{lof}{\contentsline {figure}{\numberline {2.16}{\ignorespaces PV-LSTM Model Architecture. Source:\nobreakspace  {}\citet  {DBLP:journals/corr/abs-2010-10270}\relax }}{15}{figure.caption.26}\protected@file@percent }
\newlabel{fig:pv-lstm}{{2.16}{15}{PV-LSTM Model Architecture. Source:~\citet {DBLP:journals/corr/abs-2010-10270}\relax }{figure.caption.26}{}}
\citation{FusionGRU}
\citation{FusionGRU}
\citation{FusionGRU}
\@writefile{lot}{\contentsline {table}{\numberline {2.3}{\ignorespaces Comparison of the performance of PV-LSTM with baseline models on the Citywalks dataset. Metrics include Average Displacement Error (ADE), Final Displacement Error (FDE), and Average Intersection-over-Union (AIoU). The model was evaluated using 1 second of input frames to predict 2 seconds of future frames.\relax }}{16}{table.caption.27}\protected@file@percent }
\newlabel{tab:pv-lstm-results}{{2.3}{16}{Comparison of the performance of PV-LSTM with baseline models on the Citywalks dataset. Metrics include Average Displacement Error (ADE), Final Displacement Error (FDE), and Average Intersection-over-Union (AIoU). The model was evaluated using 1 second of input frames to predict 2 seconds of future frames.\relax }{table.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.17}{\ignorespaces Fusion-GRU model architecture. Source:\nobreakspace  {}\citet  {FusionGRU}\relax }}{16}{figure.caption.28}\protected@file@percent }
\newlabel{fig:fusion-gru}{{2.17}{16}{Fusion-GRU model architecture. Source:~\citet {FusionGRU}\relax }{figure.caption.28}{}}
\citation{FusionGRU}
\citation{FusionGRU}
\citation{FusionGRU}
\@writefile{lot}{\contentsline {table}{\numberline {2.4}{\ignorespaces Comparison of the performance of Fusion-GRU with baseline models on the ROL and HEV-I datasets. Metrics include ADE, FDE, and FIoU. The model was evaluated using 0.5-second and 1-second prediction horizons.\relax }}{17}{table.caption.29}\protected@file@percent }
\newlabel{tab:fusion-gru-results}{{2.4}{17}{Comparison of the performance of Fusion-GRU with baseline models on the ROL and HEV-I datasets. Metrics include ADE, FDE, and FIoU. The model was evaluated using 0.5-second and 1-second prediction horizons.\relax }{table.caption.29}{}}
\citation{IntelRealSense}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Methodology}{18}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:methodology}{{3}{18}{Methodology}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Dataset Configuration}{18}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Dataset Description}{18}{subsection.3.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Intel® ${\text  {RealSense}}^{\text  {TM}}$ D435 Depth Camera. Source: Intel\relax }}{18}{figure.caption.30}\protected@file@percent }
\newlabel{fig:intel-realsense-d435}{{3.1}{18}{Intel® ${\text {RealSense}}^{\text {TM}}$ D435 Depth Camera. Source: Intel\relax }{figure.caption.30}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Data Annotation}{19}{subsection.3.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Summary of Available Videos}{20}{subsection.3.1.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces \centering  Summary of available videos in the HARD dataset with their assignment.\relax }}{20}{table.caption.31}\protected@file@percent }
\newlabel{tab:video_summary}{{3.1}{20}{\centering Summary of available videos in the HARD dataset with their assignment.\relax }{table.caption.31}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.4}Data Distribution}{20}{subsection.3.1.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces \centering  Distribution of frames across train, test, and validation sets for each state in the HARD dataset before balancing.\relax }}{20}{table.caption.32}\protected@file@percent }
\newlabel{tab:frame_distribution}{{3.2}{20}{\centering Distribution of frames across train, test, and validation sets for each state in the HARD dataset before balancing.\relax }{table.caption.32}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.5}Balanced Data Distribution}{21}{subsection.3.1.5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces \centering  Distribution of frames across train, test, and validation sets for each state in the HARD dataset after balancing.\relax }}{21}{table.caption.33}\protected@file@percent }
\newlabel{tab:balanced_frame_distribution}{{3.3}{21}{\centering Distribution of frames across train, test, and validation sets for each state in the HARD dataset after balancing.\relax }{table.caption.33}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Framework Design}{21}{section.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Framework Workflow\relax }}{22}{figure.caption.34}\protected@file@percent }
\newlabel{fig:framework-workflow}{{3.2}{22}{Framework Workflow\relax }{figure.caption.34}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Object Detection Model Fine-tuning}{22}{section.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Sequence Model Design}{23}{section.3.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces SizPos-GRU Model Architecture\relax }}{23}{figure.caption.35}\protected@file@percent }
\newlabel{fig:sizpos-gru}{{3.3}{23}{SizPos-GRU Model Architecture\relax }{figure.caption.35}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Input Representation}{24}{subsection.3.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Encoders}{24}{subsection.3.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces SizPos-GRU Encoder Architecture. The input sequence \( \mathbf  {X} = \{\mathbf  {x}_1, \mathbf  {x}_2, \dots  , \mathbf  {x}_T\} \) represents either the spatial dynamics vector (\(\mathbf  {P}\)) or the dimensional attributes vector (\(\mathbf  {D}\)). This sequence is processed through multiple GRU layers, producing a sequence of hidden states \( H = \{h_1, h_2, \dots  , h_T\} \) and a final hidden state \( h_T \) that encapsulates the temporal dependencies in the input sequence.\relax }}{25}{figure.caption.36}\protected@file@percent }
\newlabel{fig:sizpos-gru-encoder}{{3.4}{25}{SizPos-GRU Encoder Architecture. The input sequence \( \mathbf {X} = \{\mathbf {x}_1, \mathbf {x}_2, \dots , \mathbf {x}_T\} \) represents either the spatial dynamics vector (\(\mathbf {P}\)) or the dimensional attributes vector (\(\mathbf {D}\)). This sequence is processed through multiple GRU layers, producing a sequence of hidden states \( H = \{h_1, h_2, \dots , h_T\} \) and a final hidden state \( h_T \) that encapsulates the temporal dependencies in the input sequence.\relax }{figure.caption.36}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Hidden State Fusion}{25}{subsection.3.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.4}Decoders}{26}{subsection.3.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.4.1}Position Decoder}{26}{subsubsection.3.4.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.4.2}Size Decoder}{26}{subsubsection.3.4.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.4.3}Self-Attention Mechanism}{27}{subsubsection.3.4.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.4.4}Final Output}{27}{subsubsection.3.4.4.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces SizPos-GRU Decoder Architecture. This architecture illustrates the decoding process where the input sequence \( \mathbf  {x}_t \) and the last hidden state \( h_{t-1} \) are processed through multiple GRU layers to generate the next hidden state \( h_t \). The sequence of hidden states \( H = \{h_1, h_2, \dots  , h_t\} \) is then passed through a self-attention mechanism, which calculates attention scores and weights. The weighted sum of hidden states is combined with linear and non-linear transformations, including dropout and ReLU activation functions, to produce the final output \( \mathbf  {x}_{t+1} \). This output is used for predicting the next time step in the sequence, continuing the process iteratively for future predictions.\relax }}{28}{figure.caption.37}\protected@file@percent }
\newlabel{fig:sizpos-gru-decoder}{{3.5}{28}{SizPos-GRU Decoder Architecture. This architecture illustrates the decoding process where the input sequence \( \mathbf {x}_t \) and the last hidden state \( h_{t-1} \) are processed through multiple GRU layers to generate the next hidden state \( h_t \). The sequence of hidden states \( H = \{h_1, h_2, \dots , h_t\} \) is then passed through a self-attention mechanism, which calculates attention scores and weights. The weighted sum of hidden states is combined with linear and non-linear transformations, including dropout and ReLU activation functions, to produce the final output \( \mathbf {x}_{t+1} \). This output is used for predicting the next time step in the sequence, continuing the process iteratively for future predictions.\relax }{figure.caption.37}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Algorithm Design}{28}{section.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Data Preprocessing}{28}{subsection.3.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Data Postprocessing}{28}{subsection.3.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.3}Data Augmentation Strategy}{28}{subsection.3.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.4}Implementation Details}{29}{subsection.3.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Experiment Design}{30}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:experiment_design}{{4}{30}{Experiment Design}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Experiment Environment}{30}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Comparison Experiments}{30}{section.4.2}\protected@file@percent }
\citation{DBLP:journals/corr/abs-2010-10270}
\citation{FusionGRU}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Evaluation Metrics}{32}{section.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Results and Discussion}{34}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:results}{{5}{34}{Results and Discussion}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Object Detection Training Results}{34}{section.5.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Comparison of YOLO Models\relax }}{34}{table.caption.38}\protected@file@percent }
\newlabel{tab:comparison}{{5.1}{34}{Comparison of YOLO Models\relax }{table.caption.38}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Summary}{34}{subsection.5.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Data Description}{34}{section.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Annotated images of the refueling port in the CLOSED state.\relax }}{35}{figure.caption.39}\protected@file@percent }
\newlabel{fig:grid-closed-images}{{5.1}{35}{Annotated images of the refueling port in the CLOSED state.\relax }{figure.caption.39}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Annotated images of the refueling port in the OPEN state.\relax }}{35}{figure.caption.40}\protected@file@percent }
\newlabel{fig:grid-open-images}{{5.2}{35}{Annotated images of the refueling port in the OPEN state.\relax }{figure.caption.40}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Annotated images of the refueling port in the SEMI-OPEN state.\relax }}{35}{figure.caption.41}\protected@file@percent }
\newlabel{fig:grid-semi-open-images}{{5.3}{35}{Annotated images of the refueling port in the SEMI-OPEN state.\relax }{figure.caption.41}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Experiment Results}{36}{section.5.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces Performance comparison of various models on trajectory prediction tasks from 30 to 60 frames. The table reports the Average Displacement Error (ADE), Final Displacement Error (FDE), Average Intersection over Union (AIoU), and Final Intersection over Union (FIoU) for each model. Lower ADE and FDE values indicate better accuracy, while higher AIoU and FIoU values indicate better overlap with ground truth. The GRUSizPos model achieves the best performance across all metrics.\relax }}{36}{table.caption.42}\protected@file@percent }
\newlabel{tab:fusion-gru-results}{{5.2}{36}{Performance comparison of various models on trajectory prediction tasks from 30 to 60 frames. The table reports the Average Displacement Error (ADE), Final Displacement Error (FDE), Average Intersection over Union (AIoU), and Final Intersection over Union (FIoU) for each model. Lower ADE and FDE values indicate better accuracy, while higher AIoU and FIoU values indicate better overlap with ground truth. The GRUSizPos model achieves the best performance across all metrics.\relax }{table.caption.42}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Testing Visualisation}{36}{section.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusion and Future Work}{37}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:conclusion}{{6}{37}{Conclusion and Future Work}{chapter.6}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Analysis of Bounding Box Metrics}{38}{appendix.A}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:appendix}{{A}{39}{Analysis of Bounding Box Metrics}{appendix.A}{}}
\newlabel{fig:central-position-test-indoor1}{{A.1a}{39}{Central position of the refueling port over time.\relax }{figure.caption.43}{}}
\newlabel{sub@fig:central-position-test-indoor1}{{a}{39}{Central position of the refueling port over time.\relax }{figure.caption.43}{}}
\newlabel{fig:velocity-test-indoor1}{{A.1b}{39}{Velocity of the refueling port over time.\relax }{figure.caption.43}{}}
\newlabel{sub@fig:velocity-test-indoor1}{{b}{39}{Velocity of the refueling port over time.\relax }{figure.caption.43}{}}
\newlabel{fig:acceleration-test-indoor1}{{A.1c}{39}{Acceleration of the refueling port over time.\relax }{figure.caption.43}{}}
\newlabel{sub@fig:acceleration-test-indoor1}{{c}{39}{Acceleration of the refueling port over time.\relax }{figure.caption.43}{}}
\newlabel{fig:size-test-indoor1}{{A.1d}{39}{Area of the refueling port over time.\relax }{figure.caption.43}{}}
\newlabel{sub@fig:size-test-indoor1}{{d}{39}{Area of the refueling port over time.\relax }{figure.caption.43}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.1}{\ignorespaces Temporal analysis of different metrics for the refueling port in the \textit  {test\_indoor1} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }}{39}{figure.caption.43}\protected@file@percent }
\newlabel{fig:bbox-metrics-test-indoor1}{{A.1}{39}{Temporal analysis of different metrics for the refueling port in the \textit {test\_indoor1} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }{figure.caption.43}{}}
\newlabel{fig:central-position-test-indoor1-savgol}{{A.2a}{40}{Central position of the refueling port over time.\relax }{figure.caption.44}{}}
\newlabel{sub@fig:central-position-test-indoor1-savgol}{{a}{40}{Central position of the refueling port over time.\relax }{figure.caption.44}{}}
\newlabel{fig:velocity-test-indoor1-savgol}{{A.2b}{40}{Velocity of the refueling port over time.\relax }{figure.caption.44}{}}
\newlabel{sub@fig:velocity-test-indoor1-savgol}{{b}{40}{Velocity of the refueling port over time.\relax }{figure.caption.44}{}}
\newlabel{fig:acceleration-test-indoor1-savgol}{{A.2c}{40}{Acceleration of the refueling port over time.\relax }{figure.caption.44}{}}
\newlabel{sub@fig:acceleration-test-indoor1-savgol}{{c}{40}{Acceleration of the refueling port over time.\relax }{figure.caption.44}{}}
\newlabel{fig:size-test-indoor1-savgol}{{A.2d}{40}{Area of the refueling port over time.\relax }{figure.caption.44}{}}
\newlabel{sub@fig:size-test-indoor1-savgol}{{d}{40}{Area of the refueling port over time.\relax }{figure.caption.44}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.2}{\ignorespaces Temporal analysis of different metrics for the refueling port in the \textit  {test\_indoor1} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }}{40}{figure.caption.44}\protected@file@percent }
\newlabel{fig:bbox-metrics-test-indoor1-savgol}{{A.2}{40}{Temporal analysis of different metrics for the refueling port in the \textit {test\_indoor1} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }{figure.caption.44}{}}
\newlabel{fig:central-position-test-outdoor1}{{A.3a}{41}{Central position of the refueling port over time.\relax }{figure.caption.45}{}}
\newlabel{sub@fig:central-position-test-outdoor1}{{a}{41}{Central position of the refueling port over time.\relax }{figure.caption.45}{}}
\newlabel{fig:velocity-test-outdoor1}{{A.3b}{41}{Velocity of the refueling port over time.\relax }{figure.caption.45}{}}
\newlabel{sub@fig:velocity-test-outdoor1}{{b}{41}{Velocity of the refueling port over time.\relax }{figure.caption.45}{}}
\newlabel{fig:acceleration-test-outdoor1}{{A.3c}{41}{Acceleration of the refueling port over time.\relax }{figure.caption.45}{}}
\newlabel{sub@fig:acceleration-test-outdoor1}{{c}{41}{Acceleration of the refueling port over time.\relax }{figure.caption.45}{}}
\newlabel{fig:size-test-outdoor1}{{A.3d}{41}{Area of the refueling port over time.\relax }{figure.caption.45}{}}
\newlabel{sub@fig:size-test-outdoor1}{{d}{41}{Area of the refueling port over time.\relax }{figure.caption.45}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.3}{\ignorespaces Temporal analysis of different metrics for the refueling port in the \textit  {test\_outdoor1} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }}{41}{figure.caption.45}\protected@file@percent }
\newlabel{fig:bbox-metrics-test-outdoor1}{{A.3}{41}{Temporal analysis of different metrics for the refueling port in the \textit {test\_outdoor1} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }{figure.caption.45}{}}
\newlabel{fig:central-position-test-outdoor1-savgol}{{A.4a}{42}{Central position of the refueling port over time.\relax }{figure.caption.46}{}}
\newlabel{sub@fig:central-position-test-outdoor1-savgol}{{a}{42}{Central position of the refueling port over time.\relax }{figure.caption.46}{}}
\newlabel{fig:velocity-test-outdoor1-savgol}{{A.4b}{42}{Velocity of the refueling port over time.\relax }{figure.caption.46}{}}
\newlabel{sub@fig:velocity-test-outdoor1-savgol}{{b}{42}{Velocity of the refueling port over time.\relax }{figure.caption.46}{}}
\newlabel{fig:acceleration-test-outdoor1-savgol}{{A.4c}{42}{Acceleration of the refueling port over time.\relax }{figure.caption.46}{}}
\newlabel{sub@fig:acceleration-test-outdoor1-savgol}{{c}{42}{Acceleration of the refueling port over time.\relax }{figure.caption.46}{}}
\newlabel{fig:size-test-outdoor1-savgol}{{A.4d}{42}{Area of the refueling port over time.\relax }{figure.caption.46}{}}
\newlabel{sub@fig:size-test-outdoor1-savgol}{{d}{42}{Area of the refueling port over time.\relax }{figure.caption.46}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.4}{\ignorespaces Temporal analysis of different metrics for the refueling port in the \textit  {test\_outdoor1} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }}{42}{figure.caption.46}\protected@file@percent }
\newlabel{fig:bbox-metrics-test-outdoor1-savgol}{{A.4}{42}{Temporal analysis of different metrics for the refueling port in the \textit {test\_outdoor1} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }{figure.caption.46}{}}
\newlabel{fig:central-position-test-video_lab_platform_6}{{A.5a}{43}{Central position of the refueling port over time.\relax }{figure.caption.47}{}}
\newlabel{sub@fig:central-position-test-video_lab_platform_6}{{a}{43}{Central position of the refueling port over time.\relax }{figure.caption.47}{}}
\newlabel{fig:velocity-test-video_lab_platform_6}{{A.5b}{43}{Velocity of the refueling port over time.\relax }{figure.caption.47}{}}
\newlabel{sub@fig:velocity-test-video_lab_platform_6}{{b}{43}{Velocity of the refueling port over time.\relax }{figure.caption.47}{}}
\newlabel{fig:acceleration-test-video_lab_platform_6}{{A.5c}{43}{Acceleration of the refueling port over time.\relax }{figure.caption.47}{}}
\newlabel{sub@fig:acceleration-test-video_lab_platform_6}{{c}{43}{Acceleration of the refueling port over time.\relax }{figure.caption.47}{}}
\newlabel{fig:size-test-video_lab_platform_6}{{A.5d}{43}{Area of the refueling port over time.\relax }{figure.caption.47}{}}
\newlabel{sub@fig:size-test-video_lab_platform_6}{{d}{43}{Area of the refueling port over time.\relax }{figure.caption.47}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.5}{\ignorespaces Temporal analysis of different metrics for the refueling port in the \textit  {test\_video\_lab\_platform\_6} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }}{43}{figure.caption.47}\protected@file@percent }
\newlabel{fig:bbox-metrics-test-video_lab_platform_6}{{A.5}{43}{Temporal analysis of different metrics for the refueling port in the \textit {test\_video\_lab\_platform\_6} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }{figure.caption.47}{}}
\bibstyle{abbrvnat}
\bibdata{LaTeX,CUCitations}
\newlabel{fig:central-position-test-video_lab_platform_6-savgol}{{A.6a}{44}{Central position of the refueling port over time.\relax }{figure.caption.48}{}}
\newlabel{sub@fig:central-position-test-video_lab_platform_6-savgol}{{a}{44}{Central position of the refueling port over time.\relax }{figure.caption.48}{}}
\newlabel{fig:velocity-test-video_lab_platform_6-savgol}{{A.6b}{44}{Velocity of the refueling port over time.\relax }{figure.caption.48}{}}
\newlabel{sub@fig:velocity-test-video_lab_platform_6-savgol}{{b}{44}{Velocity of the refueling port over time.\relax }{figure.caption.48}{}}
\newlabel{fig:acceleration-test-video_lab_platform_6-savgol}{{A.6c}{44}{Acceleration of the refueling port over time.\relax }{figure.caption.48}{}}
\newlabel{sub@fig:acceleration-test-video_lab_platform_6-savgol}{{c}{44}{Acceleration of the refueling port over time.\relax }{figure.caption.48}{}}
\newlabel{fig:size-test-video_lab_platform_6-savgol}{{A.6d}{44}{Area of the refueling port over time.\relax }{figure.caption.48}{}}
\newlabel{sub@fig:size-test-video_lab_platform_6-savgol}{{d}{44}{Area of the refueling port over time.\relax }{figure.caption.48}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.6}{\ignorespaces Temporal analysis of different metrics for the refueling port in the \textit  {test\_video\_lab\_platform\_6} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }}{44}{figure.caption.48}\protected@file@percent }
\newlabel{fig:bbox-metrics-test-video_lab_platform_6-savgol}{{A.6}{44}{Temporal analysis of different metrics for the refueling port in the \textit {test\_video\_lab\_platform\_6} video. The metrics include (a) central position, (b) velocity, (c) acceleration, and (d) area, providing a comprehensive overview of the object's dynamics over time.\relax }{figure.caption.48}{}}
\bibcite{Alahi2016}{{1}{2016}{{Alahi et~al.}}{{Alahi, Goel, Ramanathan, Robicquet, Fei-Fei, and Savarese}}}
\bibcite{AR3P2020}{{2}{AvMC}{{}}{{(2020)}}}
\bibcite{ImageRefueling}{{3}{2019}{{Bailey}}{{}}}
\bibcite{Bennett1991}{{4}{1991}{{Bennett et~al.}}{{Bennett, Shiu, and Leahy}}}
\bibcite{blakey2011aviation}{{5}{2011}{{Blakey et~al.}}{{Blakey, Rye, and Wilson}}}
\bibcite{DBLP:journals/corr/abs-2004-10934}{{6}{2020}{{Bochkovskiy et~al.}}{{Bochkovskiy, Wang, and Liao}}}
\bibcite{DBLP:journals/corr/abs-2010-10270}{{7}{2020}{{Bouhsain et~al.}}{{Bouhsain, Saadatnejad, and Alahi}}}
\bibcite{Burnette2010}{{8}{2010}{{Burnette}}{{}}}
\bibcite{SurveyVisualOT}{{9}{2022}{{Chen et~al.}}{{Chen, Wang, Zhao, Lv, and Niu}}}
\bibcite{chen2023yoloms}{{10}{2023}{{Chen et~al.}}{{Chen, Yuan, Wu, Wang, Hou, and Cheng}}}
\bibcite{SurveySmallObjectDetection}{{11}{2023}{{Cheng et~al.}}{{Cheng, Yuan, Yao, Yan, Zeng, Xie, and Han}}}
\bibcite{CostsOfUnsafetyAviation}{{12}{2010}{{Cokorilo et~al.}}{{Cokorilo, Gvozdenovic, Vasov, and Mirosavljevic}}}
\@writefile{toc}{\contentsline {chapter}{References}{45}{appendix*.49}\protected@file@percent }
\bibcite{DBLP:journals/corr/DaiLHS16}{{13}{2016}{{Dai et~al.}}{{Dai, Li, He, and Sun}}}
\bibcite{huggingface2023objectdetection}{{14}{2023}{{Face}}{{}}}
\bibcite{Ficken2017}{{15}{2017}{{Ficken}}{{}}}
\bibcite{DBLP:journals/corr/abs-2107-08430}{{16}{2021}{{Ge et~al.}}{{Ge, Liu, Wang, Li, and Sun}}}
\bibcite{LearnOpenCVYOLOv10}{{17}{2024}{{Ghosh}}{{}}}
\bibcite{DBLP:journals/corr/Girshick15}{{18}{2015}{{Girshick}}{{}}}
\bibcite{DBLP:journals/corr/GirshickDDM13}{{19}{2013}{{Girshick et~al.}}{{Girshick, Donahue, Darrell, and Malik}}}
\bibcite{AARBinocularVision}{{20}{2023}{{Gong et~al.}}{{Gong, Liu, Xu, Xu, He, Zhang, and Rasol}}}
\bibcite{IntelRealSense}{{21}{2024}{{Intel}}{{}}}
\bibcite{YOLOv5Release}{{22}{2022}{{Jocher}}{{}}}
\bibcite{YOLOv8}{{23}{2023}{{Jocher}}{{}}}
\bibcite{SurveyDLOD}{{24}{2022}{{Kang et~al.}}{{Kang, Tariq, Oh, and Woo}}}
\bibcite{FusionGRU}{{25}{2024}{{Karim et~al.}}{{Karim, Qin, and Wang}}}
\bibcite{DatasetAGR}{{26}{2023}{{Kuang et~al.}}{{Kuang, Barnes, Tang, and Jenkins}}}
\bibcite{SurveyTransformersSingleOT}{{27}{2023}{{Kugarajeevan et~al.}}{{Kugarajeevan, Kokul, Ramanan, and Fernando}}}
\bibcite{FFPSpaceSystemVehicles}{{28}{2022}{{Lee et~al.}}{{Lee, Jeon, Han, and Jeong}}}
\bibcite{li2023yolov6}{{29}{2023}{{Li et~al.}}{{Li, Li, Geng, Jiang, Cheng, Zhang, Ke, Xu, and Chu}}}
\bibcite{lin2018focal}{{30}{2018}{{Lin et~al.}}{{Lin, Goyal, Girshick, He, and Dollár}}}
\bibcite{10.1007/978-981-16-5943-0_26}{{31}{2021{}}{{Liu et~al.}}{{Liu, Chen, and Liu}}}
\bibcite{OverviewCorrelationAlgoOT}{{32}{2021{}}{{Liu et~al.}}{{Liu, Liu, Srivastava, Połap, and Woźniak}}}
\bibcite{DBLP:journals/corr/LiuAESR15}{{33}{2015}{{Liu et~al.}}{{Liu, Anguelov, Erhan, Szegedy, Reed, Fu, and Berg}}}
\bibcite{doi:10.1080/13669877.2013.879493}{{34}{2014}{{Olja~Čokorilo and Dell’Acqua}}{{}}}
\bibcite{ExpertSystemsAGR}{{35}{2021}{{Plaza and Santos}}{{}}}
\bibcite{DBLP:journals/corr/RedmonF16}{{36}{2016}{{Redmon and Farhadi}}{{}}}
\bibcite{DBLP:journals/corr/RedmonDGF15}{{37}{2015}{{Redmon et~al.}}{{Redmon, Divvala, Girshick, and Farhadi}}}
\bibcite{Ren2017}{{38}{2017}{{Ren et~al.}}{{Ren, He, Girshick, and Sun}}}
\bibcite{sati2019aircraft}{{39}{2019}{{Sati et~al.}}{{Sati, Singh, and Yadav}}}
\bibcite{Schultz1986}{{40}{1986}{{Schultz}}{{}}}
\bibcite{MultipleObjectForecasting}{{41}{2020}{{Styles et~al.}}{{Styles, Guha, and Sanchez}}}
\bibcite{wang2024yolov10}{{42}{2024{}}{{Wang et~al.}}{{Wang, Chen, Liu, Chen, Lin, Han, and Ding}}}
\bibcite{wang2023goldyolo}{{43}{2023}{{Wang et~al.}}{{Wang, He, Nie, Guo, Liu, Han, and Wang}}}
\bibcite{wang2024yolov9}{{44}{2024{}}{{Wang et~al.}}{{Wang, Yeh, and Liao}}}
\bibcite{AARCNN}{{45}{2017}{{Wang et~al.}}{{Wang, Dong, Kong, Li, and Zhang}}}
\bibcite{SmallObjectDetectionPositonPrediction}{{46}{2021}{{Wu and Xu}}{{}}}
\bibcite{xu2022ppyoloe}{{47}{2022}{{Xu et~al.}}{{Xu, Wang, Lv, Chang, Cui, Deng, Wang, Dang, Wei, Du, and Lai}}}
\bibcite{xu2023damoyolo}{{48}{2023}{{Xu et~al.}}{{Xu, Jiang, Chen, Huang, Zhang, and Sun}}}
\bibcite{ODNetworkUAVCNNTransformer}{{49}{2023}{{Ye et~al.}}{{Ye, Qin, Zhao, Gao, Deng, and Ouyang}}}
\bibcite{AGRPoseEstimation}{{50}{2021}{{Yildirim et~al.}}{{Yildirim, Rana, and Tang}}}
\bibcite{HybridDatasetAGRV1}{{51}{2023}{{Yildirim et~al.}}{{Yildirim, Rana, and Tang}}}
\bibcite{SurveyModernODModels}{{52}{2022}{{Zaidi et~al.}}{{Zaidi, Ansari, Aslam, Kanwal, Asghar, and Lee}}}
\bibcite{SuveyAdvancesSingleOTMethods}{{53}{2021}{{Zhang et~al.}}{{Zhang, Wang, Liu, Zhang, and Chen}}}
\bibcite{AAREKF}{{54}{2017}{{Zhong et~al.}}{{Zhong, Li, Wang, and Su}}}
\gdef \@abspage@last{59}
