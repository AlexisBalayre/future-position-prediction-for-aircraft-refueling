\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {chapter}{Academic Integrity Declaration}{i}{Doc-Start}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Table of Contents}{ii}{chapter*.1}\protected@file@percent }
\citation{huggingface2023objectdetection}
\citation{SurveyDLOD}
\citation{huggingface2023objectdetection}
\citation{CubicLSTMsVideoPrediction}
\citation{UnsupervisedVideoForecastingFlowParsingMechanism}
\citation{VideoFramePredictionByJointOptimizationWithSynthesisAndOpticalFlowEstimation}
\citation{FusionGRU}
\citation{DualBranchSpatialTemporalLearningNetworkVideoPrediction}
\citation{SurveyDLOD}
\citation{DBLP:journals/corr/SrivastavaMS15}
\citation{DBLP:journals/corr/EitelHB17}
\citation{KTH}
\citation{UCFSport}
\@writefile{toc}{\contentsline {chapter}{List of Figures}{iii}{chapter*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{List of Tables}{iv}{chapter*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{List of Abbreviations}{v}{chapter*.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{blakey2011aviation}
\citation{kazda2015airport}
\citation{sati2019aircraft}
\citation{iata2019guidance}
\citation{sati2019aircraft}
\citation{iata2019guidance}
\citation{blakey2011aviation}
\citation{kazda2015airport}
\citation{iata2019guidance}
\citation{sati2019aircraft}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Pressure Refuelling of a Commercial Aircraft. Source: Tom Boon/Simple Flying\relax }}{1}{figure.caption.5}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:pressure-refuelling}{{1.1}{1}{Pressure Refuelling of a Commercial Aircraft. Source: Tom Boon/Simple Flying\relax }{figure.caption.5}{}}
\citation{Schultz1986,Bennett1991,DatasetAGR}
\citation{HybridDatasetAGRV2}
\citation{AGRPoseEstimation}
\citation{AARBinocularVision}
\citation{DatasetAGR}
\citation{AGRPoseEstimation}
\citation{HybridDatasetAGRV1}
\citation{HybridDatasetAGRV2}
\citation{AGRPoseEstimation}
\citation{DatasetAGR}
\citation{HybridDatasetAGRV1}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Literature Review}{3}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Automated Refulling Systems in the Aviation Industry}{3}{section.2.1}\protected@file@percent }
\citation{AARCNN}
\citation{Chen2011}
\citation{AARCNN}
\citation{AAREKF}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{DBLP:journals/corr/GirshickDDM13}
\citation{DBLP:journals/corr/Girshick15}
\citation{Ren2017}
\citation{DBLP:journals/corr/DaiLHS16}
\citation{SurveyDLOD,ODNetworkUAVCNNTransformer}
\citation{DBLP:journals/corr/LiuAESR15}
\citation{DBLP:journals/corr/RedmonDGF15,DBLP:journals/corr/RedmonF16,DBLP:journals/corr/abs-2004-10934,chen2023yoloms,DBLP:journals/corr/abs-2107-08430,YOLOv5Release,li2023yolov6,YOLOv8,wang2024yolov9,xu2022ppyoloe,wang2023goldyolo,xu2023damoyolo,wang2024yolov10}
\citation{lin2018focal}
\citation{SurveyDLOD,ODNetworkUAVCNNTransformer}
\citation{SurveyDLOD}
\citation{SurveyDLOD}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Object Detection and Tracking in Computer Vision}{5}{section.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Example of outputs from an object detector\nobreakspace  {}\cite  {huggingface2023objectdetection}.\relax }}{5}{figure.caption.6}\protected@file@percent }
\newlabel{fig:object-detection}{{2.1}{5}{Example of outputs from an object detector~\cite {huggingface2023objectdetection}.\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Basic deep learning-based one-stage vs two-stage object detection model architectures\nobreakspace  {}\cite  {SurveyDLOD}.\relax }}{5}{figure.caption.7}\protected@file@percent }
\newlabel{fig:two-stage-vs-single-stage}{{2.2}{5}{Basic deep learning-based one-stage vs two-stage object detection model architectures~\cite {SurveyDLOD}.\relax }{figure.caption.7}{}}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{huggingface2023objectdetection}
\citation{SurveyVisualOT}
\citation{SurveyVisualOT}
\citation{OverviewCorrelationAlgoOT,SuveyAdvancesSingleOTMethods,SurveyModernODModels}
\citation{SuveyAdvancesSingleOTMethods,SurveyModernODModels,SurveyTransformersSingleOT}
\citation{SurveyTransformersSingleOT}
\citation{SurveySmallObjectDetection,SmallObjectDetectionPositonPrediction}
\citation{SuveyAdvancesSingleOTMethods,SurveyModernODModels}
\citation{OverviewCorrelationAlgoOT,SuveyAdvancesSingleOTMethods}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Intersection over Union (IoU) between a detection (in green) and ground-truth (in blue).\nobreakspace  {}\cite  {huggingface2023objectdetection}\relax }}{6}{figure.caption.8}\protected@file@percent }
\newlabel{fig:iou-metric}{{2.3}{6}{Intersection over Union (IoU) between a detection (in green) and ground-truth (in blue).~\cite {huggingface2023objectdetection}\relax }{figure.caption.8}{}}
\citation{FFPSpaceSystemVehicles}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Deep Learning for Spacio-Temporal Prediction}{7}{section.2.3}\protected@file@percent }
\citation{Alahi2016}
\citation{Vaswani2017}
\citation{HowDoUGoWhere}
\citation{ConvLSTM}
\citation{CubicLSTMsVideoPrediction}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Comparing different Sequence models: RNN, LSTM, and GRU. Source: Colah's blog. Compiled by AIML.com\relax }}{8}{figure.caption.9}\protected@file@percent }
\newlabel{fig:lstm-rnn-gru}{{2.4}{8}{Comparing different Sequence models: RNN, LSTM, and GRU. Source: Colah's blog. Compiled by AIML.com\relax }{figure.caption.9}{}}
\citation{CubicLSTMsVideoPrediction}
\citation{CubicLSTMsVideoPrediction}
\citation{UnsupervisedVideoForecastingFlowParsingMechanism}
\citation{UnsupervisedVideoForecastingFlowParsingMechanism}
\citation{UnsupervisedVideoForecastingFlowParsingMechanism}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Cubic LSTM Architecture. (a) 3D structure of the CubicLSTM unit. (b) Topological diagram of the CubicLSTM unit. (c) Two-spatial-layer RNN composed of CubicLSTM units. The unit consists of three branches, a spatial (z-) branch for extracting and recognizing moving objects, a temporal (y-) branch for capturing and predicting motions, and an output (x-) branch for combining the first two branches to generate the predicted frames. Source:\nobreakspace  {}\citet  {CubicLSTMsVideoPrediction}\relax }}{9}{figure.caption.10}\protected@file@percent }
\newlabel{fig:cubic-lstm}{{2.5}{9}{Cubic LSTM Architecture. (a) 3D structure of the CubicLSTM unit. (b) Topological diagram of the CubicLSTM unit. (c) Two-spatial-layer RNN composed of CubicLSTM units. The unit consists of three branches, a spatial (z-) branch for extracting and recognizing moving objects, a temporal (y-) branch for capturing and predicting motions, and an output (x-) branch for combining the first two branches to generate the predicted frames. Source:~\citet {CubicLSTMsVideoPrediction}\relax }{figure.caption.10}{}}
\citation{VideoFramePredictionByJointOptimizationWithSynthesisAndOpticalFlowEstimation}
\citation{VideoFramePredictionByJointOptimizationWithSynthesisAndOpticalFlowEstimation}
\citation{VideoFramePredictionByJointOptimizationWithSynthesisAndOpticalFlowEstimation}
\citation{FusionGRU}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Model Architecture. Source:\nobreakspace  {}\citet  {UnsupervisedVideoForecastingFlowParsingMechanism}\relax }}{10}{figure.caption.11}\protected@file@percent }
\newlabel{fig:unsupervised-video-forecasting-flow-parsing}{{2.6}{10}{Model Architecture. Source:~\citet {UnsupervisedVideoForecastingFlowParsingMechanism}\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces FPNet-OF model architecture. Source:\nobreakspace  {}\citet  {VideoFramePredictionByJointOptimizationWithSynthesisAndOpticalFlowEstimation}\relax }}{10}{figure.caption.12}\protected@file@percent }
\newlabel{fig:joint-optimization-synthesis-optical-flow}{{2.7}{10}{FPNet-OF model architecture. Source:~\citet {VideoFramePredictionByJointOptimizationWithSynthesisAndOpticalFlowEstimation}\relax }{figure.caption.12}{}}
\citation{FusionGRU}
\citation{FusionGRU}
\citation{DualBranchSpatialTemporalLearningNetworkVideoPrediction}
\citation{DualBranchSpatialTemporalLearningNetworkVideoPrediction}
\citation{DualBranchSpatialTemporalLearningNetworkVideoPrediction}
\citation{SurveyDLOD}
\citation{SurveyDLOD}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Fusion-GRU model architecture. Source:\nobreakspace  {}\citet  {FusionGRU}\relax }}{11}{figure.caption.13}\protected@file@percent }
\newlabel{fig:fusion-gru}{{2.8}{11}{Fusion-GRU model architecture. Source:~\citet {FusionGRU}\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Dual-Branch Spatial-Temporal Learning Network. Source:\nobreakspace  {}\citet  {DualBranchSpatialTemporalLearningNetworkVideoPrediction}\relax }}{11}{figure.caption.14}\protected@file@percent }
\newlabel{fig:dual-branch-spatial-temporal-learning-network}{{2.9}{11}{Dual-Branch Spatial-Temporal Learning Network. Source:~\citet {DualBranchSpatialTemporalLearningNetworkVideoPrediction}\relax }{figure.caption.14}{}}
\citation{DBLP:journals/corr/SrivastavaMS15}
\citation{CubicLSTMsVideoPrediction}
\citation{DBLP:journals/corr/SrivastavaMS15}
\citation{DBLP:journals/corr/SrivastavaMS15}
\citation{DBLP:journals/corr/FinnGL16}
\citation{CubicLSTMsVideoPrediction}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces Dual-Branch Spatial-Temporal Learning Network. Source:\nobreakspace  {}\citet  {SurveyDLOD}\relax }}{12}{figure.caption.15}\protected@file@percent }
\newlabel{fig:dual-branch-inter-intra-frames}{{2.10}{12}{Dual-Branch Spatial-Temporal Learning Network. Source:~\citet {SurveyDLOD}\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces 2-digit Moving MNIST data by\nobreakspace  {}\citet  {DBLP:journals/corr/SrivastavaMS15}\relax }}{12}{figure.caption.16}\protected@file@percent }
\newlabel{fig:moving-mnist}{{2.11}{12}{2-digit Moving MNIST data by~\citet {DBLP:journals/corr/SrivastavaMS15}\relax }{figure.caption.16}{}}
\citation{DBLP:journals/corr/EitelHB17}
\citation{DBLP:journals/corr/EitelHB17}
\citation{KTH}
\citation{CubicLSTMsVideoPrediction}
\citation{KTH}
\citation{KTH}
\citation{UCFSport}
\citation{DualBranchSpatialTemporalLearningNetworkVideoPrediction}
\citation{UCFSport}
\citation{UCFSport}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces Robotic Pushing Dataset. Source:\nobreakspace  {}\citet  {DBLP:journals/corr/EitelHB17}\relax }}{13}{figure.caption.17}\protected@file@percent }
\newlabel{fig:robotic-pushing-dataset}{{2.12}{13}{Robotic Pushing Dataset. Source:~\citet {DBLP:journals/corr/EitelHB17}\relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces KTH Action Dataset. Source:\nobreakspace  {}\citet  {KTH}\relax }}{13}{figure.caption.18}\protected@file@percent }
\newlabel{fig:kth-action-dataset}{{2.13}{13}{KTH Action Dataset. Source:~\citet {KTH}\relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.14}{\ignorespaces UCF Sports Dataset. Source:\nobreakspace  {}\citet  {UCFSport}\relax }}{14}{figure.caption.19}\protected@file@percent }
\newlabel{fig:ucf-sports-dataset}{{2.14}{14}{UCF Sports Dataset. Source:~\citet {UCFSport}\relax }{figure.caption.19}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Methodology}{15}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Dataset Configuration}{15}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Provided Dataset Description}{15}{subsection.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Data Annotation}{15}{subsection.3.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Summary of Available Videos}{16}{subsection.3.1.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces \centering  Summary of available videos in the HARD dataset with their assignment.\relax }}{17}{table.caption.20}\protected@file@percent }
\newlabel{tab:video_summary}{{3.1}{17}{\centering Summary of available videos in the HARD dataset with their assignment.\relax }{table.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.4}Initial Data Distribution}{17}{subsection.3.1.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces \centering  Distribution of frames across train, test, and validation sets for each state in the HARD dataset before balancing.\relax }}{17}{table.caption.21}\protected@file@percent }
\newlabel{tab:frame_distribution}{{3.2}{17}{\centering Distribution of frames across train, test, and validation sets for each state in the HARD dataset before balancing.\relax }{table.caption.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.5}Balanced Data Distribution}{18}{subsection.3.1.5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces \centering  Distribution of frames across train, test, and validation sets for each state in the HARD dataset after balancing.\relax }}{18}{table.caption.22}\protected@file@percent }
\newlabel{tab:balanced_frame_distribution}{{3.3}{18}{\centering Distribution of frames across train, test, and validation sets for each state in the HARD dataset after balancing.\relax }{table.caption.22}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.6}Example Images from the Dataset}{18}{subsection.3.1.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Annotated images of the fueling port in the CLOSED state.\relax }}{19}{figure.caption.23}\protected@file@percent }
\newlabel{fig:grid-closed-images}{{3.1}{19}{Annotated images of the fueling port in the CLOSED state.\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Annotated images of the fueling port in the OPEN state.\relax }}{19}{figure.caption.24}\protected@file@percent }
\newlabel{fig:grid-open-images}{{3.2}{19}{Annotated images of the fueling port in the OPEN state.\relax }{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Annotated images of the fueling port in the SEMI-OPEN state.\relax }}{19}{figure.caption.25}\protected@file@percent }
\newlabel{fig:grid-semi-open-images}{{3.3}{19}{Annotated images of the fueling port in the SEMI-OPEN state.\relax }{figure.caption.25}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Framework Design}{20}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Model Design}{20}{section.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}LSTM-based Sequence Model}{20}{subsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1.1}Input Representation}{20}{subsubsection.3.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1.2}Encoders}{20}{subsubsection.3.3.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1.3}Attention Mechanism}{21}{subsubsection.3.3.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Decoders}{21}{subsection.3.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}Transformer-Based Architecture}{22}{subsection.3.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.3.1}Input Representation}{22}{subsubsection.3.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.3.2}Encoder}{22}{subsubsection.3.3.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.3.3}Decoder}{23}{subsubsection.3.3.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.3.4}Multi-Head Self-Attention}{23}{subsubsection.3.3.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.3.5}Output Generation}{23}{subsubsection.3.3.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.3.6}Loss Function and Training}{23}{subsubsection.3.3.3.6}\protected@file@percent }
\gdef \@abspage@last{30}
