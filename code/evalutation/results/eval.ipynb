{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate YOLO Model on Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = json.load(open('/Users/alexis/Library/CloudStorage/OneDrive-Balayre&Co/Cranfield/Thesis/thesis-github-repository/data/frames/full_dataset_annotated_fpp/test.json'))\n",
    "predictions_nano = json.load(open('/Users/alexis/Library/CloudStorage/OneDrive-Balayre&Co/Cranfield/Thesis/thesis-github-repository/code/evalutation/results/results_nano.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 187\u001b[0m\n\u001b[1;32m    184\u001b[0m img_height \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m480\u001b[39m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# Compare annotations and compute metrics for each video\u001b[39;00m\n\u001b[0;32m--> 187\u001b[0m video_results \u001b[38;5;241m=\u001b[39m \u001b[43mcompare_annotations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgt_annotations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_annotations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_height\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# Display results\u001b[39;00m\n\u001b[1;32m    190\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(video_results)\n",
      "Cell \u001b[0;32mIn[13], line 91\u001b[0m, in \u001b[0;36mcompare_annotations\u001b[0;34m(gt_annotations, pred_annotations, img_width, img_height)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gt_bbox \u001b[38;5;129;01mand\u001b[39;00m pred_bbox:\n\u001b[1;32m     90\u001b[0m     iou \u001b[38;5;241m=\u001b[39m bbox_iou(gt_bbox, pred_bbox, img_width, img_height)\n\u001b[0;32m---> 91\u001b[0m     \u001b[43mclass_iou_scores\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclass_id\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mappend(iou)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m gt_bbox \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m pred_bbox \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     class_iou_scores[class_id]\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m1.0\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not NoneType"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from typing import List, Dict, Tuple\n",
    "import pandas as pd\n",
    "\n",
    "def load_json(file_path: str) -> Dict:\n",
    "    with open(file_path, \"r\") as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def is_valid_bbox(bbox: List[float]) -> bool:\n",
    "    return isinstance(bbox, list) and len(bbox) == 4 and all(isinstance(x, (int, float)) for x in bbox)\n",
    "\n",
    "def bbox_iou(bbox1: List[float], bbox2: List[float], img_width: int, img_height: int) -> float:\n",
    "    if not is_valid_bbox(bbox1) or not is_valid_bbox(bbox2):\n",
    "        return 0.0\n",
    "\n",
    "    x1, y1, w1, h1 = bbox1\n",
    "    x2, y2, w2, h2 = bbox2\n",
    "\n",
    "    # Denormalize the bounding boxes\n",
    "    x1 *= img_width\n",
    "    y1 *= img_height\n",
    "    w1 *= img_width\n",
    "    h1 *= img_height\n",
    "    x2 *= img_width\n",
    "    y2 *= img_height\n",
    "    w2 *= img_width\n",
    "    h2 *= img_height\n",
    "\n",
    "    x1_min = x1 - w1 / 2\n",
    "    y1_min = y1 - h1 / 2\n",
    "    x1_max = x1 + w1 / 2\n",
    "    y1_max = y1 + h1 / 2\n",
    "\n",
    "    x2_min = x2 - w2 / 2\n",
    "    y2_min = y2 - h2 / 2\n",
    "    x2_max = x2 + w2 / 2\n",
    "    y2_max = y2 + h2 / 2\n",
    "\n",
    "    inter_x_min = max(x1_min, x2_min)\n",
    "    inter_y_min = max(y1_min, y2_min)\n",
    "    inter_x_max = min(x1_max, x2_max)\n",
    "    inter_y_max = min(y1_max, y2_max)\n",
    "\n",
    "    inter_area = max(0, inter_x_max - inter_x_min) * max(0, inter_y_max - inter_y_min)\n",
    "    bbox1_area = w1 * h1\n",
    "    bbox2_area = w2 * h2\n",
    "\n",
    "    iou = inter_area / (bbox1_area + bbox2_area - inter_area)\n",
    "    return iou\n",
    "\n",
    "def group_annotations_by_video(annotations: List[Dict]) -> Dict[str, List[Dict]]:\n",
    "    grouped_annotations = {}\n",
    "    for video in annotations:\n",
    "        video_id = video[\"video_id\"]\n",
    "        if video_id not in grouped_annotations:\n",
    "            grouped_annotations[video_id] = []\n",
    "        grouped_annotations[video_id].append(video)\n",
    "    return grouped_annotations\n",
    "\n",
    "def compare_annotations(\n",
    "    gt_annotations: List[Dict], pred_annotations: List[Dict], img_width: int, img_height: int\n",
    ") -> List[Dict]:\n",
    "    gt_videos = group_annotations_by_video(gt_annotations)\n",
    "    pred_videos = group_annotations_by_video(pred_annotations)\n",
    "\n",
    "    video_results = []\n",
    "\n",
    "    for video_id, gt_videos_list in gt_videos.items():\n",
    "        pred_videos_list = pred_videos.get(video_id, [])\n",
    "        \n",
    "        for gt_video, pred_video in zip(gt_videos_list, pred_videos_list):\n",
    "            gt_frames = {frame[\"frame_id\"]: frame for frame in gt_video[\"frames\"]}\n",
    "            pred_frames = {frame[\"frame_id\"]: frame for frame in pred_video[\"frames\"]}\n",
    "\n",
    "            class_iou_scores = [[] for _ in range(3)]\n",
    "            \n",
    "            for frame_id in gt_frames:\n",
    "                if frame_id in pred_frames:\n",
    "                    gt_frame = gt_frames[frame_id]\n",
    "                    pred_frame = pred_frames[frame_id]\n",
    "                    \n",
    "                    gt_class_id = gt_frame[\"class_id\"]\n",
    "                    pred_class_ids = [d[\"class_id\"] for d in pred_frame[\"detections\"]]\n",
    "\n",
    "                    for class_id in set([gt_class_id] + pred_class_ids):\n",
    "                        gt_bbox = gt_frame[\"bbox\"] if gt_frame[\"class_id\"] == class_id else None\n",
    "                        pred_bbox = next((d[\"bbox\"] for d in pred_frame[\"detections\"] if pred_frame[\"detections\"]), None)\n",
    "                        \n",
    "                        if gt_bbox and pred_bbox:\n",
    "                            iou = bbox_iou(gt_bbox, pred_bbox, img_width, img_height)\n",
    "                            class_iou_scores[class_id].append(iou)\n",
    "                        elif gt_bbox is None and pred_bbox is None:\n",
    "                            class_iou_scores[class_id].append(1.0)\n",
    "                        else:\n",
    "                            class_iou_scores[class_id].append(0.0)\n",
    "\n",
    "            class_avg_iou = [average_iou(scores) for scores in class_iou_scores]\n",
    "            class_map, class_recall, class_precision = [], [], []\n",
    "\n",
    "            for class_id in range(3):\n",
    "                if class_iou_scores[class_id]:\n",
    "                    class_map_value, class_recall_value, class_precision_value = calculate_map(\n",
    "                        gt_video[\"frames\"], pred_video[\"frames\"], img_width, img_height, class_id\n",
    "                    )\n",
    "                    class_map.append(class_map_value)\n",
    "                    class_recall.append(class_recall_value)\n",
    "                    class_precision.append(class_precision_value)\n",
    "                else:\n",
    "                    class_map.append(0.0)\n",
    "                    class_recall.append(0.0)\n",
    "                    class_precision.append(0.0)\n",
    "\n",
    "            video_results.append({\n",
    "                \"video_id\": video_id,\n",
    "                \"average_iou_class_0\": class_avg_iou[0],\n",
    "                \"average_iou_class_1\": class_avg_iou[1],\n",
    "                \"average_iou_class_2\": class_avg_iou[2],\n",
    "                \"map_class_0\": class_map[0],\n",
    "                \"map_class_1\": class_map[1],\n",
    "                \"map_class_2\": class_map[2],\n",
    "                \"average_recall_class_0\": class_recall[0],\n",
    "                \"average_recall_class_1\": class_recall[1],\n",
    "                \"average_recall_class_2\": class_recall[2],\n",
    "                \"average_precision_class_0\": class_precision[0],\n",
    "                \"average_precision_class_1\": class_precision[1],\n",
    "                \"average_precision_class_2\": class_precision[2],\n",
    "            })\n",
    "\n",
    "    return video_results\n",
    "\n",
    "def average_iou(iou_scores: List[float]) -> float:\n",
    "    return sum(iou_scores) / len(iou_scores) if iou_scores else 0.0\n",
    "\n",
    "def compute_ap(recalls: List[float], precisions: List[float]) -> float:\n",
    "    recalls = [0.0] + recalls + [1.0]\n",
    "    precisions = [0.0] + precisions + [0.0]\n",
    "    for i in range(len(precisions) - 1, 0, -1):\n",
    "        precisions[i - 1] = max(precisions[i - 1], precisions[i])\n",
    "    ap = 0.0\n",
    "    for i in range(1, len(recalls)):\n",
    "        ap += (recalls[i] - recalls[i - 1]) * precisions[i]\n",
    "    return ap\n",
    "\n",
    "def calculate_map(\n",
    "    gt_frames: List[Dict], pred_frames: List[Dict], img_width: int, img_height: int, class_id: int\n",
    ") -> Tuple[float, float, float]:\n",
    "    gt_bboxes = [frame[\"bbox\"] for frame in gt_frames if frame[\"class_id\"] == class_id]\n",
    "    pred_bboxes = [\n",
    "        detection[\"bbox\"]\n",
    "        for frame in pred_frames\n",
    "        for detection in frame[\"detections\"]\n",
    "        if detection[\"class_id\"] == class_id\n",
    "    ]\n",
    "\n",
    "    tp, fp, fn = 0, 0, len(gt_bboxes)\n",
    "\n",
    "    for pred_bbox in pred_bboxes:\n",
    "        matched = False\n",
    "        for gt_bbox in gt_bboxes:\n",
    "            if bbox_iou(pred_bbox, gt_bbox, img_width, img_height) > 0.5:\n",
    "                matched = True\n",
    "                tp += 1\n",
    "                fn -= 1\n",
    "                break\n",
    "        if not matched:\n",
    "            fp += 1\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "    ap = compute_ap([recall], [precision])\n",
    "    return ap, recall, precision\n",
    "\n",
    "# Load data\n",
    "gt_annotations = load_json(\n",
    "    \"/Users/alexis/Library/CloudStorage/OneDrive-Balayre&Co/Cranfield/Thesis/thesis-github-repository/data/frames/full_dataset_annotated_fpp/test.json\"\n",
    ")\n",
    "pred_annotations = load_json(\n",
    "    \"/Users/alexis/Library/CloudStorage/OneDrive-Balayre&Co/Cranfield/Thesis/thesis-github-repository/code/evalutation/results/results_nano.json\"\n",
    ")\n",
    "\n",
    "# Get the image size\n",
    "img_width = 640\n",
    "img_height = 480\n",
    "\n",
    "# Compare annotations and compute metrics for each video\n",
    "video_results = compare_annotations(gt_annotations, pred_annotations, img_width, img_height)\n",
    "\n",
    "# Display results\n",
    "df = pd.DataFrame(video_results)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>average_iou</th>\n",
       "      <th>map</th>\n",
       "      <th>average_recall</th>\n",
       "      <th>average_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>video_lab_platform_6</td>\n",
       "      <td>0.984820</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_indoor1</td>\n",
       "      <td>0.911021</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>video_lab_semiopen_1______3</td>\n",
       "      <td>0.974404</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      video_id  average_iou       map  average_recall  \\\n",
       "0         video_lab_platform_6     0.984820  1.000000        1.000000   \n",
       "1                 test_indoor1     0.911021  0.974359        0.974359   \n",
       "2  video_lab_semiopen_1______3     0.974404  1.000000        1.000000   \n",
       "\n",
       "   average_precision  \n",
       "0                1.0  \n",
       "1                1.0  \n",
       "2                1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
